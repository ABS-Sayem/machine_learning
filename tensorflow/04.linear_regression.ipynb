{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Linear Regression**\n",
    "###### **In this tutorial we will deal with a regression problem and we will learn how to load the data, analyze the data and apply some pre-processing and apply a linear regression model(having only one layer). And further this tutorial we will extend this to a deep neural network. This will help us deep understanding of keras dense layer and activation functions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Let's Start**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Silence Warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Import Libraries\n",
    "import pandas as pd     # used to work with datasets, analyze and modify them\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# Make numpy printouts easier to read\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Std_Id</th>\n",
       "      <th>Attendance</th>\n",
       "      <th>Class_Test</th>\n",
       "      <th>Mid</th>\n",
       "      <th>Final</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR01</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR02</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>Re_Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR03</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>Re_Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR04</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>42</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR05</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR06</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>38</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR07</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR08</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LR09</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LR10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>39</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Std_Id  Attendance  Class_Test  Mid  Final      Type\n",
       "0   LR01           8           8   20     40   Regular\n",
       "1   LR02           9           7   19     32  Re_Admit\n",
       "2   LR03           9           9   26     27  Re_Admit\n",
       "3   LR04           5           8   27     42   Regular\n",
       "4   LR05           7           5   24     37   Regular\n",
       "5   LR06           8           5   19     38   Regular\n",
       "6   LR07           8           5   20     40   Regular\n",
       "7   LR08           5           9   19     33   Regular\n",
       "8   LR09           7          10   27     30   Regular\n",
       "9   LR10           7           8   22     39   Regular"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data.csv')\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Std_Id  Attendance  Class_Test  Mid  Final  Regular  Re_Admit\n",
      "0    LR01           8           8   20     40        1         0\n",
      "1    LR02           9           7   19     32        0         1\n",
      "2    LR03           9           9   26     27        0         1\n",
      "3    LR04           5           8   27     42        1         0\n",
      "4    LR05           7           5   24     37        1         0\n",
      "..    ...         ...         ...  ...    ...      ...       ...\n",
      "95   LR96           8           5   19     40        1         0\n",
      "96   LR97           8           5   20     40        1         0\n",
      "97   LR98           5           9   19     33        1         0\n",
      "98   LR99           7          10   27     30        1         0\n",
      "99  LR100           7           8   22     39        1         0\n",
      "\n",
      "[100 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop the data with missing values. In our dataset there is no missing value, so we need not drop anything.\n",
    "#dataset = dataset.dropna()\n",
    "#dataset\n",
    "\n",
    "# Convert Categorical 'Type' data into one-hot data: In our dataset, all the data are numerical except Type data. So, to ignore confusion of our model we will one-hot encoding the type.\n",
    "dataset = pd.read_csv('data.csv')\n",
    "type = dataset.pop('Type')\n",
    "dataset['Regular'] = (type == 'Regular')*1\n",
    "dataset['Re_Admit'] = (type == 'Re_Admit')*1\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Data into Train-Test**\n",
    "###### **We can do it by calling *sample* that includes what percentage we want to use for training. Remaining percentage automatically goes for testing, We just have to drop the training specified dataset.**\n",
    "###### **Before spliting data we have to remove the *Std_Id* column, because is a string type object and it can confuse the spliting process.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Attendance  Class_Test  Mid  Final  Regular  Re_Admit\n",
      "0            8           8   20     40        1         0\n",
      "1            9           7   19     32        0         1\n",
      "2            9           9   26     27        0         1\n",
      "3            5           8   27     42        1         0\n",
      "4            7           5   24     37        1         0\n",
      "..         ...         ...  ...    ...      ...       ...\n",
      "95           8           5   19     40        1         0\n",
      "96           8           5   20     40        1         0\n",
      "97           5           9   19     33        1         0\n",
      "98           7          10   27     30        1         0\n",
      "99           7           8   22     39        1         0\n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Removing the \"Sd_Id\" column\n",
    "id = dataset.pop('Std_Id')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 6) (80, 6) (20, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attendance</th>\n",
       "      <td>80.0</td>\n",
       "      <td>7.2000</td>\n",
       "      <td>1.335020</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class_Test</th>\n",
       "      <td>80.0</td>\n",
       "      <td>7.4625</td>\n",
       "      <td>1.749819</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mid</th>\n",
       "      <td>80.0</td>\n",
       "      <td>22.1625</td>\n",
       "      <td>3.183994</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final</th>\n",
       "      <td>80.0</td>\n",
       "      <td>35.8250</td>\n",
       "      <td>4.716722</td>\n",
       "      <td>27.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regular</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.265053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Re_Admit</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.265053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count     mean       std   min   25%   50%   75%   max\n",
       "Attendance   80.0   7.2000  1.335020   5.0   7.0   7.0   8.0  10.0\n",
       "Class_Test   80.0   7.4625  1.749819   5.0   5.0   8.0   9.0  10.0\n",
       "Mid          80.0  22.1625  3.183994  19.0  19.0  20.0  26.0  27.0\n",
       "Final        80.0  35.8250  4.716722  27.0  32.0  37.0  40.0  44.0\n",
       "Regular      80.0   0.9250  0.265053   0.0   1.0   1.0   1.0   1.0\n",
       "Re_Admit     80.0   0.0750  0.265053   0.0   0.0   0.0   0.0   1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "print(dataset.shape, train_dataset.shape, test_dataset.shape)\n",
    "train_dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **In our dataset, we have 10 entries and 7 different columns. From which 8 entries will be used for training and remaining 2 entries will be used for testing. And the dercribe function gives us some parameters that might be used to analyze the dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Features**\n",
    "###### **Here, we will split the features from the labels. From our dataset, we will predict *Final* marks so we copy the training and testing dataset as training and testing features and because Final is the label of both training and testing features we pop the *Final* label.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('Final')\n",
    "test_labels = test_features.pop('Final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Features**\n",
    "###### **We will define a simple plot function and can use the function to plot any feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(feature, x=None, y=None):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.scatter(train_features[feature], train_labels, label='Data')\n",
    "    if(x is not None and y is not None):\n",
    "        plt,plot(x, y, color='k', label='Prediction')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Final')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot('Attendance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize**\n",
    "###### **If we see the description of the data, seen above in Split Data in Train-Test, we can see that the mean values have different ranges. If we take then as it is, it may confuge our model. The best way to overcome it is to normalize the data. For this, we can use a normalization layer from tensorflow preprocessing module.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               mean       std\n",
      "Attendance   7.2000  1.335020\n",
      "Class_Test   7.4625  1.749819\n",
      "Mid         22.1625  3.183994\n",
      "Final       35.8250  4.716722\n",
      "Regular      0.9250  0.265053\n",
      "Re_Admit     0.0750  0.265053\n",
      "[[ 7.2    7.463 22.163  0.925  0.075]]\n"
     ]
    }
   ],
   "source": [
    "# First, see the data\n",
    "print(train_dataset.describe().transpose()[['mean', 'std']])\n",
    "\n",
    "# Normalization Layer\n",
    "normalizer = preprocessing.Normalization()  # This is a keras layer for sequential api.\n",
    "# Adapt to Data: To call the normalizer we have to adapt it to our data.\n",
    "# Because our dataset is a pandas dataset, we need to make it to a numpy array.\n",
    "normalizer.adapt(np.array(train_features))\n",
    "# Now, if we see the normalization value we see that it is exactly the mean value. Because we don't apply the normalization layer so far.\n",
    "print(normalizer.mean.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **Let's check out the first training features to be normalized. When the normalize layer is called, it returns the input data with each feature independently normalized. It uses the formula- ((input-mean)/stddev).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Column: [[ 5  9 19  1  0]]\n",
      "Normalized: [[-1.658  0.884 -1.     0.285 -0.285]]\n"
     ]
    }
   ],
   "source": [
    "first = np.array(train_features[:1])\n",
    "# We will use the normalizer and casting the tensor into numpy array\n",
    "normalized_first = normalizer(first).numpy()\n",
    "print(\"First Column:\", first)\n",
    "print(\"Normalized:\", normalized_first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regression**\n",
    "###### **Now, we will use Linear Regression to predict final ccording to attendance/class_test/mid. For this, we have to normalize the input(attendance/class_test/mid). To predict the output(final) it will use a linear transformation function(y=mx+c) used in dense layer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 5) (80, 5)\n"
     ]
    }
   ],
   "source": [
    "# Work with Single Feature: [Not working due to shape issue]\n",
    "# Use \"Attendance\" as input\n",
    "#feature = \"Attendance\"\n",
    "single_feature = np.array(train_features)\n",
    "print(single_feature.shape, train_features.shape)\n",
    "# Now, we have to normalize and adapt the frature\n",
    "# Normalization Layer\n",
    "single_feature_normalizer = preprocessing.Normalization()\n",
    "# Adapt to the data\n",
    "single_feature_normalizer.adapt(single_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sequential Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Model\n",
    "feature_model = keras.models.Sequential([\n",
    "    normalizer,\n",
    "    layers.Dense(units=1)   # Linear Model\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizatio  (None, 5)                11        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17\n",
      "Trainable params: 6\n",
      "Non-trainable params: 11\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(feature_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "loss = keras.losses.MeanAbsoluteError()     # |y_p - y|. We can also use MeanSquareError: (y_p - p)^2\n",
    "optim = keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "feature_model.compile(optimizer=optim, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 1s 180ms/step - loss: 35.9752 - val_loss: 34.9866\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 35.7395 - val_loss: 34.8880\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 35.5239 - val_loss: 34.7631\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 35.2890 - val_loss: 34.6268\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 35.0785 - val_loss: 34.4950\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 34.8496 - val_loss: 34.3431\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 34.6401 - val_loss: 34.1999\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 34.4263 - val_loss: 34.0467\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 34.2191 - val_loss: 33.9037\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 34.0012 - val_loss: 33.7516\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 33.7945 - val_loss: 33.6012\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 33.5841 - val_loss: 33.4529\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 33.3679 - val_loss: 33.3056\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 33.1467 - val_loss: 33.1491\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 32.9475 - val_loss: 33.0030\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 32.7317 - val_loss: 32.8507\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 32.5208 - val_loss: 32.7033\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 32.3052 - val_loss: 32.5516\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 32.1067 - val_loss: 32.4084\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 32.19 - 0s 41ms/step - loss: 31.8822 - val_loss: 32.2580\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 31.6612 - val_loss: 32.1009\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 31.4608 - val_loss: 31.9530\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 31.2429 - val_loss: 31.8018\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 31.0350 - val_loss: 31.6548\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 30.8173 - val_loss: 31.5018\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 30.6042 - val_loss: 31.3512\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 30.3935 - val_loss: 31.2008\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 30.1878 - val_loss: 31.0547\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 29.9619 - val_loss: 30.9001\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 29.7588 - val_loss: 30.7517\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 29.5451 - val_loss: 30.6028\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 29.3262 - val_loss: 30.4497\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 29.1252 - val_loss: 30.3044\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 28.9063 - val_loss: 30.1533\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 28.6944 - val_loss: 30.0055\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 28.4727 - val_loss: 29.8511\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 28.2626 - val_loss: 29.6983\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 28.0567 - val_loss: 29.5468\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 27.8478 - val_loss: 29.3974\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 27.6338 - val_loss: 29.2512\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 27.4196 - val_loss: 29.1016\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 27.2021 - val_loss: 28.9485\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 26.9914 - val_loss: 28.7994\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 26.7836 - val_loss: 28.6528\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 26.5711 - val_loss: 28.5048\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 26.3664 - val_loss: 28.3617\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 26.1400 - val_loss: 28.2096\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 25.9259 - val_loss: 28.0583\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 25.7253 - val_loss: 27.9123\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 25.5010 - val_loss: 27.7610\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 25.2925 - val_loss: 27.6103\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 25.0827 - val_loss: 27.4625\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 24.8622 - val_loss: 27.3088\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 24.6517 - val_loss: 27.1578\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 24.4394 - val_loss: 27.0083\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 22.34 - 0s 48ms/step - loss: 24.2386 - val_loss: 26.8646\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 24.0186 - val_loss: 26.7175\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 23.8121 - val_loss: 26.5723\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 23.5870 - val_loss: 26.4196\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 23.3780 - val_loss: 26.2659\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 23.1606 - val_loss: 26.1116\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 22.9497 - val_loss: 25.9601\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 22.7429 - val_loss: 25.8138\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 22.5268 - val_loss: 25.6653\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 22.3087 - val_loss: 25.5115\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 22.1123 - val_loss: 25.3700\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 21.8857 - val_loss: 25.2190\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 21.6732 - val_loss: 25.0659\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 21.4606 - val_loss: 24.9164\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 21.2455 - val_loss: 24.7640\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 21.0395 - val_loss: 24.6169\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 20.8263 - val_loss: 24.4707\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 20.6080 - val_loss: 24.3204\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 20.3928 - val_loss: 24.1683\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 20.1926 - val_loss: 24.0247\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 19.24 - 0s 38ms/step - loss: 19.9759 - val_loss: 23.8799\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 19.7629 - val_loss: 23.7358\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 19.5448 - val_loss: 23.5868\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 19.3333 - val_loss: 23.4312\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 19.1382 - val_loss: 23.2828\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 18.9395 - val_loss: 23.1293\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 18.7357 - val_loss: 22.9718\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 18.5396 - val_loss: 22.8146\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 18.3493 - val_loss: 22.6632\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 18.1404 - val_loss: 22.5016\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 17.9501 - val_loss: 22.3454\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 17.7588 - val_loss: 22.2089\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 17.5536 - val_loss: 22.0879\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 17.3596 - val_loss: 21.9664\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 17.1654 - val_loss: 21.8484\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 16.9776 - val_loss: 21.7259\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 16.7924 - val_loss: 21.5950\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 16.5996 - val_loss: 21.4459\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 16.4226 - val_loss: 21.3041\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 16.2310 - val_loss: 21.1506\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 16.0477 - val_loss: 20.9869\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 15.8688 - val_loss: 20.8229\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 15.6851 - val_loss: 20.6442\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 15.5057 - val_loss: 20.4696\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 15.3305 - val_loss: 20.2903\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 15.1518 - val_loss: 20.1052\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 14.9576 - val_loss: 19.9141\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 14.7817 - val_loss: 19.7317\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 14.5836 - val_loss: 19.5471\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 14.4014 - val_loss: 19.3491\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 14.2254 - val_loss: 19.1531\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 14.0488 - val_loss: 18.9635\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 13.8537 - val_loss: 18.7773\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 13.6620 - val_loss: 18.5907\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 13.4859 - val_loss: 18.4042\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 13.3063 - val_loss: 18.2213\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 13.1155 - val_loss: 18.0545\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 12.9410 - val_loss: 17.8887\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 12.7608 - val_loss: 17.7166\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 12.5717 - val_loss: 17.5516\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 12.3992 - val_loss: 17.3805\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 12.2196 - val_loss: 17.2036\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 12.0644 - val_loss: 17.0219\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 11.9056 - val_loss: 16.8398\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 11.7521 - val_loss: 16.6552\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 11.6043 - val_loss: 16.4685\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 11.4454 - val_loss: 16.2778\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 11.2924 - val_loss: 16.0680\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 11.1390 - val_loss: 15.8697\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 10.9903 - val_loss: 15.6540\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 10.8388 - val_loss: 15.4480\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 10.6815 - val_loss: 15.2476\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 10.5285 - val_loss: 15.0844\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 10.3638 - val_loss: 14.9182\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 10.2133 - val_loss: 14.7389\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 10.0731 - val_loss: 14.5599\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 9.9394 - val_loss: 14.3707\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 9.7909 - val_loss: 14.1909\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 9.6527 - val_loss: 13.9967\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 9.5107 - val_loss: 13.8013\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 9.3770 - val_loss: 13.6098\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 9.2378 - val_loss: 13.4150\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 9.1132 - val_loss: 13.2284\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 8.9861 - val_loss: 13.0526\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 8.8620 - val_loss: 12.8919\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 8.7340 - val_loss: 12.7290\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 8.6013 - val_loss: 12.5644\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 8.4760 - val_loss: 12.4026\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 8.3428 - val_loss: 12.2508\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 8.2177 - val_loss: 12.0897\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 8.1029 - val_loss: 11.9320\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 7.9628 - val_loss: 11.7749\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 7.8540 - val_loss: 11.6256\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 7.7389 - val_loss: 11.4620\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 7.6111 - val_loss: 11.3018\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 7.4960 - val_loss: 11.1490\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 7.3993 - val_loss: 11.0071\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 7.2901 - val_loss: 10.8734\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 7.1900 - val_loss: 10.7237\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 7.0790 - val_loss: 10.5892\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 6.9831 - val_loss: 10.4542\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 6.8758 - val_loss: 10.3323\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 6.7847 - val_loss: 10.2075\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 6.6885 - val_loss: 10.0984\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 6.5919 - val_loss: 9.9907\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 6.4711 - val_loss: 9.8862\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6.3766 - val_loss: 9.7607\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 6.3015 - val_loss: 9.6302\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 6.2169 - val_loss: 9.4655\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 6.1356 - val_loss: 9.2957\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 6.0529 - val_loss: 9.1202\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 4.648 - 0s 34ms/step - loss: 5.9630 - val_loss: 8.9383\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 5.8782 - val_loss: 8.7586\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 5.8022 - val_loss: 8.5778\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 5.7085 - val_loss: 8.4044\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 5.6302 - val_loss: 8.2333\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 5.5326 - val_loss: 8.0778\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 5.4813 - val_loss: 7.9074\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 5.3956 - val_loss: 7.7434\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 5.3087 - val_loss: 7.5868\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 5.2135 - val_loss: 7.4314\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 5.1268 - val_loss: 7.2699\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 5.0532 - val_loss: 7.0929\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 4.9698 - val_loss: 6.9214\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 4.8868 - val_loss: 6.7429\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 4.7857 - val_loss: 6.5772\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 4.7113 - val_loss: 6.4207\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 4.6272 - val_loss: 6.2616\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 4.5552 - val_loss: 6.0957\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 4.4604 - val_loss: 5.9239\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 4.3752 - val_loss: 5.7678\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 4.3022 - val_loss: 5.5971\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 4.2084 - val_loss: 5.4331\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 4.121 - 0s 33ms/step - loss: 4.1240 - val_loss: 5.2675\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 4.0320 - val_loss: 5.1057\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 3.9568 - val_loss: 4.9347\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3.8851 - val_loss: 4.7617\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7908 - val_loss: 4.7592\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 3.7402 - val_loss: 4.7337\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 3.7450 - val_loss: 4.6854\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 3.7170 - val_loss: 4.6282\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 3.6880 - val_loss: 4.5629\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - ETA: 0s - loss: 3.510 - 0s 43ms/step - loss: 3.6668 - val_loss: 4.5055\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 3.6364 - val_loss: 4.4377\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.6060 - val_loss: 4.3897\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to Data\n",
    "history = feature_model.fit(\n",
    "    train_features, train_labels,\n",
    "    epochs=200,\n",
    "    verbose=1,\n",
    "    # Use 20% of data for validation\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the History**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.ylim([0,25])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error[Final]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step - loss: 5.2127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.212676048278809"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_model.evaluate(\n",
    "    test_features, test_labels,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10888/3599482806.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10888/3143107193.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(feature, x, y)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Prediction'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[0;32m   2805\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2806\u001b[0m         edgecolors=None, plotnonfinite=False, data=None, **kwargs):\n\u001b[1;32m-> 2807\u001b[1;33m     __ret = gca().scatter(\n\u001b[0m\u001b[0;32m   2808\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmarker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2809\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1410\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1412\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m         \u001b[0mbound\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[0;32m   4367\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4368\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4369\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x and y must be the same size\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4371\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "range_min = np.min(test_features)-10\n",
    "range_max = np.max(test_features)+10\n",
    "x = tf.linspace(range_min, range_max, 50)\n",
    "y = feature_model.predict(x)\n",
    "\n",
    "plot(test_features, x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24d7359adec4ffe2916680474ceb48a86338759ffb8252cd67d6683f84078a4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
