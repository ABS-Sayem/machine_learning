{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Linear Regression**\n",
    "###### **In this tutorial we will deal with a regression problem and we will learn how to load the data, analyze the data and apply some pre-processing and apply a linear regression model(having only one layer). And further this tutorial we will extend this to a deep neural network. This will help us deep understanding of keras dense layer and activation functions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Let's Start**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Silence Warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Import Libraries\n",
    "import pandas as pd     # used to work with datasets, analyze and modify them\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# Make numpy printouts easier to read\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Std_Id</th>\n",
       "      <th>Attendance</th>\n",
       "      <th>Class_Test</th>\n",
       "      <th>Mid</th>\n",
       "      <th>Final</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR01</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR02</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>Re_Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR03</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>Re_Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR04</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>42</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR05</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR06</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>38</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR07</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR08</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LR09</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LR10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>39</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Std_Id  Attendance  Class_Test  Mid  Final      Type\n",
       "0   LR01           8           8   20     40   Regular\n",
       "1   LR02           9           7   19     32  Re_Admit\n",
       "2   LR03           9           9   26     27  Re_Admit\n",
       "3   LR04           5           8   27     42   Regular\n",
       "4   LR05           7           5   24     37   Regular\n",
       "5   LR06           8           5   19     38   Regular\n",
       "6   LR07           8           5   20     40   Regular\n",
       "7   LR08           5           9   19     33   Regular\n",
       "8   LR09           7          10   27     30   Regular\n",
       "9   LR10           7           8   22     39   Regular"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data.csv')\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Std_Id  Attendance  Class_Test  Mid  Final  Regular  Re_Admit\n",
      "0    LR01           8           8   23     40        1         0\n",
      "1    LR02           9           7   19     32        0         1\n",
      "2    LR03           9           9   26     27        0         1\n",
      "3    LR04           5           8   27     42        1         0\n",
      "4    LR05           7           5   24     37        1         0\n",
      "..    ...         ...         ...  ...    ...      ...       ...\n",
      "95   LR96           8           5   19     40        1         0\n",
      "96   LR97           8           5   15     40        1         0\n",
      "97   LR98           5           9   19     33        1         0\n",
      "98   LR99           7          10   17     30        1         0\n",
      "99  LR100           7           8   22     39        1         0\n",
      "\n",
      "[100 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop the data with missing values. In our dataset there is no missing value, so we need not drop anything.\n",
    "#dataset = dataset.dropna()\n",
    "#dataset\n",
    "\n",
    "# Convert Categorical 'Type' data into one-hot data: In our dataset, all the data are numerical except Type data. So, to ignore confusion of our model we will one-hot encoding the type.\n",
    "dataset = pd.read_csv('data.csv')\n",
    "type = dataset.pop('Type')\n",
    "dataset['Regular'] = (type == 'Regular')*1\n",
    "dataset['Re_Admit'] = (type == 'Re_Admit')*1\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Data into Train-Test**\n",
    "###### **We can do it by calling *sample* that includes what percentage we want to use for training. Remaining percentage automatically goes for testing, We just have to drop the training specified dataset.**\n",
    "###### **Before spliting data we have to remove the *Std_Id* column, because is a string type object and it can confuse the spliting process.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Attendance  Class_Test  Mid  Final  Regular  Re_Admit\n",
      "0            8           8   23     40        1         0\n",
      "1            9           7   19     32        0         1\n",
      "2            9           9   26     27        0         1\n",
      "3            5           8   27     42        1         0\n",
      "4            7           5   24     37        1         0\n",
      "..         ...         ...  ...    ...      ...       ...\n",
      "95           8           5   19     40        1         0\n",
      "96           8           5   15     40        1         0\n",
      "97           5           9   19     33        1         0\n",
      "98           7          10   17     30        1         0\n",
      "99           7           8   22     39        1         0\n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Removing the \"Sd_Id\" column\n",
    "id = dataset.pop('Std_Id')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 6) (80, 6) (20, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attendance</th>\n",
       "      <td>80.0</td>\n",
       "      <td>7.2000</td>\n",
       "      <td>1.335020</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class_Test</th>\n",
       "      <td>80.0</td>\n",
       "      <td>7.4625</td>\n",
       "      <td>1.749819</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mid</th>\n",
       "      <td>80.0</td>\n",
       "      <td>21.8750</td>\n",
       "      <td>3.934190</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final</th>\n",
       "      <td>80.0</td>\n",
       "      <td>35.8250</td>\n",
       "      <td>4.716722</td>\n",
       "      <td>27.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regular</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.265053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Re_Admit</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.265053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count     mean       std   min   25%   50%   75%   max\n",
       "Attendance   80.0   7.2000  1.335020   5.0   7.0   7.0   8.0  10.0\n",
       "Class_Test   80.0   7.4625  1.749819   5.0   5.0   8.0   9.0  10.0\n",
       "Mid          80.0  21.8750  3.934190  13.0  19.0  21.5  26.0  29.0\n",
       "Final        80.0  35.8250  4.716722  27.0  32.0  37.0  40.0  44.0\n",
       "Regular      80.0   0.9250  0.265053   0.0   1.0   1.0   1.0   1.0\n",
       "Re_Admit     80.0   0.0750  0.265053   0.0   0.0   0.0   0.0   1.0"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "print(dataset.shape, train_dataset.shape, test_dataset.shape)\n",
    "train_dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **In our dataset, we have 10 entries and 7 different columns. From which 8 entries will be used for training and remaining 2 entries will be used for testing. And the dercribe function gives us some parameters that might be used to analyze the dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Features**\n",
    "###### **Here, we will split the features from the labels. From our dataset, we will predict *Final* marks so we copy the training and testing dataset as training and testing features and because Final is the label of both training and testing features we pop the *Final* label.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('Final')\n",
    "test_labels = test_features.pop('Final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Features**\n",
    "###### **We will define a simple plot function and can use the function to plot any feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(feature, x=None, y=None):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.scatter(train_features[feature], train_labels, label='Data')\n",
    "    if(x is not None and y is not None):\n",
    "        plt.plot(x, y, color='k', label='Prediction')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Final')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot('Mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize**\n",
    "###### **If we see the description of the data, seen above in Split Data in Train-Test, we can see that the mean values have different ranges. If we take then as it is, it may confuge our model. The best way to overcome it is to normalize the data. For this, we can use a normalization layer from tensorflow preprocessing module.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               mean       std\n",
      "Attendance   7.2000  1.335020\n",
      "Class_Test   7.4625  1.749819\n",
      "Mid         21.8750  3.934190\n",
      "Final       35.8250  4.716722\n",
      "Regular      0.9250  0.265053\n",
      "Re_Admit     0.0750  0.265053\n",
      "[[ 7.2    7.463 21.875  0.925  0.075]]\n"
     ]
    }
   ],
   "source": [
    "# First, see the data\n",
    "print(train_dataset.describe().transpose()[['mean', 'std']])\n",
    "\n",
    "# Normalization Layer\n",
    "normalizer = preprocessing.Normalization()  # This is a keras layer for sequential api.\n",
    "# Adapt to Data: To call the normalizer we have to adapt it to our data.\n",
    "# Because our dataset is a pandas dataset, we need to make it to a numpy array.\n",
    "normalizer.adapt(np.array(train_features))\n",
    "# Now, if we see the normalization value we see that it is exactly the mean value. Because we don't apply the normalization layer so far.\n",
    "print(normalizer.mean.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **Let's check out the first training features to be normalized. When the normalize layer is called, it returns the input data with each feature independently normalized. It uses the formula- ((input-mean)/stddev).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Column: [[ 5  9 19  1  0]]\n",
      "Normalized: [[-1.658  0.884 -0.735  0.285 -0.285]]\n"
     ]
    }
   ],
   "source": [
    "first = np.array(train_features[:1])\n",
    "# We will use the normalizer and casting the tensor into numpy array\n",
    "normalized_first = normalizer(first).numpy()\n",
    "print(\"First Column:\", first)\n",
    "print(\"Normalized:\", normalized_first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regression**\n",
    "###### **Now, we will use Linear Regression to predict final ccording to attendance/class_test/mid. For this, we have to normalize the input(attendance/class_test/mid). To predict the output(final) it will use a linear transformation function(y=mx+c) used in dense layer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80,) (80, 5)\n"
     ]
    }
   ],
   "source": [
    "# Work with Single Feature: [Not working due to shape issue]\n",
    "# Use \"Attendance\" as input\n",
    "feature = \"Attendance\"\n",
    "single_feature = np.array(train_features[feature])\n",
    "print(single_feature.shape, train_features.shape)\n",
    "# Now, we have to normalize and adapt the frature\n",
    "# Normalization Layer\n",
    "single_feature_normalizer = preprocessing.Normalization()\n",
    "# Adapt to the data\n",
    "#single_feature_normalizer.adapt(single_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sequential Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Model\n",
    "feature_model = keras.models.Sequential([\n",
    "    normalizer,\n",
    "    layers.Dense(units=1)   # Linear Model\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizatio  (None, 5)                11        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17\n",
      "Trainable params: 6\n",
      "Non-trainable params: 11\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(feature_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "loss = keras.losses.MeanAbsoluteError()     # |y_p - y|. We can also use MeanSquareError: (y_p - p)^2\n",
    "optim = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "feature_model.compile(optimizer=optim, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "2/2 [==============================] - 1s 179ms/step - loss: 35.9565 - val_loss: 35.2768\n",
      "Epoch 2/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 35.9325 - val_loss: 35.2676\n",
      "Epoch 3/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 35.9091 - val_loss: 35.2552\n",
      "Epoch 4/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 35.8877 - val_loss: 35.2424\n",
      "Epoch 5/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 35.8651 - val_loss: 35.2297\n",
      "Epoch 6/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 35.8437 - val_loss: 35.2166\n",
      "Epoch 7/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 35.8215 - val_loss: 35.2037\n",
      "Epoch 8/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 35.7993 - val_loss: 35.1904\n",
      "Epoch 9/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 35.7782 - val_loss: 35.1782\n",
      "Epoch 10/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 35.7566 - val_loss: 35.1663\n",
      "Epoch 11/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 35.7345 - val_loss: 35.1545\n",
      "Epoch 12/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 35.7125 - val_loss: 35.1429\n",
      "Epoch 13/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 35.6911 - val_loss: 35.1311\n",
      "Epoch 14/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 35.6681 - val_loss: 35.1189\n",
      "Epoch 15/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 35.6472 - val_loss: 35.1074\n",
      "Epoch 16/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 35.6242 - val_loss: 35.0951\n",
      "Epoch 17/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 35.6036 - val_loss: 35.0831\n",
      "Epoch 18/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 35.5804 - val_loss: 35.0706\n",
      "Epoch 19/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 35.5581 - val_loss: 35.0578\n",
      "Epoch 20/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 35.5374 - val_loss: 35.0459\n",
      "Epoch 21/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 35.5147 - val_loss: 35.0330\n",
      "Epoch 22/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 35.10 - 0s 42ms/step - loss: 35.4927 - val_loss: 35.0200\n",
      "Epoch 23/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 35.4705 - val_loss: 35.0070\n",
      "Epoch 24/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 35.4498 - val_loss: 34.9943\n",
      "Epoch 25/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 35.4276 - val_loss: 34.9816\n",
      "Epoch 26/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 35.4065 - val_loss: 34.9694\n",
      "Epoch 27/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 35.3848 - val_loss: 34.9573\n",
      "Epoch 28/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 35.3619 - val_loss: 34.9446\n",
      "Epoch 29/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 35.3394 - val_loss: 34.9311\n",
      "Epoch 30/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 35.3190 - val_loss: 34.9188\n",
      "Epoch 31/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 35.2970 - val_loss: 34.9064\n",
      "Epoch 32/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 35.2742 - val_loss: 34.8933\n",
      "Epoch 33/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 35.2531 - val_loss: 34.8806\n",
      "Epoch 34/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 35.2308 - val_loss: 34.8675\n",
      "Epoch 35/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 35.2101 - val_loss: 34.8553\n",
      "Epoch 36/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 35.1873 - val_loss: 34.8423\n",
      "Epoch 37/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 35.1648 - val_loss: 34.8288\n",
      "Epoch 38/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 35.1434 - val_loss: 34.8158\n",
      "Epoch 39/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 35.1211 - val_loss: 34.8021\n",
      "Epoch 40/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 35.1000 - val_loss: 34.7892\n",
      "Epoch 41/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 35.0783 - val_loss: 34.7763\n",
      "Epoch 42/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 35.0565 - val_loss: 34.7636\n",
      "Epoch 43/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 35.0355 - val_loss: 34.7514\n",
      "Epoch 44/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 35.0126 - val_loss: 34.7386\n",
      "Epoch 45/3000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 34.9906 - val_loss: 34.7256\n",
      "Epoch 46/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 34.9691 - val_loss: 34.7129\n",
      "Epoch 47/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 34.9467 - val_loss: 34.6994\n",
      "Epoch 48/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 34.9253 - val_loss: 34.6860\n",
      "Epoch 49/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 34.9040 - val_loss: 34.6734\n",
      "Epoch 50/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 34.8824 - val_loss: 34.6610\n",
      "Epoch 51/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 34.8602 - val_loss: 34.6484\n",
      "Epoch 52/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 34.8398 - val_loss: 34.6366\n",
      "Epoch 53/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 34.8166 - val_loss: 34.6241\n",
      "Epoch 54/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 34.7955 - val_loss: 34.6120\n",
      "Epoch 55/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 34.7722 - val_loss: 34.5987\n",
      "Epoch 56/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 34.7511 - val_loss: 34.5861\n",
      "Epoch 57/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 34.7295 - val_loss: 34.5732\n",
      "Epoch 58/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 34.7074 - val_loss: 34.5605\n",
      "Epoch 59/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 34.6855 - val_loss: 34.5476\n",
      "Epoch 60/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 34.77 - 0s 35ms/step - loss: 34.6650 - val_loss: 34.5354\n",
      "Epoch 61/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 34.6429 - val_loss: 34.5230\n",
      "Epoch 62/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 34.6206 - val_loss: 34.5100\n",
      "Epoch 63/3000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 34.5980 - val_loss: 34.4968\n",
      "Epoch 64/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 34.5787 - val_loss: 34.4849\n",
      "Epoch 65/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 34.5553 - val_loss: 34.4720\n",
      "Epoch 66/3000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 34.5343 - val_loss: 34.4595\n",
      "Epoch 67/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 34.5121 - val_loss: 34.4468\n",
      "Epoch 68/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 34.4892 - val_loss: 34.4333\n",
      "Epoch 69/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 34.4672 - val_loss: 34.4196\n",
      "Epoch 70/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 34.4459 - val_loss: 34.4064\n",
      "Epoch 71/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 34.4255 - val_loss: 34.3939\n",
      "Epoch 72/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 34.4037 - val_loss: 34.3813\n",
      "Epoch 73/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 34.3809 - val_loss: 34.3679\n",
      "Epoch 74/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 34.3588 - val_loss: 34.3546\n",
      "Epoch 75/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 34.3374 - val_loss: 34.3415\n",
      "Epoch 76/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 34.3162 - val_loss: 34.3286\n",
      "Epoch 77/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 34.2933 - val_loss: 34.3149\n",
      "Epoch 78/3000\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 34.2724 - val_loss: 34.3018\n",
      "Epoch 79/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 34.2506 - val_loss: 34.2887\n",
      "Epoch 80/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 34.2287 - val_loss: 34.2753\n",
      "Epoch 81/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 34.2099 - val_loss: 34.2635\n",
      "Epoch 82/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 34.1853 - val_loss: 34.2498\n",
      "Epoch 83/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 34.1633 - val_loss: 34.2359\n",
      "Epoch 84/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 34.1419 - val_loss: 34.2223\n",
      "Epoch 85/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 34.1205 - val_loss: 34.2092\n",
      "Epoch 86/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 34.0988 - val_loss: 34.1960\n",
      "Epoch 87/3000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 34.0779 - val_loss: 34.1832\n",
      "Epoch 88/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 34.0549 - val_loss: 34.1696\n",
      "Epoch 89/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 34.0345 - val_loss: 34.1568\n",
      "Epoch 90/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 34.0116 - val_loss: 34.1433\n",
      "Epoch 91/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 33.9904 - val_loss: 34.1301\n",
      "Epoch 92/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 33.9684 - val_loss: 34.1165\n",
      "Epoch 93/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 33.9468 - val_loss: 34.1032\n",
      "Epoch 94/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 33.9249 - val_loss: 34.0897\n",
      "Epoch 95/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 33.9042 - val_loss: 34.0770\n",
      "Epoch 96/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 33.8817 - val_loss: 34.0638\n",
      "Epoch 97/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 33.8599 - val_loss: 34.0504\n",
      "Epoch 98/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 33.8386 - val_loss: 34.0375\n",
      "Epoch 99/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 33.8164 - val_loss: 34.0239\n",
      "Epoch 100/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 33.7947 - val_loss: 34.0104\n",
      "Epoch 101/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 33.7734 - val_loss: 33.9973\n",
      "Epoch 102/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 33.7518 - val_loss: 33.9840\n",
      "Epoch 103/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 33.7296 - val_loss: 33.9706\n",
      "Epoch 104/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 33.7094 - val_loss: 33.9576\n",
      "Epoch 105/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 33.6874 - val_loss: 33.9448\n",
      "Epoch 106/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 33.6651 - val_loss: 33.9318\n",
      "Epoch 107/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 33.6440 - val_loss: 33.9192\n",
      "Epoch 108/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 33.6211 - val_loss: 33.9055\n",
      "Epoch 109/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 33.5993 - val_loss: 33.8921\n",
      "Epoch 110/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 33.5782 - val_loss: 33.8790\n",
      "Epoch 111/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 33.5575 - val_loss: 33.8665\n",
      "Epoch 112/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 33.5344 - val_loss: 33.8531\n",
      "Epoch 113/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 33.5127 - val_loss: 33.8396\n",
      "Epoch 114/3000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 33.4913 - val_loss: 33.8266\n",
      "Epoch 115/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 33.4690 - val_loss: 33.8129\n",
      "Epoch 116/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 33.4481 - val_loss: 33.7999\n",
      "Epoch 117/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 33.4262 - val_loss: 33.7863\n",
      "Epoch 118/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 33.11 - 0s 39ms/step - loss: 33.4051 - val_loss: 33.7734\n",
      "Epoch 119/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 33.3829 - val_loss: 33.7603\n",
      "Epoch 120/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 33.3607 - val_loss: 33.7468\n",
      "Epoch 121/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 33.3394 - val_loss: 33.7336\n",
      "Epoch 122/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 33.3181 - val_loss: 33.7208\n",
      "Epoch 123/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 33.2958 - val_loss: 33.7075\n",
      "Epoch 124/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 33.2742 - val_loss: 33.6943\n",
      "Epoch 125/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 33.2522 - val_loss: 33.6809\n",
      "Epoch 126/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 33.2301 - val_loss: 33.6672\n",
      "Epoch 127/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 33.45 - 0s 46ms/step - loss: 33.2090 - val_loss: 33.6540\n",
      "Epoch 128/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 33.1880 - val_loss: 33.6414\n",
      "Epoch 129/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 33.1655 - val_loss: 33.6277\n",
      "Epoch 130/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 33.1433 - val_loss: 33.6139\n",
      "Epoch 131/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 33.1218 - val_loss: 33.6002\n",
      "Epoch 132/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 33.1011 - val_loss: 33.5875\n",
      "Epoch 133/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 33.0788 - val_loss: 33.5742\n",
      "Epoch 134/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 33.0574 - val_loss: 33.5606\n",
      "Epoch 135/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 33.0361 - val_loss: 33.5480\n",
      "Epoch 136/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 33.0145 - val_loss: 33.5353\n",
      "Epoch 137/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 32.9915 - val_loss: 33.5216\n",
      "Epoch 138/3000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 32.9703 - val_loss: 33.5083\n",
      "Epoch 139/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 32.9486 - val_loss: 33.4952\n",
      "Epoch 140/3000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 32.9270 - val_loss: 33.4823\n",
      "Epoch 141/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 32.9057 - val_loss: 33.4695\n",
      "Epoch 142/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 32.8839 - val_loss: 33.4566\n",
      "Epoch 143/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 32.8609 - val_loss: 33.4426\n",
      "Epoch 144/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 32.8405 - val_loss: 33.4297\n",
      "Epoch 145/3000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 32.8202 - val_loss: 33.4175\n",
      "Epoch 146/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 32.7964 - val_loss: 33.4043\n",
      "Epoch 147/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 32.7747 - val_loss: 33.3910\n",
      "Epoch 148/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 32.7535 - val_loss: 33.3782\n",
      "Epoch 149/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 32.7318 - val_loss: 33.3652\n",
      "Epoch 150/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 32.7093 - val_loss: 33.3517\n",
      "Epoch 151/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 32.6881 - val_loss: 33.3387\n",
      "Epoch 152/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 32.6662 - val_loss: 33.3255\n",
      "Epoch 153/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 32.6446 - val_loss: 33.3121\n",
      "Epoch 154/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 32.6239 - val_loss: 33.2997\n",
      "Epoch 155/3000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 32.6015 - val_loss: 33.2868\n",
      "Epoch 156/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 32.5796 - val_loss: 33.2739\n",
      "Epoch 157/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 32.5585 - val_loss: 33.2611\n",
      "Epoch 158/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 32.5365 - val_loss: 33.2480\n",
      "Epoch 159/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 32.5144 - val_loss: 33.2347\n",
      "Epoch 160/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 32.4929 - val_loss: 33.2219\n",
      "Epoch 161/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 32.4715 - val_loss: 33.2093\n",
      "Epoch 162/3000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 32.4486 - val_loss: 33.1958\n",
      "Epoch 163/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 32.4281 - val_loss: 33.1831\n",
      "Epoch 164/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 32.4047 - val_loss: 33.1692\n",
      "Epoch 165/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 32.3841 - val_loss: 33.1563\n",
      "Epoch 166/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 32.3616 - val_loss: 33.1427\n",
      "Epoch 167/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 32.3403 - val_loss: 33.1296\n",
      "Epoch 168/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 32.3188 - val_loss: 33.1164\n",
      "Epoch 169/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 32.2965 - val_loss: 33.1028\n",
      "Epoch 170/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 32.2747 - val_loss: 33.0893\n",
      "Epoch 171/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 32.2533 - val_loss: 33.0761\n",
      "Epoch 172/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 32.2322 - val_loss: 33.0634\n",
      "Epoch 173/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 32.2101 - val_loss: 33.0503\n",
      "Epoch 174/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 32.1889 - val_loss: 33.0377\n",
      "Epoch 175/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 32.1671 - val_loss: 33.0247\n",
      "Epoch 176/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 32.1448 - val_loss: 33.0111\n",
      "Epoch 177/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 32.1238 - val_loss: 32.9986\n",
      "Epoch 178/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 32.1013 - val_loss: 32.9856\n",
      "Epoch 179/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 32.0793 - val_loss: 32.9723\n",
      "Epoch 180/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 32.0578 - val_loss: 32.9588\n",
      "Epoch 181/3000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 32.0360 - val_loss: 32.9457\n",
      "Epoch 182/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 32.0153 - val_loss: 32.9332\n",
      "Epoch 183/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 31.9923 - val_loss: 32.9200\n",
      "Epoch 184/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 31.9704 - val_loss: 32.9065\n",
      "Epoch 185/3000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 31.9488 - val_loss: 32.8932\n",
      "Epoch 186/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 31.9281 - val_loss: 32.8807\n",
      "Epoch 187/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 31.9057 - val_loss: 32.8676\n",
      "Epoch 188/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 31.8836 - val_loss: 32.8543\n",
      "Epoch 189/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 31.8634 - val_loss: 32.8421\n",
      "Epoch 190/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 31.8408 - val_loss: 32.8294\n",
      "Epoch 191/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 31.8182 - val_loss: 32.8161\n",
      "Epoch 192/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 31.7971 - val_loss: 32.8032\n",
      "Epoch 193/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 31.7748 - val_loss: 32.7896\n",
      "Epoch 194/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 31.7539 - val_loss: 32.7771\n",
      "Epoch 195/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 31.7322 - val_loss: 32.7646\n",
      "Epoch 196/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 31.7100 - val_loss: 32.7517\n",
      "Epoch 197/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 31.6876 - val_loss: 32.7384\n",
      "Epoch 198/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 31.6666 - val_loss: 32.7257\n",
      "Epoch 199/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 31.6443 - val_loss: 32.7127\n",
      "Epoch 200/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 31.6227 - val_loss: 32.6997\n",
      "Epoch 201/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 31.6007 - val_loss: 32.6867\n",
      "Epoch 202/3000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 31.5796 - val_loss: 32.6740\n",
      "Epoch 203/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 31.5579 - val_loss: 32.6612\n",
      "Epoch 204/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 31.5352 - val_loss: 32.6479\n",
      "Epoch 205/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 31.5133 - val_loss: 32.6345\n",
      "Epoch 206/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 31.4937 - val_loss: 32.6225\n",
      "Epoch 207/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 31.4700 - val_loss: 32.6094\n",
      "Epoch 208/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 31.4484 - val_loss: 32.5965\n",
      "Epoch 209/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 31.4283 - val_loss: 32.5840\n",
      "Epoch 210/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 31.4050 - val_loss: 32.5712\n",
      "Epoch 211/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 31.3830 - val_loss: 32.5578\n",
      "Epoch 212/3000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 31.3612 - val_loss: 32.5446\n",
      "Epoch 213/3000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 31.3396 - val_loss: 32.5317\n",
      "Epoch 214/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 31.3183 - val_loss: 32.5192\n",
      "Epoch 215/3000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 31.2966 - val_loss: 32.5067\n",
      "Epoch 216/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 31.2750 - val_loss: 32.4940\n",
      "Epoch 217/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 31.2531 - val_loss: 32.4815\n",
      "Epoch 218/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 31.2306 - val_loss: 32.4683\n",
      "Epoch 219/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 31.2084 - val_loss: 32.4548\n",
      "Epoch 220/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 31.1875 - val_loss: 32.4422\n",
      "Epoch 221/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 31.1656 - val_loss: 32.4295\n",
      "Epoch 222/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 31.1435 - val_loss: 32.4163\n",
      "Epoch 223/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 31.1213 - val_loss: 32.4029\n",
      "Epoch 224/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 31.1002 - val_loss: 32.3901\n",
      "Epoch 225/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 31.0788 - val_loss: 32.3776\n",
      "Epoch 226/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 31.0571 - val_loss: 32.3651\n",
      "Epoch 227/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 31.0346 - val_loss: 32.3521\n",
      "Epoch 228/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 31.0134 - val_loss: 32.3396\n",
      "Epoch 229/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 30.9909 - val_loss: 32.3266\n",
      "Epoch 230/3000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 30.9697 - val_loss: 32.3140\n",
      "Epoch 231/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 30.9484 - val_loss: 32.3010\n",
      "Epoch 232/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 30.9252 - val_loss: 32.2874\n",
      "Epoch 233/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 30.9036 - val_loss: 32.2742\n",
      "Epoch 234/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 30.8820 - val_loss: 32.2612\n",
      "Epoch 235/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 30.8626 - val_loss: 32.2497\n",
      "Epoch 236/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 30.8381 - val_loss: 32.2365\n",
      "Epoch 237/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 30.8165 - val_loss: 32.2233\n",
      "Epoch 238/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 30.7954 - val_loss: 32.2107\n",
      "Epoch 239/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 30.7726 - val_loss: 32.1973\n",
      "Epoch 240/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 30.7516 - val_loss: 32.1847\n",
      "Epoch 241/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 30.7292 - val_loss: 32.1714\n",
      "Epoch 242/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 30.7086 - val_loss: 32.1589\n",
      "Epoch 243/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 30.6867 - val_loss: 32.1465\n",
      "Epoch 244/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 30.6644 - val_loss: 32.1339\n",
      "Epoch 245/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 30.6429 - val_loss: 32.1214\n",
      "Epoch 246/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 30.6207 - val_loss: 32.1087\n",
      "Epoch 247/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 30.5989 - val_loss: 32.0959\n",
      "Epoch 248/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 30.5776 - val_loss: 32.0834\n",
      "Epoch 249/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 30.5544 - val_loss: 32.0697\n",
      "Epoch 250/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 30.5343 - val_loss: 32.0575\n",
      "Epoch 251/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 30.5113 - val_loss: 32.0443\n",
      "Epoch 252/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 30.4908 - val_loss: 32.0320\n",
      "Epoch 253/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 30.4684 - val_loss: 32.0194\n",
      "Epoch 254/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 30.4461 - val_loss: 32.0060\n",
      "Epoch 255/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 30.4241 - val_loss: 31.9928\n",
      "Epoch 256/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 30.4037 - val_loss: 31.9808\n",
      "Epoch 257/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 30.3814 - val_loss: 31.9683\n",
      "Epoch 258/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 30.3588 - val_loss: 31.9553\n",
      "Epoch 259/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 30.3368 - val_loss: 31.9422\n",
      "Epoch 260/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 30.3153 - val_loss: 31.9291\n",
      "Epoch 261/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 30.2939 - val_loss: 31.9163\n",
      "Epoch 262/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 30.2723 - val_loss: 31.9039\n",
      "Epoch 263/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 30.2498 - val_loss: 31.8909\n",
      "Epoch 264/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 30.2285 - val_loss: 31.8780\n",
      "Epoch 265/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 30.2057 - val_loss: 31.8643\n",
      "Epoch 266/3000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 30.1851 - val_loss: 31.8519\n",
      "Epoch 267/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 30.1641 - val_loss: 31.8396\n",
      "Epoch 268/3000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 30.1419 - val_loss: 31.8274\n",
      "Epoch 269/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 30.1187 - val_loss: 31.8142\n",
      "Epoch 270/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 30.0970 - val_loss: 31.8010\n",
      "Epoch 271/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 30.0755 - val_loss: 31.7881\n",
      "Epoch 272/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 30.0548 - val_loss: 31.7759\n",
      "Epoch 273/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 30.0318 - val_loss: 31.7629\n",
      "Epoch 274/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 30.0102 - val_loss: 31.7500\n",
      "Epoch 275/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 29.9891 - val_loss: 31.7377\n",
      "Epoch 276/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 29.9661 - val_loss: 31.7244\n",
      "Epoch 277/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 29.9444 - val_loss: 31.7112\n",
      "Epoch 278/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 29.9230 - val_loss: 31.6983\n",
      "Epoch 279/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 29.9020 - val_loss: 31.6860\n",
      "Epoch 280/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 29.8798 - val_loss: 31.6734\n",
      "Epoch 281/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 29.8579 - val_loss: 31.6608\n",
      "Epoch 282/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 29.8360 - val_loss: 31.6481\n",
      "Epoch 283/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 29.8139 - val_loss: 31.6352\n",
      "Epoch 284/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 29.7925 - val_loss: 31.6225\n",
      "Epoch 285/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 29.7708 - val_loss: 31.6101\n",
      "Epoch 286/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 29.7480 - val_loss: 31.5970\n",
      "Epoch 287/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 29.7275 - val_loss: 31.5844\n",
      "Epoch 288/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 29.7046 - val_loss: 31.5714\n",
      "Epoch 289/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 29.6825 - val_loss: 31.5581\n",
      "Epoch 290/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 29.6612 - val_loss: 31.5452\n",
      "Epoch 291/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 29.6400 - val_loss: 31.5326\n",
      "Epoch 292/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 29.6176 - val_loss: 31.5198\n",
      "Epoch 293/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 29.5976 - val_loss: 31.5079\n",
      "Epoch 294/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 29.5742 - val_loss: 31.4952\n",
      "Epoch 295/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 29.5532 - val_loss: 31.4827\n",
      "Epoch 296/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 29.5300 - val_loss: 31.4695\n",
      "Epoch 297/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 29.5082 - val_loss: 31.4565\n",
      "Epoch 298/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 29.4865 - val_loss: 31.4435\n",
      "Epoch 299/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 29.4653 - val_loss: 31.4307\n",
      "Epoch 300/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 29.4432 - val_loss: 31.4180\n",
      "Epoch 301/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 29.4219 - val_loss: 31.4054\n",
      "Epoch 302/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 29.3993 - val_loss: 31.3925\n",
      "Epoch 303/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 29.3777 - val_loss: 31.3796\n",
      "Epoch 304/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 29.3562 - val_loss: 31.3669\n",
      "Epoch 305/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 29.3341 - val_loss: 31.3540\n",
      "Epoch 306/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 29.3127 - val_loss: 31.3416\n",
      "Epoch 307/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 29.2910 - val_loss: 31.3292\n",
      "Epoch 308/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 29.2701 - val_loss: 31.3172\n",
      "Epoch 309/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 29.2470 - val_loss: 31.3044\n",
      "Epoch 310/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 29.2248 - val_loss: 31.2910\n",
      "Epoch 311/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 29.2030 - val_loss: 31.2780\n",
      "Epoch 312/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 29.1822 - val_loss: 31.2654\n",
      "Epoch 313/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 29.1593 - val_loss: 31.2520\n",
      "Epoch 314/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 29.1384 - val_loss: 31.2396\n",
      "Epoch 315/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 29.1157 - val_loss: 31.2266\n",
      "Epoch 316/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 29.0950 - val_loss: 31.2141\n",
      "Epoch 317/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 29.0722 - val_loss: 31.2012\n",
      "Epoch 318/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 29.0504 - val_loss: 31.1882\n",
      "Epoch 319/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 29.0300 - val_loss: 31.1761\n",
      "Epoch 320/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 29.0069 - val_loss: 31.1632\n",
      "Epoch 321/3000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 28.9859 - val_loss: 31.1509\n",
      "Epoch 322/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 28.9632 - val_loss: 31.1380\n",
      "Epoch 323/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 28.9420 - val_loss: 31.1256\n",
      "Epoch 324/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 28.9196 - val_loss: 31.1128\n",
      "Epoch 325/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 28.8974 - val_loss: 31.0995\n",
      "Epoch 326/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 28.8758 - val_loss: 31.0864\n",
      "Epoch 327/3000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 28.8561 - val_loss: 31.0746\n",
      "Epoch 328/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 28.8324 - val_loss: 31.0619\n",
      "Epoch 329/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 28.8111 - val_loss: 31.0493\n",
      "Epoch 330/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 28.7885 - val_loss: 31.0362\n",
      "Epoch 331/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 28.7667 - val_loss: 31.0231\n",
      "Epoch 332/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 28.7451 - val_loss: 31.0101\n",
      "Epoch 333/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 28.7234 - val_loss: 30.9971\n",
      "Epoch 334/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 28.7017 - val_loss: 30.9839\n",
      "Epoch 335/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 28.6804 - val_loss: 30.9716\n",
      "Epoch 336/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 28.6583 - val_loss: 30.9591\n",
      "Epoch 337/3000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 28.6364 - val_loss: 30.9466\n",
      "Epoch 338/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 28.6146 - val_loss: 30.9335\n",
      "Epoch 339/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 28.5924 - val_loss: 30.9207\n",
      "Epoch 340/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 28.5711 - val_loss: 30.9081\n",
      "Epoch 341/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 28.5487 - val_loss: 30.8952\n",
      "Epoch 342/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 28.5269 - val_loss: 30.8820\n",
      "Epoch 343/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 28.5054 - val_loss: 30.8691\n",
      "Epoch 344/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 28.4840 - val_loss: 30.8567\n",
      "Epoch 345/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 28.4628 - val_loss: 30.8444\n",
      "Epoch 346/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 28.4399 - val_loss: 30.8315\n",
      "Epoch 347/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 29.06 - 0s 41ms/step - loss: 28.4177 - val_loss: 30.8184\n",
      "Epoch 348/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 28.3964 - val_loss: 30.8058\n",
      "Epoch 349/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 28.3739 - val_loss: 30.7926\n",
      "Epoch 350/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 28.3526 - val_loss: 30.7794\n",
      "Epoch 351/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 28.3313 - val_loss: 30.7668\n",
      "Epoch 352/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 28.3096 - val_loss: 30.7542\n",
      "Epoch 353/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 28.2865 - val_loss: 30.7408\n",
      "Epoch 354/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 28.2651 - val_loss: 30.7278\n",
      "Epoch 355/3000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 28.2440 - val_loss: 30.7152\n",
      "Epoch 356/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 28.2223 - val_loss: 30.7028\n",
      "Epoch 357/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 28.1995 - val_loss: 30.6896\n",
      "Epoch 358/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 28.1790 - val_loss: 30.6774\n",
      "Epoch 359/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 28.1562 - val_loss: 30.6646\n",
      "Epoch 360/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 28.1345 - val_loss: 30.6519\n",
      "Epoch 361/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 28.1125 - val_loss: 30.6390\n",
      "Epoch 362/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 28.0908 - val_loss: 30.6263\n",
      "Epoch 363/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 28.0690 - val_loss: 30.6136\n",
      "Epoch 364/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 28.0490 - val_loss: 30.6017\n",
      "Epoch 365/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 28.0253 - val_loss: 30.5888\n",
      "Epoch 366/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 28.0031 - val_loss: 30.5756\n",
      "Epoch 367/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 27.9819 - val_loss: 30.5624\n",
      "Epoch 368/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 27.9597 - val_loss: 30.5493\n",
      "Epoch 369/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 27.9386 - val_loss: 30.5367\n",
      "Epoch 370/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 27.9159 - val_loss: 30.5232\n",
      "Epoch 371/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 27.8947 - val_loss: 30.5106\n",
      "Epoch 372/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 27.8736 - val_loss: 30.4985\n",
      "Epoch 373/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 27.8518 - val_loss: 30.4864\n",
      "Epoch 374/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 27.8297 - val_loss: 30.4741\n",
      "Epoch 375/3000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 27.8086 - val_loss: 30.4621\n",
      "Epoch 376/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 27.7849 - val_loss: 30.4488\n",
      "Epoch 377/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 27.7640 - val_loss: 30.4361\n",
      "Epoch 378/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 27.7420 - val_loss: 30.4232\n",
      "Epoch 379/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 27.7203 - val_loss: 30.4107\n",
      "Epoch 380/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 27.6983 - val_loss: 30.3978\n",
      "Epoch 381/3000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 27.6762 - val_loss: 30.3849\n",
      "Epoch 382/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 29.15 - 0s 41ms/step - loss: 27.6540 - val_loss: 30.3716\n",
      "Epoch 383/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 27.6327 - val_loss: 30.3584\n",
      "Epoch 384/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 27.6115 - val_loss: 30.3459\n",
      "Epoch 385/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 27.5891 - val_loss: 30.3330\n",
      "Epoch 386/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 27.5668 - val_loss: 30.3196\n",
      "Epoch 387/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 27.5456 - val_loss: 30.3069\n",
      "Epoch 388/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 27.5244 - val_loss: 30.2946\n",
      "Epoch 389/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 27.5017 - val_loss: 30.2816\n",
      "Epoch 390/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 27.4804 - val_loss: 30.2691\n",
      "Epoch 391/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 27.4581 - val_loss: 30.2562\n",
      "Epoch 392/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 27.4371 - val_loss: 30.2438\n",
      "Epoch 393/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 27.4158 - val_loss: 30.2319\n",
      "Epoch 394/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 27.3925 - val_loss: 30.2189\n",
      "Epoch 395/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 27.3714 - val_loss: 30.2062\n",
      "Epoch 396/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 27.3503 - val_loss: 30.1942\n",
      "Epoch 397/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 27.3270 - val_loss: 30.1811\n",
      "Epoch 398/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 27.3049 - val_loss: 30.1676\n",
      "Epoch 399/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 27.2842 - val_loss: 30.1552\n",
      "Epoch 400/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 27.2633 - val_loss: 30.1431\n",
      "Epoch 401/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 27.2401 - val_loss: 30.1303\n",
      "Epoch 402/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 27.2195 - val_loss: 30.1181\n",
      "Epoch 403/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 27.1970 - val_loss: 30.1055\n",
      "Epoch 404/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 27.1746 - val_loss: 30.0926\n",
      "Epoch 405/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 27.1523 - val_loss: 30.0792\n",
      "Epoch 406/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 27.1322 - val_loss: 30.0671\n",
      "Epoch 407/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 27.1094 - val_loss: 30.0544\n",
      "Epoch 408/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 27.24 - 0s 32ms/step - loss: 27.0872 - val_loss: 30.0415\n",
      "Epoch 409/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 27.0661 - val_loss: 30.0287\n",
      "Epoch 410/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 27.0438 - val_loss: 30.0159\n",
      "Epoch 411/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 27.0215 - val_loss: 30.0028\n",
      "Epoch 412/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 27.0007 - val_loss: 29.9903\n",
      "Epoch 413/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 26.9786 - val_loss: 29.9772\n",
      "Epoch 414/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 26.9563 - val_loss: 29.9642\n",
      "Epoch 415/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 26.9348 - val_loss: 29.9515\n",
      "Epoch 416/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 26.9128 - val_loss: 29.9386\n",
      "Epoch 417/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 26.8918 - val_loss: 29.9263\n",
      "Epoch 418/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 26.8691 - val_loss: 29.9133\n",
      "Epoch 419/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 26.8474 - val_loss: 29.9005\n",
      "Epoch 420/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 26.8256 - val_loss: 29.8876\n",
      "Epoch 421/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 26.8044 - val_loss: 29.8752\n",
      "Epoch 422/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 26.7813 - val_loss: 29.8617\n",
      "Epoch 423/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 26.7606 - val_loss: 29.8491\n",
      "Epoch 424/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 26.7384 - val_loss: 29.8364\n",
      "Epoch 425/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 26.7169 - val_loss: 29.8238\n",
      "Epoch 426/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 26.6950 - val_loss: 29.8112\n",
      "Epoch 427/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 26.6732 - val_loss: 29.7986\n",
      "Epoch 428/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 26.6522 - val_loss: 29.7864\n",
      "Epoch 429/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 26.6293 - val_loss: 29.7736\n",
      "Epoch 430/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 26.6080 - val_loss: 29.7612\n",
      "Epoch 431/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 26.5855 - val_loss: 29.7483\n",
      "Epoch 432/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 26.5642 - val_loss: 29.7359\n",
      "Epoch 433/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 26.5420 - val_loss: 29.7231\n",
      "Epoch 434/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 26.5200 - val_loss: 29.7103\n",
      "Epoch 435/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 26.4977 - val_loss: 29.6968\n",
      "Epoch 436/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 26.4762 - val_loss: 29.6836\n",
      "Epoch 437/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 26.4548 - val_loss: 29.6707\n",
      "Epoch 438/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 26.4333 - val_loss: 29.6581\n",
      "Epoch 439/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 26.4116 - val_loss: 29.6457\n",
      "Epoch 440/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 26.3892 - val_loss: 29.6329\n",
      "Epoch 441/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 26.3683 - val_loss: 29.6207\n",
      "Epoch 442/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 26.3454 - val_loss: 29.6078\n",
      "Epoch 443/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 26.3234 - val_loss: 29.5947\n",
      "Epoch 444/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 26.3016 - val_loss: 29.5817\n",
      "Epoch 445/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 26.2805 - val_loss: 29.5689\n",
      "Epoch 446/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 26.2586 - val_loss: 29.5563\n",
      "Epoch 447/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 26.2381 - val_loss: 29.5441\n",
      "Epoch 448/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 26.2145 - val_loss: 29.5313\n",
      "Epoch 449/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 26.1925 - val_loss: 29.5182\n",
      "Epoch 450/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 26.1716 - val_loss: 29.5058\n",
      "Epoch 451/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 26.1494 - val_loss: 29.4931\n",
      "Epoch 452/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 26.1278 - val_loss: 29.4807\n",
      "Epoch 453/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 26.1056 - val_loss: 29.4678\n",
      "Epoch 454/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 26.0840 - val_loss: 29.4552\n",
      "Epoch 455/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 26.0622 - val_loss: 29.4426\n",
      "Epoch 456/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 26.0407 - val_loss: 29.4304\n",
      "Epoch 457/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 26.0190 - val_loss: 29.4182\n",
      "Epoch 458/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 25.9971 - val_loss: 29.4059\n",
      "Epoch 459/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 25.9753 - val_loss: 29.3935\n",
      "Epoch 460/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 25.9519 - val_loss: 29.3798\n",
      "Epoch 461/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 25.9312 - val_loss: 29.3670\n",
      "Epoch 462/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 25.9087 - val_loss: 29.3539\n",
      "Epoch 463/3000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 25.8881 - val_loss: 29.3416\n",
      "Epoch 464/3000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 25.8656 - val_loss: 29.3289\n",
      "Epoch 465/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 25.8435 - val_loss: 29.3161\n",
      "Epoch 466/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 25.8216 - val_loss: 29.3033\n",
      "Epoch 467/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 25.8003 - val_loss: 29.2907\n",
      "Epoch 468/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 25.7783 - val_loss: 29.2781\n",
      "Epoch 469/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 25.7558 - val_loss: 29.2646\n",
      "Epoch 470/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 25.7355 - val_loss: 29.2523\n",
      "Epoch 471/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 25.7128 - val_loss: 29.2394\n",
      "Epoch 472/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 25.6910 - val_loss: 29.2267\n",
      "Epoch 473/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 25.6702 - val_loss: 29.2145\n",
      "Epoch 474/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 25.6481 - val_loss: 29.2023\n",
      "Epoch 475/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 25.6249 - val_loss: 29.1885\n",
      "Epoch 476/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 25.6041 - val_loss: 29.1760\n",
      "Epoch 477/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 25.5812 - val_loss: 29.1624\n",
      "Epoch 478/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 25.5603 - val_loss: 29.1495\n",
      "Epoch 479/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 25.5382 - val_loss: 29.1367\n",
      "Epoch 480/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 25.5179 - val_loss: 29.1247\n",
      "Epoch 481/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 25.4939 - val_loss: 29.1113\n",
      "Epoch 482/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 25.4743 - val_loss: 29.0991\n",
      "Epoch 483/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 25.4519 - val_loss: 29.0867\n",
      "Epoch 484/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 25.4290 - val_loss: 29.0737\n",
      "Epoch 485/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 25.4085 - val_loss: 29.0616\n",
      "Epoch 486/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 25.3855 - val_loss: 29.0489\n",
      "Epoch 487/3000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 25.3630 - val_loss: 29.0355\n",
      "Epoch 488/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 25.3419 - val_loss: 29.0228\n",
      "Epoch 489/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 25.3198 - val_loss: 29.0095\n",
      "Epoch 490/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 25.2994 - val_loss: 28.9973\n",
      "Epoch 491/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 25.2767 - val_loss: 28.9845\n",
      "Epoch 492/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 25.2547 - val_loss: 28.9717\n",
      "Epoch 493/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 25.2338 - val_loss: 28.9596\n",
      "Epoch 494/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 25.2118 - val_loss: 28.9473\n",
      "Epoch 495/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 25.1890 - val_loss: 28.9343\n",
      "Epoch 496/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 25.1675 - val_loss: 28.9216\n",
      "Epoch 497/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 25.1457 - val_loss: 28.9087\n",
      "Epoch 498/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 25.1239 - val_loss: 28.8954\n",
      "Epoch 499/3000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 25.1034 - val_loss: 28.8834\n",
      "Epoch 500/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 25.0800 - val_loss: 28.8705\n",
      "Epoch 501/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 25.0582 - val_loss: 28.8576\n",
      "Epoch 502/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 25.0361 - val_loss: 28.8441\n",
      "Epoch 503/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 25.0148 - val_loss: 28.8313\n",
      "Epoch 504/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 24.9938 - val_loss: 28.8187\n",
      "Epoch 505/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 24.9709 - val_loss: 28.8056\n",
      "Epoch 506/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 24.9500 - val_loss: 28.7928\n",
      "Epoch 507/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 24.9280 - val_loss: 28.7800\n",
      "Epoch 508/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 24.9058 - val_loss: 28.7673\n",
      "Epoch 509/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 24.8841 - val_loss: 28.7542\n",
      "Epoch 510/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 24.8617 - val_loss: 28.7410\n",
      "Epoch 511/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 24.8410 - val_loss: 28.7287\n",
      "Epoch 512/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 24.8187 - val_loss: 28.7160\n",
      "Epoch 513/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 24.7962 - val_loss: 28.7026\n",
      "Epoch 514/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 24.7745 - val_loss: 28.6894\n",
      "Epoch 515/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 24.7540 - val_loss: 28.6772\n",
      "Epoch 516/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 24.7313 - val_loss: 28.6645\n",
      "Epoch 517/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 24.7094 - val_loss: 28.6515\n",
      "Epoch 518/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 24.6882 - val_loss: 28.6390\n",
      "Epoch 519/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 24.6666 - val_loss: 28.6267\n",
      "Epoch 520/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 24.6444 - val_loss: 28.6141\n",
      "Epoch 521/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 24.6234 - val_loss: 28.6017\n",
      "Epoch 522/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 24.6006 - val_loss: 28.5889\n",
      "Epoch 523/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 24.5789 - val_loss: 28.5762\n",
      "Epoch 524/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 24.5560 - val_loss: 28.5625\n",
      "Epoch 525/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 24.5353 - val_loss: 28.5496\n",
      "Epoch 526/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 24.5133 - val_loss: 28.5369\n",
      "Epoch 527/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 24.4914 - val_loss: 28.5241\n",
      "Epoch 528/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 24.4702 - val_loss: 28.5115\n",
      "Epoch 529/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 24.4471 - val_loss: 28.4979\n",
      "Epoch 530/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 24.4265 - val_loss: 28.4853\n",
      "Epoch 531/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 24.4056 - val_loss: 28.4734\n",
      "Epoch 532/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 24.3836 - val_loss: 28.4613\n",
      "Epoch 533/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 24.3603 - val_loss: 28.4480\n",
      "Epoch 534/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 24.3390 - val_loss: 28.4354\n",
      "Epoch 535/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 24.3170 - val_loss: 28.4222\n",
      "Epoch 536/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 24.2948 - val_loss: 28.4090\n",
      "Epoch 537/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 24.2753 - val_loss: 28.3972\n",
      "Epoch 538/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 24.2518 - val_loss: 28.3846\n",
      "Epoch 539/3000\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 24.2293 - val_loss: 28.3714\n",
      "Epoch 540/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 24.2080 - val_loss: 28.3584\n",
      "Epoch 541/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 24.1865 - val_loss: 28.3458\n",
      "Epoch 542/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 24.1640 - val_loss: 28.3323\n",
      "Epoch 543/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 24.1438 - val_loss: 28.3199\n",
      "Epoch 544/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 24.1205 - val_loss: 28.3068\n",
      "Epoch 545/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 24.0986 - val_loss: 28.2935\n",
      "Epoch 546/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 24.0767 - val_loss: 28.2803\n",
      "Epoch 547/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 24.0564 - val_loss: 28.2677\n",
      "Epoch 548/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 24.0346 - val_loss: 28.2555\n",
      "Epoch 549/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 24.0125 - val_loss: 28.2427\n",
      "Epoch 550/3000\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 23.9901 - val_loss: 28.2299\n",
      "Epoch 551/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 23.9686 - val_loss: 28.2172\n",
      "Epoch 552/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 23.9478 - val_loss: 28.2049\n",
      "Epoch 553/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 23.9242 - val_loss: 28.1916\n",
      "Epoch 554/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 23.9036 - val_loss: 28.1792\n",
      "Epoch 555/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 23.8814 - val_loss: 28.1666\n",
      "Epoch 556/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 23.8589 - val_loss: 28.1534\n",
      "Epoch 557/3000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 23.8385 - val_loss: 28.1412\n",
      "Epoch 558/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 23.8155 - val_loss: 28.1282\n",
      "Epoch 559/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 23.7940 - val_loss: 28.1154\n",
      "Epoch 560/3000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 23.7722 - val_loss: 28.1025\n",
      "Epoch 561/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 23.7513 - val_loss: 28.0901\n",
      "Epoch 562/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 23.7278 - val_loss: 28.0764\n",
      "Epoch 563/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 22.94 - 0s 48ms/step - loss: 23.7068 - val_loss: 28.0636\n",
      "Epoch 564/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 23.6853 - val_loss: 28.0511\n",
      "Epoch 565/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 23.6629 - val_loss: 28.0381\n",
      "Epoch 566/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 23.6419 - val_loss: 28.0256\n",
      "Epoch 567/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 23.6186 - val_loss: 28.0114\n",
      "Epoch 568/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 23.5984 - val_loss: 27.9990\n",
      "Epoch 569/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 23.5779 - val_loss: 27.9872\n",
      "Epoch 570/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 23.5534 - val_loss: 27.9736\n",
      "Epoch 571/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 23.5319 - val_loss: 27.9603\n",
      "Epoch 572/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 23.5113 - val_loss: 27.9476\n",
      "Epoch 573/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 23.4899 - val_loss: 27.9353\n",
      "Epoch 574/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 23.52 - 0s 35ms/step - loss: 23.4669 - val_loss: 27.9221\n",
      "Epoch 575/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 23.4447 - val_loss: 27.9088\n",
      "Epoch 576/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 23.4237 - val_loss: 27.8958\n",
      "Epoch 577/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 23.4013 - val_loss: 27.8826\n",
      "Epoch 578/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 23.3803 - val_loss: 27.8697\n",
      "Epoch 579/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 23.3585 - val_loss: 27.8569\n",
      "Epoch 580/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 23.3367 - val_loss: 27.8442\n",
      "Epoch 581/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 23.3149 - val_loss: 27.8314\n",
      "Epoch 582/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 23.2934 - val_loss: 27.8188\n",
      "Epoch 583/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 23.2717 - val_loss: 27.8064\n",
      "Epoch 584/3000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 23.2494 - val_loss: 27.7937\n",
      "Epoch 585/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 23.2273 - val_loss: 27.7805\n",
      "Epoch 586/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 23.2060 - val_loss: 27.7679\n",
      "Epoch 587/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 23.1832 - val_loss: 27.7543\n",
      "Epoch 588/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 23.1621 - val_loss: 27.7414\n",
      "Epoch 589/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 23.1405 - val_loss: 27.7286\n",
      "Epoch 590/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 23.1196 - val_loss: 27.7162\n",
      "Epoch 591/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 23.0976 - val_loss: 27.7038\n",
      "Epoch 592/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 23.0747 - val_loss: 27.6907\n",
      "Epoch 593/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 23.0532 - val_loss: 27.6779\n",
      "Epoch 594/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 23.0318 - val_loss: 27.6687\n",
      "Epoch 595/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 23.0098 - val_loss: 27.6611\n",
      "Epoch 596/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 22.9872 - val_loss: 27.6529\n",
      "Epoch 597/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 22.9661 - val_loss: 27.6452\n",
      "Epoch 598/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 22.9454 - val_loss: 27.6383\n",
      "Epoch 599/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 22.9224 - val_loss: 27.6307\n",
      "Epoch 600/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 22.9007 - val_loss: 27.6232\n",
      "Epoch 601/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 22.8793 - val_loss: 27.6158\n",
      "Epoch 602/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 22.8584 - val_loss: 27.6086\n",
      "Epoch 603/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 22.8358 - val_loss: 27.6015\n",
      "Epoch 604/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 22.8137 - val_loss: 27.5932\n",
      "Epoch 605/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 22.7931 - val_loss: 27.5865\n",
      "Epoch 606/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 22.7698 - val_loss: 27.5789\n",
      "Epoch 607/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 22.7492 - val_loss: 27.5723\n",
      "Epoch 608/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 22.7262 - val_loss: 27.5640\n",
      "Epoch 609/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 25.71 - 0s 53ms/step - loss: 22.7040 - val_loss: 27.5551\n",
      "Epoch 610/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 22.6827 - val_loss: 27.5473\n",
      "Epoch 611/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 22.6615 - val_loss: 27.5400\n",
      "Epoch 612/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 22.6402 - val_loss: 27.5328\n",
      "Epoch 613/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 22.6169 - val_loss: 27.5245\n",
      "Epoch 614/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 22.5957 - val_loss: 27.5168\n",
      "Epoch 615/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 22.5742 - val_loss: 27.5091\n",
      "Epoch 616/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 22.5529 - val_loss: 27.5020\n",
      "Epoch 617/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 22.5312 - val_loss: 27.4949\n",
      "Epoch 618/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 22.5087 - val_loss: 27.4869\n",
      "Epoch 619/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 22.4881 - val_loss: 27.4799\n",
      "Epoch 620/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 22.4653 - val_loss: 27.4723\n",
      "Epoch 621/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 22.4428 - val_loss: 27.4642\n",
      "Epoch 622/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 22.4216 - val_loss: 27.4564\n",
      "Epoch 623/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 22.3999 - val_loss: 27.4476\n",
      "Epoch 624/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 22.3785 - val_loss: 27.4407\n",
      "Epoch 625/3000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 22.3565 - val_loss: 27.4330\n",
      "Epoch 626/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 22.3343 - val_loss: 27.4252\n",
      "Epoch 627/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 22.3124 - val_loss: 27.4170\n",
      "Epoch 628/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 22.2916 - val_loss: 27.4103\n",
      "Epoch 629/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 22.2695 - val_loss: 27.4029\n",
      "Epoch 630/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 22.2475 - val_loss: 27.3948\n",
      "Epoch 631/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 22.2249 - val_loss: 27.3865\n",
      "Epoch 632/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 22.2036 - val_loss: 27.3784\n",
      "Epoch 633/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 22.1823 - val_loss: 27.3706\n",
      "Epoch 634/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 22.1612 - val_loss: 27.3634\n",
      "Epoch 635/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 22.1394 - val_loss: 27.3566\n",
      "Epoch 636/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 22.1167 - val_loss: 27.3491\n",
      "Epoch 637/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 22.0950 - val_loss: 27.3412\n",
      "Epoch 638/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 22.0733 - val_loss: 27.3335\n",
      "Epoch 639/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 22.0520 - val_loss: 27.3265\n",
      "Epoch 640/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 22.0296 - val_loss: 27.3189\n",
      "Epoch 641/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 22.0079 - val_loss: 27.3113\n",
      "Epoch 642/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 21.9868 - val_loss: 27.3045\n",
      "Epoch 643/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 21.9639 - val_loss: 27.2963\n",
      "Epoch 644/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 21.9421 - val_loss: 27.2879\n",
      "Epoch 645/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 21.9203 - val_loss: 27.2792\n",
      "Epoch 646/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 21.8995 - val_loss: 27.2718\n",
      "Epoch 647/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 21.8786 - val_loss: 27.2653\n",
      "Epoch 648/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 21.8561 - val_loss: 27.2583\n",
      "Epoch 649/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 21.8335 - val_loss: 27.2506\n",
      "Epoch 650/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 21.8116 - val_loss: 27.2422\n",
      "Epoch 651/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 21.7904 - val_loss: 27.2344\n",
      "Epoch 652/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 21.7678 - val_loss: 27.2260\n",
      "Epoch 653/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 21.7466 - val_loss: 27.2187\n",
      "Epoch 654/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 21.7249 - val_loss: 27.2109\n",
      "Epoch 655/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 21.7034 - val_loss: 27.2037\n",
      "Epoch 656/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 21.6820 - val_loss: 27.1969\n",
      "Epoch 657/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 21.6602 - val_loss: 27.1899\n",
      "Epoch 658/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 21.6379 - val_loss: 27.1823\n",
      "Epoch 659/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 21.6160 - val_loss: 27.1740\n",
      "Epoch 660/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 21.5946 - val_loss: 27.1668\n",
      "Epoch 661/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 21.5724 - val_loss: 27.1589\n",
      "Epoch 662/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 21.5520 - val_loss: 27.1522\n",
      "Epoch 663/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 21.5286 - val_loss: 27.1446\n",
      "Epoch 664/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 21.5070 - val_loss: 27.1369\n",
      "Epoch 665/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 21.4857 - val_loss: 27.1299\n",
      "Epoch 666/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 21.4646 - val_loss: 27.1230\n",
      "Epoch 667/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 21.4415 - val_loss: 27.1150\n",
      "Epoch 668/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 21.4193 - val_loss: 27.1067\n",
      "Epoch 669/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 21.3991 - val_loss: 27.0998\n",
      "Epoch 670/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 21.3754 - val_loss: 27.0907\n",
      "Epoch 671/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 21.3545 - val_loss: 27.0826\n",
      "Epoch 672/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 21.3336 - val_loss: 27.0759\n",
      "Epoch 673/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 21.3117 - val_loss: 27.0691\n",
      "Epoch 674/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 21.2891 - val_loss: 27.0611\n",
      "Epoch 675/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 21.2675 - val_loss: 27.0533\n",
      "Epoch 676/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 21.2461 - val_loss: 27.0461\n",
      "Epoch 677/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 21.2243 - val_loss: 27.0387\n",
      "Epoch 678/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 21.2023 - val_loss: 27.0308\n",
      "Epoch 679/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 21.1815 - val_loss: 27.0242\n",
      "Epoch 680/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 21.1584 - val_loss: 27.0158\n",
      "Epoch 681/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 21.1360 - val_loss: 27.0069\n",
      "Epoch 682/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 21.1162 - val_loss: 26.9999\n",
      "Epoch 683/3000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 21.0942 - val_loss: 26.9923\n",
      "Epoch 684/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 21.0722 - val_loss: 26.9855\n",
      "Epoch 685/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 21.0503 - val_loss: 26.9784\n",
      "Epoch 686/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 21.0279 - val_loss: 26.9706\n",
      "Epoch 687/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 21.0059 - val_loss: 26.9627\n",
      "Epoch 688/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 20.9839 - val_loss: 26.9539\n",
      "Epoch 689/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 20.9626 - val_loss: 26.9461\n",
      "Epoch 690/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 20.9410 - val_loss: 26.9383\n",
      "Epoch 691/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 20.9196 - val_loss: 26.9312\n",
      "Epoch 692/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 20.8973 - val_loss: 26.9233\n",
      "Epoch 693/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 20.8755 - val_loss: 26.9155\n",
      "Epoch 694/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 20.8542 - val_loss: 26.9076\n",
      "Epoch 695/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 20.8329 - val_loss: 26.9005\n",
      "Epoch 696/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 20.8107 - val_loss: 26.8927\n",
      "Epoch 697/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 20.7891 - val_loss: 26.8854\n",
      "Epoch 698/3000\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 20.7685 - val_loss: 26.8784\n",
      "Epoch 699/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 20.7448 - val_loss: 26.8700\n",
      "Epoch 700/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 20.7239 - val_loss: 26.8629\n",
      "Epoch 701/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 20.7017 - val_loss: 26.8550\n",
      "Epoch 702/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 20.6792 - val_loss: 26.8464\n",
      "Epoch 703/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 20.6582 - val_loss: 26.8386\n",
      "Epoch 704/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 20.6374 - val_loss: 26.8323\n",
      "Epoch 705/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 20.6157 - val_loss: 26.8255\n",
      "Epoch 706/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 20.5929 - val_loss: 26.8173\n",
      "Epoch 707/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 20.5714 - val_loss: 26.8101\n",
      "Epoch 708/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 20.5491 - val_loss: 26.8019\n",
      "Epoch 709/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 20.5277 - val_loss: 26.7948\n",
      "Epoch 710/3000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 20.5054 - val_loss: 26.7868\n",
      "Epoch 711/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 20.4840 - val_loss: 26.7788\n",
      "Epoch 712/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 20.4626 - val_loss: 26.7711\n",
      "Epoch 713/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 20.4406 - val_loss: 26.7636\n",
      "Epoch 714/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 20.4184 - val_loss: 26.7550\n",
      "Epoch 715/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 20.3966 - val_loss: 26.7473\n",
      "Epoch 716/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 20.3755 - val_loss: 26.7400\n",
      "Epoch 717/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 20.3544 - val_loss: 26.7327\n",
      "Epoch 718/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 20.3317 - val_loss: 26.7252\n",
      "Epoch 719/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 20.3099 - val_loss: 26.7175\n",
      "Epoch 720/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 20.2876 - val_loss: 26.7095\n",
      "Epoch 721/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 20.2669 - val_loss: 26.7024\n",
      "Epoch 722/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 20.2446 - val_loss: 26.6950\n",
      "Epoch 723/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 20.2226 - val_loss: 26.6871\n",
      "Epoch 724/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 20.2012 - val_loss: 26.6793\n",
      "Epoch 725/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 20.1794 - val_loss: 26.6715\n",
      "Epoch 726/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 20.1576 - val_loss: 26.6636\n",
      "Epoch 727/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 20.1368 - val_loss: 26.6566\n",
      "Epoch 728/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 20.1139 - val_loss: 26.6492\n",
      "Epoch 729/3000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 20.0920 - val_loss: 26.6417\n",
      "Epoch 730/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 20.0699 - val_loss: 26.6334\n",
      "Epoch 731/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 20.0489 - val_loss: 26.6254\n",
      "Epoch 732/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 20.0275 - val_loss: 26.6176\n",
      "Epoch 733/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 20.0059 - val_loss: 26.6109\n",
      "Epoch 734/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 19.9827 - val_loss: 26.6026\n",
      "Epoch 735/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 19.9621 - val_loss: 26.5945\n",
      "Epoch 736/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 19.9407 - val_loss: 26.5879\n",
      "Epoch 737/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 19.9191 - val_loss: 26.5810\n",
      "Epoch 738/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 19.8959 - val_loss: 26.5724\n",
      "Epoch 739/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 19.8749 - val_loss: 26.5652\n",
      "Epoch 740/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 19.8532 - val_loss: 26.5578\n",
      "Epoch 741/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 19.8310 - val_loss: 26.5504\n",
      "Epoch 742/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 19.8099 - val_loss: 26.5435\n",
      "Epoch 743/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 19.7872 - val_loss: 26.5356\n",
      "Epoch 744/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 19.7665 - val_loss: 26.5281\n",
      "Epoch 745/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 19.7440 - val_loss: 26.5207\n",
      "Epoch 746/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 19.7219 - val_loss: 26.5127\n",
      "Epoch 747/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 19.6997 - val_loss: 26.5041\n",
      "Epoch 748/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 19.6794 - val_loss: 26.4974\n",
      "Epoch 749/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 19.6564 - val_loss: 26.4892\n",
      "Epoch 750/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 19.6351 - val_loss: 26.4810\n",
      "Epoch 751/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 19.6139 - val_loss: 26.4739\n",
      "Epoch 752/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 19.5914 - val_loss: 26.4664\n",
      "Epoch 753/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 19.5698 - val_loss: 26.4587\n",
      "Epoch 754/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 19.5484 - val_loss: 26.4516\n",
      "Epoch 755/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 19.5259 - val_loss: 26.4427\n",
      "Epoch 756/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 19.5069 - val_loss: 26.4357\n",
      "Epoch 757/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 19.4854 - val_loss: 26.4269\n",
      "Epoch 758/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 19.4658 - val_loss: 26.4189\n",
      "Epoch 759/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 19.4460 - val_loss: 26.4108\n",
      "Epoch 760/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 19.4244 - val_loss: 26.4020\n",
      "Epoch 761/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 19.4054 - val_loss: 26.3940\n",
      "Epoch 762/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 19.3840 - val_loss: 26.3846\n",
      "Epoch 763/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 19.3655 - val_loss: 26.3767\n",
      "Epoch 764/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 19.3443 - val_loss: 26.3672\n",
      "Epoch 765/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 19.3249 - val_loss: 26.3574\n",
      "Epoch 766/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 19.3045 - val_loss: 26.3480\n",
      "Epoch 767/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 19.2845 - val_loss: 26.3390\n",
      "Epoch 768/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 19.2644 - val_loss: 26.3298\n",
      "Epoch 769/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 19.2464 - val_loss: 26.3222\n",
      "Epoch 770/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 19.2248 - val_loss: 26.3134\n",
      "Epoch 771/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 19.2048 - val_loss: 26.3044\n",
      "Epoch 772/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 19.1858 - val_loss: 26.2957\n",
      "Epoch 773/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 19.1661 - val_loss: 26.2875\n",
      "Epoch 774/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 19.1449 - val_loss: 26.2780\n",
      "Epoch 775/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 19.1256 - val_loss: 26.2693\n",
      "Epoch 776/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 19.1054 - val_loss: 26.2605\n",
      "Epoch 777/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 19.0849 - val_loss: 26.2504\n",
      "Epoch 778/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 19.0656 - val_loss: 26.2416\n",
      "Epoch 779/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 19.0462 - val_loss: 26.2328\n",
      "Epoch 780/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 19.0261 - val_loss: 26.2242\n",
      "Epoch 781/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 19.0057 - val_loss: 26.2144\n",
      "Epoch 782/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 18.9860 - val_loss: 26.2056\n",
      "Epoch 783/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 18.9668 - val_loss: 26.1973\n",
      "Epoch 784/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 18.9469 - val_loss: 26.1891\n",
      "Epoch 785/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 18.9271 - val_loss: 26.1808\n",
      "Epoch 786/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 18.9058 - val_loss: 26.1710\n",
      "Epoch 787/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 18.8862 - val_loss: 26.1614\n",
      "Epoch 788/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 18.8672 - val_loss: 26.1535\n",
      "Epoch 789/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 18.8463 - val_loss: 26.1439\n",
      "Epoch 790/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 18.8266 - val_loss: 26.1344\n",
      "Epoch 791/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 18.8072 - val_loss: 26.1262\n",
      "Epoch 792/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 18.7879 - val_loss: 26.1179\n",
      "Epoch 793/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 18.7672 - val_loss: 26.1096\n",
      "Epoch 794/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 18.7471 - val_loss: 26.1008\n",
      "Epoch 795/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 18.7278 - val_loss: 26.0925\n",
      "Epoch 796/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 18.7070 - val_loss: 26.0828\n",
      "Epoch 797/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 18.6869 - val_loss: 26.0739\n",
      "Epoch 798/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 18.6669 - val_loss: 26.0649\n",
      "Epoch 799/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 18.6479 - val_loss: 26.0565\n",
      "Epoch 800/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 18.6270 - val_loss: 26.0470\n",
      "Epoch 801/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 18.6075 - val_loss: 26.0384\n",
      "Epoch 802/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 18.5869 - val_loss: 26.0290\n",
      "Epoch 803/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 18.5678 - val_loss: 26.0200\n",
      "Epoch 804/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 18.5472 - val_loss: 26.0106\n",
      "Epoch 805/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 18.5270 - val_loss: 26.0011\n",
      "Epoch 806/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 18.5076 - val_loss: 25.9921\n",
      "Epoch 807/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 18.4875 - val_loss: 25.9830\n",
      "Epoch 808/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 18.4671 - val_loss: 25.9731\n",
      "Epoch 809/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 18.4485 - val_loss: 25.9647\n",
      "Epoch 810/3000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 18.4279 - val_loss: 25.9560\n",
      "Epoch 811/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 18.4076 - val_loss: 25.9470\n",
      "Epoch 812/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 21.57 - 0s 41ms/step - loss: 18.3879 - val_loss: 25.9373\n",
      "Epoch 813/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 18.3680 - val_loss: 25.9286\n",
      "Epoch 814/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 18.3489 - val_loss: 25.9206\n",
      "Epoch 815/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 18.3279 - val_loss: 25.9116\n",
      "Epoch 816/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 18.3088 - val_loss: 25.9026\n",
      "Epoch 817/3000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 18.2888 - val_loss: 25.8944\n",
      "Epoch 818/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 18.2676 - val_loss: 25.8845\n",
      "Epoch 819/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 18.2476 - val_loss: 25.8750\n",
      "Epoch 820/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 18.2279 - val_loss: 25.8654\n",
      "Epoch 821/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 18.2083 - val_loss: 25.8567\n",
      "Epoch 822/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 18.1885 - val_loss: 25.8482\n",
      "Epoch 823/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 18.1678 - val_loss: 25.8387\n",
      "Epoch 824/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 18.1482 - val_loss: 25.8297\n",
      "Epoch 825/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 18.1291 - val_loss: 25.8216\n",
      "Epoch 826/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 18.1081 - val_loss: 25.8126\n",
      "Epoch 827/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 18.0885 - val_loss: 25.8038\n",
      "Epoch 828/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 18.0687 - val_loss: 25.7948\n",
      "Epoch 829/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 18.0481 - val_loss: 25.7852\n",
      "Epoch 830/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 18.0281 - val_loss: 25.7760\n",
      "Epoch 831/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 18.0082 - val_loss: 25.7674\n",
      "Epoch 832/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 17.9883 - val_loss: 25.7581\n",
      "Epoch 833/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 17.9681 - val_loss: 25.7487\n",
      "Epoch 834/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 17.9496 - val_loss: 25.7414\n",
      "Epoch 835/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 17.9286 - val_loss: 25.7319\n",
      "Epoch 836/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 17.9097 - val_loss: 25.7224\n",
      "Epoch 837/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 17.8909 - val_loss: 25.7122\n",
      "Epoch 838/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 17.8716 - val_loss: 25.7011\n",
      "Epoch 839/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 17.8540 - val_loss: 25.6917\n",
      "Epoch 840/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 17.8354 - val_loss: 25.6820\n",
      "Epoch 841/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 17.8167 - val_loss: 25.6717\n",
      "Epoch 842/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 17.7981 - val_loss: 25.6611\n",
      "Epoch 843/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 17.7792 - val_loss: 25.6481\n",
      "Epoch 844/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 17.7615 - val_loss: 25.6368\n",
      "Epoch 845/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 17.7423 - val_loss: 25.6259\n",
      "Epoch 846/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 17.7248 - val_loss: 25.6156\n",
      "Epoch 847/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 17.7064 - val_loss: 25.6044\n",
      "Epoch 848/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 17.6877 - val_loss: 25.5935\n",
      "Epoch 849/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 17.6690 - val_loss: 25.5821\n",
      "Epoch 850/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 17.6514 - val_loss: 25.5719\n",
      "Epoch 851/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 17.6327 - val_loss: 25.5608\n",
      "Epoch 852/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 17.6148 - val_loss: 25.5502\n",
      "Epoch 853/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 17.5957 - val_loss: 25.5388\n",
      "Epoch 854/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 17.5774 - val_loss: 25.5278\n",
      "Epoch 855/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 17.5594 - val_loss: 25.5167\n",
      "Epoch 856/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 17.5411 - val_loss: 25.5060\n",
      "Epoch 857/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 17.5230 - val_loss: 25.4954\n",
      "Epoch 858/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 17.5045 - val_loss: 25.4837\n",
      "Epoch 859/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 17.4866 - val_loss: 25.4732\n",
      "Epoch 860/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 17.4680 - val_loss: 25.4616\n",
      "Epoch 861/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 17.4489 - val_loss: 25.4502\n",
      "Epoch 862/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 17.4314 - val_loss: 25.4398\n",
      "Epoch 863/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 17.4126 - val_loss: 25.4285\n",
      "Epoch 864/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 17.3943 - val_loss: 25.4171\n",
      "Epoch 865/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 17.3760 - val_loss: 25.4057\n",
      "Epoch 866/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 17.3578 - val_loss: 25.3944\n",
      "Epoch 867/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 17.3394 - val_loss: 25.3837\n",
      "Epoch 868/3000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 17.3217 - val_loss: 25.3735\n",
      "Epoch 869/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 17.3028 - val_loss: 25.3627\n",
      "Epoch 870/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 17.2847 - val_loss: 25.3517\n",
      "Epoch 871/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 17.2664 - val_loss: 25.3410\n",
      "Epoch 872/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 17.2472 - val_loss: 25.3302\n",
      "Epoch 873/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 17.2292 - val_loss: 25.3190\n",
      "Epoch 874/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 17.2107 - val_loss: 25.3080\n",
      "Epoch 875/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 17.1925 - val_loss: 25.2969\n",
      "Epoch 876/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 17.1740 - val_loss: 25.2850\n",
      "Epoch 877/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 17.1559 - val_loss: 25.2732\n",
      "Epoch 878/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 17.1368 - val_loss: 25.2618\n",
      "Epoch 879/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 17.1189 - val_loss: 25.2502\n",
      "Epoch 880/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 17.1008 - val_loss: 25.2388\n",
      "Epoch 881/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 17.0838 - val_loss: 25.2268\n",
      "Epoch 882/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 17.0658 - val_loss: 25.2137\n",
      "Epoch 883/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 17.0485 - val_loss: 25.2005\n",
      "Epoch 884/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 17.0314 - val_loss: 25.1878\n",
      "Epoch 885/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 17.0137 - val_loss: 25.1738\n",
      "Epoch 886/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 16.9965 - val_loss: 25.1604\n",
      "Epoch 887/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 16.9797 - val_loss: 25.1474\n",
      "Epoch 888/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 16.9625 - val_loss: 25.1333\n",
      "Epoch 889/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 16.9440 - val_loss: 25.1188\n",
      "Epoch 890/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 16.9273 - val_loss: 25.1047\n",
      "Epoch 891/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 16.9089 - val_loss: 25.0899\n",
      "Epoch 892/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 16.8927 - val_loss: 25.0757\n",
      "Epoch 893/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 16.8761 - val_loss: 25.0615\n",
      "Epoch 894/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 16.8585 - val_loss: 25.0466\n",
      "Epoch 895/3000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 16.8416 - val_loss: 25.0297\n",
      "Epoch 896/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 16.8252 - val_loss: 25.0138\n",
      "Epoch 897/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 16.8076 - val_loss: 24.9977\n",
      "Epoch 898/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 16.7926 - val_loss: 24.9806\n",
      "Epoch 899/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 16.7748 - val_loss: 24.9625\n",
      "Epoch 900/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 16.7584 - val_loss: 24.9459\n",
      "Epoch 901/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 16.7409 - val_loss: 24.9288\n",
      "Epoch 902/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 16.7257 - val_loss: 24.9112\n",
      "Epoch 903/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 16.7076 - val_loss: 24.8939\n",
      "Epoch 904/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 16.6917 - val_loss: 24.8747\n",
      "Epoch 905/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 16.6742 - val_loss: 24.8575\n",
      "Epoch 906/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 16.6579 - val_loss: 24.8399\n",
      "Epoch 907/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 16.6410 - val_loss: 24.8224\n",
      "Epoch 908/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 16.6241 - val_loss: 24.8043\n",
      "Epoch 909/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 16.6076 - val_loss: 24.7862\n",
      "Epoch 910/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 16.5909 - val_loss: 24.7693\n",
      "Epoch 911/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 16.5750 - val_loss: 24.7509\n",
      "Epoch 912/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 16.5576 - val_loss: 24.7331\n",
      "Epoch 913/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 16.5415 - val_loss: 24.7160\n",
      "Epoch 914/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 19.57 - 0s 55ms/step - loss: 16.5238 - val_loss: 24.6969\n",
      "Epoch 915/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 16.5074 - val_loss: 24.6793\n",
      "Epoch 916/3000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 16.4908 - val_loss: 24.6619\n",
      "Epoch 917/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 16.4737 - val_loss: 24.6446\n",
      "Epoch 918/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 16.4587 - val_loss: 24.6260\n",
      "Epoch 919/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 16.4399 - val_loss: 24.6084\n",
      "Epoch 920/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 16.4229 - val_loss: 24.5907\n",
      "Epoch 921/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 16.4068 - val_loss: 24.5731\n",
      "Epoch 922/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 16.3904 - val_loss: 24.5556\n",
      "Epoch 923/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 16.3733 - val_loss: 24.5387\n",
      "Epoch 924/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 16.3571 - val_loss: 24.5214\n",
      "Epoch 925/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 16.3395 - val_loss: 24.5035\n",
      "Epoch 926/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 16.3234 - val_loss: 24.4864\n",
      "Epoch 927/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 16.3067 - val_loss: 24.4680\n",
      "Epoch 928/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 16.2895 - val_loss: 24.4498\n",
      "Epoch 929/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 16.2729 - val_loss: 24.4308\n",
      "Epoch 930/3000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 16.2558 - val_loss: 24.4134\n",
      "Epoch 931/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 16.2396 - val_loss: 24.3959\n",
      "Epoch 932/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 16.2225 - val_loss: 24.3776\n",
      "Epoch 933/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 16.2058 - val_loss: 24.3589\n",
      "Epoch 934/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 16.1887 - val_loss: 24.3420\n",
      "Epoch 935/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 16.1716 - val_loss: 24.3241\n",
      "Epoch 936/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 16.1548 - val_loss: 24.3067\n",
      "Epoch 937/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 16.1382 - val_loss: 24.2877\n",
      "Epoch 938/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 16.1222 - val_loss: 24.2703\n",
      "Epoch 939/3000\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 16.1060 - val_loss: 24.2520\n",
      "Epoch 940/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 16.0879 - val_loss: 24.2346\n",
      "Epoch 941/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 16.0713 - val_loss: 24.2169\n",
      "Epoch 942/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 16.0539 - val_loss: 24.2032\n",
      "Epoch 943/3000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 16.0372 - val_loss: 24.1887\n",
      "Epoch 944/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 16.0207 - val_loss: 24.1754\n",
      "Epoch 945/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 16.0048 - val_loss: 24.1610\n",
      "Epoch 946/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 15.9893 - val_loss: 24.1439\n",
      "Epoch 947/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 15.9726 - val_loss: 24.1270\n",
      "Epoch 948/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 15.9573 - val_loss: 24.1091\n",
      "Epoch 949/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 15.9428 - val_loss: 24.0892\n",
      "Epoch 950/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 15.9277 - val_loss: 24.0684\n",
      "Epoch 951/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 15.9131 - val_loss: 24.0481\n",
      "Epoch 952/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 15.8970 - val_loss: 24.0265\n",
      "Epoch 953/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 15.8819 - val_loss: 24.0053\n",
      "Epoch 954/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 15.8676 - val_loss: 23.9818\n",
      "Epoch 955/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 15.8528 - val_loss: 23.9574\n",
      "Epoch 956/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 15.8367 - val_loss: 23.9340\n",
      "Epoch 957/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 15.8220 - val_loss: 23.9098\n",
      "Epoch 958/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 15.8066 - val_loss: 23.8873\n",
      "Epoch 959/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 15.7920 - val_loss: 23.8625\n",
      "Epoch 960/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 15.7759 - val_loss: 23.8381\n",
      "Epoch 961/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 15.7617 - val_loss: 23.8127\n",
      "Epoch 962/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 15.7454 - val_loss: 23.7879\n",
      "Epoch 963/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 15.7305 - val_loss: 23.7633\n",
      "Epoch 964/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 15.7148 - val_loss: 23.7397\n",
      "Epoch 965/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 15.7002 - val_loss: 23.7164\n",
      "Epoch 966/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 15.6847 - val_loss: 23.6925\n",
      "Epoch 967/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 15.6692 - val_loss: 23.6708\n",
      "Epoch 968/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 15.6548 - val_loss: 23.6468\n",
      "Epoch 969/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 16.70 - 0s 48ms/step - loss: 15.6395 - val_loss: 23.6231\n",
      "Epoch 970/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 15.6239 - val_loss: 23.6002\n",
      "Epoch 971/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 15.6079 - val_loss: 23.5780\n",
      "Epoch 972/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 15.5937 - val_loss: 23.5542\n",
      "Epoch 973/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 15.5791 - val_loss: 23.5309\n",
      "Epoch 974/3000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 15.5636 - val_loss: 23.5070\n",
      "Epoch 975/3000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 15.5484 - val_loss: 23.4832\n",
      "Epoch 976/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 15.5323 - val_loss: 23.4617\n",
      "Epoch 977/3000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 15.5172 - val_loss: 23.4386\n",
      "Epoch 978/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 15.5016 - val_loss: 23.4168\n",
      "Epoch 979/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 15.4868 - val_loss: 23.3946\n",
      "Epoch 980/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 15.4714 - val_loss: 23.3727\n",
      "Epoch 981/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 15.4566 - val_loss: 23.3494\n",
      "Epoch 982/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 15.4406 - val_loss: 23.3263\n",
      "Epoch 983/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 15.4266 - val_loss: 23.3036\n",
      "Epoch 984/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 15.4105 - val_loss: 23.2801\n",
      "Epoch 985/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 15.3967 - val_loss: 23.2566\n",
      "Epoch 986/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 15.3795 - val_loss: 23.2354\n",
      "Epoch 987/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 15.3644 - val_loss: 23.2128\n",
      "Epoch 988/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 15.3496 - val_loss: 23.1892\n",
      "Epoch 989/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 15.3336 - val_loss: 23.1663\n",
      "Epoch 990/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 15.3179 - val_loss: 23.1440\n",
      "Epoch 991/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 15.3033 - val_loss: 23.1208\n",
      "Epoch 992/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 15.2876 - val_loss: 23.0979\n",
      "Epoch 993/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 15.2733 - val_loss: 23.0738\n",
      "Epoch 994/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 15.2569 - val_loss: 23.0513\n",
      "Epoch 995/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 15.2414 - val_loss: 23.0288\n",
      "Epoch 996/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 15.2271 - val_loss: 23.0056\n",
      "Epoch 997/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 15.2114 - val_loss: 22.9831\n",
      "Epoch 998/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 15.1958 - val_loss: 22.9607\n",
      "Epoch 999/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 15.1802 - val_loss: 22.9383\n",
      "Epoch 1000/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 15.1647 - val_loss: 22.9160\n",
      "Epoch 1001/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 15.1510 - val_loss: 22.8921\n",
      "Epoch 1002/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 15.1336 - val_loss: 22.8706\n",
      "Epoch 1003/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 15.1182 - val_loss: 22.8486\n",
      "Epoch 1004/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 15.1039 - val_loss: 22.8259\n",
      "Epoch 1005/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 15.0888 - val_loss: 22.8032\n",
      "Epoch 1006/3000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 15.0732 - val_loss: 22.7801\n",
      "Epoch 1007/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 15.0570 - val_loss: 22.7576\n",
      "Epoch 1008/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 15.0427 - val_loss: 22.7351\n",
      "Epoch 1009/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 15.0278 - val_loss: 22.7117\n",
      "Epoch 1010/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 15.0114 - val_loss: 22.6884\n",
      "Epoch 1011/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 14.9964 - val_loss: 22.6645\n",
      "Epoch 1012/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 14.9814 - val_loss: 22.6411\n",
      "Epoch 1013/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 14.9654 - val_loss: 22.6182\n",
      "Epoch 1014/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 14.9499 - val_loss: 22.5958\n",
      "Epoch 1015/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 14.9340 - val_loss: 22.5740\n",
      "Epoch 1016/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 14.9198 - val_loss: 22.5507\n",
      "Epoch 1017/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 14.9042 - val_loss: 22.5279\n",
      "Epoch 1018/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 14.8877 - val_loss: 22.5052\n",
      "Epoch 1019/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 14.8728 - val_loss: 22.4823\n",
      "Epoch 1020/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 14.8573 - val_loss: 22.4599\n",
      "Epoch 1021/3000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 14.8424 - val_loss: 22.4364\n",
      "Epoch 1022/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 14.8269 - val_loss: 22.4129\n",
      "Epoch 1023/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 14.8112 - val_loss: 22.3898\n",
      "Epoch 1024/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 16.67 - 0s 43ms/step - loss: 14.7964 - val_loss: 22.3668\n",
      "Epoch 1025/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 14.7808 - val_loss: 22.3428\n",
      "Epoch 1026/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 14.7648 - val_loss: 22.3196\n",
      "Epoch 1027/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 14.7492 - val_loss: 22.2967\n",
      "Epoch 1028/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 14.7337 - val_loss: 22.2743\n",
      "Epoch 1029/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 14.7189 - val_loss: 22.2528\n",
      "Epoch 1030/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 14.7033 - val_loss: 22.2297\n",
      "Epoch 1031/3000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 14.6873 - val_loss: 22.2066\n",
      "Epoch 1032/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 14.6712 - val_loss: 22.1841\n",
      "Epoch 1033/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 14.6567 - val_loss: 22.1606\n",
      "Epoch 1034/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 14.6414 - val_loss: 22.1369\n",
      "Epoch 1035/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 14.6261 - val_loss: 22.1142\n",
      "Epoch 1036/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 14.6107 - val_loss: 22.0915\n",
      "Epoch 1037/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 14.5936 - val_loss: 22.0696\n",
      "Epoch 1038/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 14.5791 - val_loss: 22.0460\n",
      "Epoch 1039/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 14.5647 - val_loss: 22.0218\n",
      "Epoch 1040/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 14.5483 - val_loss: 21.9979\n",
      "Epoch 1041/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 14.5337 - val_loss: 21.9732\n",
      "Epoch 1042/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 14.5176 - val_loss: 21.9495\n",
      "Epoch 1043/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 14.5028 - val_loss: 21.9250\n",
      "Epoch 1044/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 14.4881 - val_loss: 21.9004\n",
      "Epoch 1045/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 14.4729 - val_loss: 21.8759\n",
      "Epoch 1046/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 14.4580 - val_loss: 21.8509\n",
      "Epoch 1047/3000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 14.4429 - val_loss: 21.8262\n",
      "Epoch 1048/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 14.4277 - val_loss: 21.8007\n",
      "Epoch 1049/3000\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 14.4115 - val_loss: 21.7764\n",
      "Epoch 1050/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 14.3973 - val_loss: 21.7505\n",
      "Epoch 1051/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 14.3811 - val_loss: 21.7260\n",
      "Epoch 1052/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 14.3667 - val_loss: 21.7010\n",
      "Epoch 1053/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 14.3513 - val_loss: 21.6757\n",
      "Epoch 1054/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 14.3373 - val_loss: 21.6504\n",
      "Epoch 1055/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 14.3210 - val_loss: 21.6261\n",
      "Epoch 1056/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 14.3059 - val_loss: 21.6007\n",
      "Epoch 1057/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 14.2901 - val_loss: 21.5771\n",
      "Epoch 1058/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 14.2757 - val_loss: 21.5520\n",
      "Epoch 1059/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 14.2594 - val_loss: 21.5279\n",
      "Epoch 1060/3000\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 14.2454 - val_loss: 21.5025\n",
      "Epoch 1061/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 14.2306 - val_loss: 21.4763\n",
      "Epoch 1062/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 14.2137 - val_loss: 21.4519\n",
      "Epoch 1063/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 14.1981 - val_loss: 21.4275\n",
      "Epoch 1064/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 14.1834 - val_loss: 21.4028\n",
      "Epoch 1065/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 14.1688 - val_loss: 21.3773\n",
      "Epoch 1066/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 14.1539 - val_loss: 21.3516\n",
      "Epoch 1067/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 14.1376 - val_loss: 21.3259\n",
      "Epoch 1068/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 14.1234 - val_loss: 21.2996\n",
      "Epoch 1069/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 14.1069 - val_loss: 21.2752\n",
      "Epoch 1070/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 14.0921 - val_loss: 21.2503\n",
      "Epoch 1071/3000\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 14.0775 - val_loss: 21.2249\n",
      "Epoch 1072/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 14.0612 - val_loss: 21.2000\n",
      "Epoch 1073/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 14.0463 - val_loss: 21.1750\n",
      "Epoch 1074/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 14.0309 - val_loss: 21.1512\n",
      "Epoch 1075/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 14.0160 - val_loss: 21.1260\n",
      "Epoch 1076/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 14.0005 - val_loss: 21.1007\n",
      "Epoch 1077/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 13.9857 - val_loss: 21.0747\n",
      "Epoch 1078/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 13.9699 - val_loss: 21.0494\n",
      "Epoch 1079/3000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 13.9544 - val_loss: 21.0234\n",
      "Epoch 1080/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 13.9393 - val_loss: 20.9984\n",
      "Epoch 1081/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 13.9236 - val_loss: 20.9734\n",
      "Epoch 1082/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 13.9080 - val_loss: 20.9487\n",
      "Epoch 1083/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 13.8929 - val_loss: 20.9237\n",
      "Epoch 1084/3000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 13.8776 - val_loss: 20.8985\n",
      "Epoch 1085/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 13.8624 - val_loss: 20.8736\n",
      "Epoch 1086/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 13.8472 - val_loss: 20.8492\n",
      "Epoch 1087/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 13.8322 - val_loss: 20.8241\n",
      "Epoch 1088/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 14.15 - 0s 45ms/step - loss: 13.8170 - val_loss: 20.7979\n",
      "Epoch 1089/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 13.8018 - val_loss: 20.7725\n",
      "Epoch 1090/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 13.7854 - val_loss: 20.7482\n",
      "Epoch 1091/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 13.7706 - val_loss: 20.7226\n",
      "Epoch 1092/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 13.7558 - val_loss: 20.6968\n",
      "Epoch 1093/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 13.7393 - val_loss: 20.6718\n",
      "Epoch 1094/3000\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 13.7238 - val_loss: 20.6469\n",
      "Epoch 1095/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 13.7090 - val_loss: 20.6214\n",
      "Epoch 1096/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 13.6943 - val_loss: 20.5965\n",
      "Epoch 1097/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 13.6783 - val_loss: 20.5709\n",
      "Epoch 1098/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 13.6626 - val_loss: 20.5453\n",
      "Epoch 1099/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 13.6482 - val_loss: 20.5193\n",
      "Epoch 1100/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 13.6324 - val_loss: 20.4934\n",
      "Epoch 1101/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 13.6167 - val_loss: 20.4684\n",
      "Epoch 1102/3000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 13.6009 - val_loss: 20.4437\n",
      "Epoch 1103/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 13.5858 - val_loss: 20.4192\n",
      "Epoch 1104/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 13.5703 - val_loss: 20.3944\n",
      "Epoch 1105/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 13.5553 - val_loss: 20.3686\n",
      "Epoch 1106/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 13.5390 - val_loss: 20.3437\n",
      "Epoch 1107/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 13.5249 - val_loss: 20.3182\n",
      "Epoch 1108/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 13.5084 - val_loss: 20.2927\n",
      "Epoch 1109/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 13.4932 - val_loss: 20.2688\n",
      "Epoch 1110/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 13.4779 - val_loss: 20.2433\n",
      "Epoch 1111/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 13.4628 - val_loss: 20.2173\n",
      "Epoch 1112/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 13.4474 - val_loss: 20.1919\n",
      "Epoch 1113/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 13.4318 - val_loss: 20.1668\n",
      "Epoch 1114/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 13.4164 - val_loss: 20.1415\n",
      "Epoch 1115/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 13.4014 - val_loss: 20.1153\n",
      "Epoch 1116/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 13.3848 - val_loss: 20.0909\n",
      "Epoch 1117/3000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 13.3697 - val_loss: 20.0653\n",
      "Epoch 1118/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 13.3546 - val_loss: 20.0400\n",
      "Epoch 1119/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 13.3385 - val_loss: 20.0152\n",
      "Epoch 1120/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 13.3245 - val_loss: 19.9897\n",
      "Epoch 1121/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 13.3074 - val_loss: 19.9648\n",
      "Epoch 1122/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 13.2918 - val_loss: 19.9406\n",
      "Epoch 1123/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 13.2767 - val_loss: 19.9164\n",
      "Epoch 1124/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 13.2626 - val_loss: 19.8899\n",
      "Epoch 1125/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 13.2460 - val_loss: 19.8653\n",
      "Epoch 1126/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 13.2313 - val_loss: 19.8393\n",
      "Epoch 1127/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 13.2152 - val_loss: 19.8139\n",
      "Epoch 1128/3000\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 13.1991 - val_loss: 19.7892\n",
      "Epoch 1129/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 13.1839 - val_loss: 19.7640\n",
      "Epoch 1130/3000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 13.1680 - val_loss: 19.7395\n",
      "Epoch 1131/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 13.1526 - val_loss: 19.7154\n",
      "Epoch 1132/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 13.1385 - val_loss: 19.6894\n",
      "Epoch 1133/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 13.1232 - val_loss: 19.6634\n",
      "Epoch 1134/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 13.1067 - val_loss: 19.6386\n",
      "Epoch 1135/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 13.0914 - val_loss: 19.6133\n",
      "Epoch 1136/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 13.0757 - val_loss: 19.5895\n",
      "Epoch 1137/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 13.0603 - val_loss: 19.5640\n",
      "Epoch 1138/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 13.0447 - val_loss: 19.5386\n",
      "Epoch 1139/3000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 13.0287 - val_loss: 19.5135\n",
      "Epoch 1140/3000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 13.0132 - val_loss: 19.4894\n",
      "Epoch 1141/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 12.9997 - val_loss: 19.4626\n",
      "Epoch 1142/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 12.9819 - val_loss: 19.4388\n",
      "Epoch 1143/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 12.9676 - val_loss: 19.4132\n",
      "Epoch 1144/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 12.9521 - val_loss: 19.3877\n",
      "Epoch 1145/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 12.9361 - val_loss: 19.3621\n",
      "Epoch 1146/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 12.9198 - val_loss: 19.3369\n",
      "Epoch 1147/3000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 12.9054 - val_loss: 19.3113\n",
      "Epoch 1148/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 12.8889 - val_loss: 19.2861\n",
      "Epoch 1149/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 12.8743 - val_loss: 19.2612\n",
      "Epoch 1150/3000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 12.8586 - val_loss: 19.2351\n",
      "Epoch 1151/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 12.8426 - val_loss: 19.2104\n",
      "Epoch 1152/3000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 12.8275 - val_loss: 19.1861\n",
      "Epoch 1153/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 12.8114 - val_loss: 19.1623\n",
      "Epoch 1154/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 12.7958 - val_loss: 19.1382\n",
      "Epoch 1155/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 12.7809 - val_loss: 19.1140\n",
      "Epoch 1156/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 12.7643 - val_loss: 19.0895\n",
      "Epoch 1157/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 12.7498 - val_loss: 19.0648\n",
      "Epoch 1158/3000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 12.7343 - val_loss: 19.0402\n",
      "Epoch 1159/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 12.7183 - val_loss: 19.0152\n",
      "Epoch 1160/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 12.7019 - val_loss: 18.9917\n",
      "Epoch 1161/3000\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 12.6875 - val_loss: 18.9678\n",
      "Epoch 1162/3000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 12.6721 - val_loss: 18.9425\n",
      "Epoch 1163/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 12.6572 - val_loss: 18.9181\n",
      "Epoch 1164/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 12.6402 - val_loss: 18.8932\n",
      "Epoch 1165/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 12.6244 - val_loss: 18.8688\n",
      "Epoch 1166/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 12.6089 - val_loss: 18.8439\n",
      "Epoch 1167/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 12.5943 - val_loss: 18.8197\n",
      "Epoch 1168/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 12.5787 - val_loss: 18.7947\n",
      "Epoch 1169/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 12.5620 - val_loss: 18.7697\n",
      "Epoch 1170/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 12.5461 - val_loss: 18.7450\n",
      "Epoch 1171/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 12.5307 - val_loss: 18.7207\n",
      "Epoch 1172/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 12.5151 - val_loss: 18.6965\n",
      "Epoch 1173/3000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 12.4996 - val_loss: 18.6726\n",
      "Epoch 1174/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 12.4839 - val_loss: 18.6485\n",
      "Epoch 1175/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 12.4689 - val_loss: 18.6226\n",
      "Epoch 1176/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 12.4532 - val_loss: 18.5984\n",
      "Epoch 1177/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 12.4372 - val_loss: 18.5741\n",
      "Epoch 1178/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 12.4219 - val_loss: 18.5496\n",
      "Epoch 1179/3000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 12.4065 - val_loss: 18.5252\n",
      "Epoch 1180/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 12.3906 - val_loss: 18.5006\n",
      "Epoch 1181/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 12.3752 - val_loss: 18.4763\n",
      "Epoch 1182/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 12.3596 - val_loss: 18.4513\n",
      "Epoch 1183/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 12.3437 - val_loss: 18.4268\n",
      "Epoch 1184/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 12.3273 - val_loss: 18.4030\n",
      "Epoch 1185/3000\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 12.3123 - val_loss: 18.3788\n",
      "Epoch 1186/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 12.2960 - val_loss: 18.3541\n",
      "Epoch 1187/3000\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 12.2821 - val_loss: 18.3285\n",
      "Epoch 1188/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 12.2655 - val_loss: 18.3033\n",
      "Epoch 1189/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 12.2493 - val_loss: 18.2778\n",
      "Epoch 1190/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 12.2341 - val_loss: 18.2517\n",
      "Epoch 1191/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 12.2173 - val_loss: 18.2271\n",
      "Epoch 1192/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 12.2029 - val_loss: 18.2028\n",
      "Epoch 1193/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 12.1877 - val_loss: 18.1776\n",
      "Epoch 1194/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 12.1710 - val_loss: 18.1534\n",
      "Epoch 1195/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 12.1552 - val_loss: 18.1300\n",
      "Epoch 1196/3000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 12.1406 - val_loss: 18.1060\n",
      "Epoch 1197/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 12.1239 - val_loss: 18.0815\n",
      "Epoch 1198/3000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 12.1092 - val_loss: 18.0561\n",
      "Epoch 1199/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 12.0933 - val_loss: 18.0302\n",
      "Epoch 1200/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 12.0764 - val_loss: 18.0061\n",
      "Epoch 1201/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 12.0615 - val_loss: 17.9813\n",
      "Epoch 1202/3000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 12.0449 - val_loss: 17.9569\n",
      "Epoch 1203/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 12.0298 - val_loss: 17.9322\n",
      "Epoch 1204/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 12.0140 - val_loss: 17.9069\n",
      "Epoch 1205/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 11.9984 - val_loss: 17.8807\n",
      "Epoch 1206/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 11.9826 - val_loss: 17.8554\n",
      "Epoch 1207/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 11.9667 - val_loss: 17.8296\n",
      "Epoch 1208/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 15.65 - 0s 50ms/step - loss: 11.9524 - val_loss: 17.8032\n",
      "Epoch 1209/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 11.9352 - val_loss: 17.7784\n",
      "Epoch 1210/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 11.9192 - val_loss: 17.7547\n",
      "Epoch 1211/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 11.9040 - val_loss: 17.7304\n",
      "Epoch 1212/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 11.8878 - val_loss: 17.7070\n",
      "Epoch 1213/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 11.8733 - val_loss: 17.6826\n",
      "Epoch 1214/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 11.8572 - val_loss: 17.6588\n",
      "Epoch 1215/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 11.8410 - val_loss: 17.6342\n",
      "Epoch 1216/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 11.8249 - val_loss: 17.6108\n",
      "Epoch 1217/3000\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 11.8099 - val_loss: 17.5855\n",
      "Epoch 1218/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 11.7947 - val_loss: 17.5595\n",
      "Epoch 1219/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 11.7783 - val_loss: 17.5352\n",
      "Epoch 1220/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 11.7624 - val_loss: 17.5098\n",
      "Epoch 1221/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 11.7468 - val_loss: 17.4839\n",
      "Epoch 1222/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 11.7309 - val_loss: 17.4579\n",
      "Epoch 1223/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 11.7154 - val_loss: 17.4331\n",
      "Epoch 1224/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 11.6986 - val_loss: 17.4081\n",
      "Epoch 1225/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 11.6834 - val_loss: 17.3825\n",
      "Epoch 1226/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 11.6672 - val_loss: 17.3583\n",
      "Epoch 1227/3000\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 11.6522 - val_loss: 17.3329\n",
      "Epoch 1228/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 11.6366 - val_loss: 17.3067\n",
      "Epoch 1229/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 11.6202 - val_loss: 17.2811\n",
      "Epoch 1230/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 11.6032 - val_loss: 17.2566\n",
      "Epoch 1231/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 11.5879 - val_loss: 17.2319\n",
      "Epoch 1232/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 11.5724 - val_loss: 17.2074\n",
      "Epoch 1233/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 11.5580 - val_loss: 17.1834\n",
      "Epoch 1234/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 11.5412 - val_loss: 17.1591\n",
      "Epoch 1235/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 11.5246 - val_loss: 17.1347\n",
      "Epoch 1236/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 11.5095 - val_loss: 17.1108\n",
      "Epoch 1237/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 11.4944 - val_loss: 17.0854\n",
      "Epoch 1238/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 11.4776 - val_loss: 17.0608\n",
      "Epoch 1239/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 11.4622 - val_loss: 17.0356\n",
      "Epoch 1240/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 11.4468 - val_loss: 17.0095\n",
      "Epoch 1241/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 11.4303 - val_loss: 16.9836\n",
      "Epoch 1242/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 11.4158 - val_loss: 16.9576\n",
      "Epoch 1243/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 11.3991 - val_loss: 16.9317\n",
      "Epoch 1244/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 11.3827 - val_loss: 16.9074\n",
      "Epoch 1245/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 11.3664 - val_loss: 16.8821\n",
      "Epoch 1246/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 11.3510 - val_loss: 16.8574\n",
      "Epoch 1247/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 11.3351 - val_loss: 16.8316\n",
      "Epoch 1248/3000\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 11.3196 - val_loss: 16.8061\n",
      "Epoch 1249/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 11.3037 - val_loss: 16.7809\n",
      "Epoch 1250/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 11.2878 - val_loss: 16.7560\n",
      "Epoch 1251/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 11.2722 - val_loss: 16.7310\n",
      "Epoch 1252/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 11.2555 - val_loss: 16.7058\n",
      "Epoch 1253/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 11.2394 - val_loss: 16.6809\n",
      "Epoch 1254/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 11.2237 - val_loss: 16.6562\n",
      "Epoch 1255/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 11.2084 - val_loss: 16.6309\n",
      "Epoch 1256/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 11.1920 - val_loss: 16.6055\n",
      "Epoch 1257/3000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 11.1764 - val_loss: 16.5813\n",
      "Epoch 1258/3000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 11.1612 - val_loss: 16.5566\n",
      "Epoch 1259/3000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 11.1450 - val_loss: 16.5317\n",
      "Epoch 1260/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 11.1286 - val_loss: 16.5061\n",
      "Epoch 1261/3000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 11.1126 - val_loss: 16.4808\n",
      "Epoch 1262/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 11.0987 - val_loss: 16.4545\n",
      "Epoch 1263/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 11.0829 - val_loss: 16.4290\n",
      "Epoch 1264/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 11.0683 - val_loss: 16.4032\n",
      "Epoch 1265/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 11.0521 - val_loss: 16.3784\n",
      "Epoch 1266/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 11.0379 - val_loss: 16.3535\n",
      "Epoch 1267/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 11.0215 - val_loss: 16.3306\n",
      "Epoch 1268/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 11.0065 - val_loss: 16.3076\n",
      "Epoch 1269/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 10.9912 - val_loss: 16.2840\n",
      "Epoch 1270/3000\n",
      "2/2 [==============================] - 0s 149ms/step - loss: 10.9760 - val_loss: 16.2599\n",
      "Epoch 1271/3000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 10.9609 - val_loss: 16.2365\n",
      "Epoch 1272/3000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 10.9463 - val_loss: 16.2115\n",
      "Epoch 1273/3000\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 10.9313 - val_loss: 16.1865\n",
      "Epoch 1274/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 10.9163 - val_loss: 16.1602\n",
      "Epoch 1275/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 10.9011 - val_loss: 16.1356\n",
      "Epoch 1276/3000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 10.8858 - val_loss: 16.1098\n",
      "Epoch 1277/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 10.8700 - val_loss: 16.0849\n",
      "Epoch 1278/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10.8542 - val_loss: 16.0602\n",
      "Epoch 1279/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 10.8404 - val_loss: 16.0354\n",
      "Epoch 1280/3000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 10.8238 - val_loss: 16.0114\n",
      "Epoch 1281/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 10.8093 - val_loss: 15.9876\n",
      "Epoch 1282/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 10.7950 - val_loss: 15.9637\n",
      "Epoch 1283/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 10.7783 - val_loss: 15.9415\n",
      "Epoch 1284/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 10.7639 - val_loss: 15.9192\n",
      "Epoch 1285/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10.7488 - val_loss: 15.8958\n",
      "Epoch 1286/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 10.7335 - val_loss: 15.8717\n",
      "Epoch 1287/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 10.7192 - val_loss: 15.8474\n",
      "Epoch 1288/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 10.7034 - val_loss: 15.8214\n",
      "Epoch 1289/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 10.6889 - val_loss: 15.7951\n",
      "Epoch 1290/3000\n",
      "2/2 [==============================] - 0s 227ms/step - loss: 10.6726 - val_loss: 15.7708\n",
      "Epoch 1291/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 10.6581 - val_loss: 15.7455\n",
      "Epoch 1292/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 10.6432 - val_loss: 15.7207\n",
      "Epoch 1293/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 10.6272 - val_loss: 15.6957\n",
      "Epoch 1294/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 10.6117 - val_loss: 15.6708\n",
      "Epoch 1295/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 10.5983 - val_loss: 15.6454\n",
      "Epoch 1296/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 10.5816 - val_loss: 15.6207\n",
      "Epoch 1297/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 10.5679 - val_loss: 15.5952\n",
      "Epoch 1298/3000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 10.5512 - val_loss: 15.5718\n",
      "Epoch 1299/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 10.5356 - val_loss: 15.5490\n",
      "Epoch 1300/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 10.5200 - val_loss: 15.5248\n",
      "Epoch 1301/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 10.5067 - val_loss: 15.4996\n",
      "Epoch 1302/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 10.4899 - val_loss: 15.4770\n",
      "Epoch 1303/3000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 10.4755 - val_loss: 15.4521\n",
      "Epoch 1304/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 10.4602 - val_loss: 15.4278\n",
      "Epoch 1305/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 10.4437 - val_loss: 15.4029\n",
      "Epoch 1306/3000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 10.4295 - val_loss: 15.3773\n",
      "Epoch 1307/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10.4142 - val_loss: 15.3518\n",
      "Epoch 1308/3000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 10.3983 - val_loss: 15.3270\n",
      "Epoch 1309/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10.3833 - val_loss: 15.3030\n",
      "Epoch 1310/3000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 10.3681 - val_loss: 15.2781\n",
      "Epoch 1311/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 10.3538 - val_loss: 15.2520\n",
      "Epoch 1312/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 10.3389 - val_loss: 15.2260\n",
      "Epoch 1313/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 10.3231 - val_loss: 15.2014\n",
      "Epoch 1314/3000\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 10.3073 - val_loss: 15.1774\n",
      "Epoch 1315/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 10.2921 - val_loss: 15.1536\n",
      "Epoch 1316/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 10.2769 - val_loss: 15.1298\n",
      "Epoch 1317/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 10.2619 - val_loss: 15.1055\n",
      "Epoch 1318/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 10.2466 - val_loss: 15.0815\n",
      "Epoch 1319/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10.2309 - val_loss: 15.0576\n",
      "Epoch 1320/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 10.2158 - val_loss: 15.0332\n",
      "Epoch 1321/3000\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 10.2009 - val_loss: 15.0079\n",
      "Epoch 1322/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 10.1847 - val_loss: 14.9827\n",
      "Epoch 1323/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 10.1699 - val_loss: 14.9564\n",
      "Epoch 1324/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 10.1542 - val_loss: 14.9306\n",
      "Epoch 1325/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 10.1390 - val_loss: 14.9053\n",
      "Epoch 1326/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 10.1241 - val_loss: 14.8812\n",
      "Epoch 1327/3000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 10.1084 - val_loss: 14.8559\n",
      "Epoch 1328/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 10.0936 - val_loss: 14.8303\n",
      "Epoch 1329/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 10.0781 - val_loss: 14.8053\n",
      "Epoch 1330/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 10.0627 - val_loss: 14.7810\n",
      "Epoch 1331/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 10.0477 - val_loss: 14.7562\n",
      "Epoch 1332/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 10.0322 - val_loss: 14.7321\n",
      "Epoch 1333/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 10.0170 - val_loss: 14.7080\n",
      "Epoch 1334/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 10.0017 - val_loss: 14.6844\n",
      "Epoch 1335/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 9.9860 - val_loss: 14.6609\n",
      "Epoch 1336/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9.9706 - val_loss: 14.6371\n",
      "Epoch 1337/3000\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 9.9555 - val_loss: 14.6131\n",
      "Epoch 1338/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 9.9391 - val_loss: 14.5891\n",
      "Epoch 1339/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 9.9244 - val_loss: 14.5649\n",
      "Epoch 1340/3000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 9.9089 - val_loss: 14.5407\n",
      "Epoch 1341/3000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 9.8952 - val_loss: 14.5143\n",
      "Epoch 1342/3000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 9.8789 - val_loss: 14.4885\n",
      "Epoch 1343/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9.8639 - val_loss: 14.4638\n",
      "Epoch 1344/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 9.8483 - val_loss: 14.4382\n",
      "Epoch 1345/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 9.8333 - val_loss: 14.4128\n",
      "Epoch 1346/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 9.8173 - val_loss: 14.3867\n",
      "Epoch 1347/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 9.8011 - val_loss: 14.3612\n",
      "Epoch 1348/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 9.7864 - val_loss: 14.3348\n",
      "Epoch 1349/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 9.7712 - val_loss: 14.3100\n",
      "Epoch 1350/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 9.7555 - val_loss: 14.2858\n",
      "Epoch 1351/3000\n",
      "2/2 [==============================] - 0s 216ms/step - loss: 9.7403 - val_loss: 14.2619\n",
      "Epoch 1352/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 9.7245 - val_loss: 14.2377\n",
      "Epoch 1353/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 9.7094 - val_loss: 14.2136\n",
      "Epoch 1354/3000\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 9.6942 - val_loss: 14.1896\n",
      "Epoch 1355/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 9.6793 - val_loss: 14.1639\n",
      "Epoch 1356/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 9.6625 - val_loss: 14.1397\n",
      "Epoch 1357/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 9.6478 - val_loss: 14.1159\n",
      "Epoch 1358/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 9.6327 - val_loss: 14.0913\n",
      "Epoch 1359/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 9.6186 - val_loss: 14.0657\n",
      "Epoch 1360/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 9.6018 - val_loss: 14.0388\n",
      "Epoch 1361/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9.5858 - val_loss: 14.0141\n",
      "Epoch 1362/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 9.5710 - val_loss: 13.9883\n",
      "Epoch 1363/3000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 9.5556 - val_loss: 13.9634\n",
      "Epoch 1364/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 9.5414 - val_loss: 13.9374\n",
      "Epoch 1365/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 9.5246 - val_loss: 13.9129\n",
      "Epoch 1366/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 9.5094 - val_loss: 13.8888\n",
      "Epoch 1367/3000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 9.4945 - val_loss: 13.8649\n",
      "Epoch 1368/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9.4789 - val_loss: 13.8412\n",
      "Epoch 1369/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9.4626 - val_loss: 13.8187\n",
      "Epoch 1370/3000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 9.4490 - val_loss: 13.7942\n",
      "Epoch 1371/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 9.4333 - val_loss: 13.7696\n",
      "Epoch 1372/3000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 9.4185 - val_loss: 13.7438\n",
      "Epoch 1373/3000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 9.4050 - val_loss: 13.7163\n",
      "Epoch 1374/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 9.3887 - val_loss: 13.6897\n",
      "Epoch 1375/3000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 9.3723 - val_loss: 13.6652\n",
      "Epoch 1376/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 9.3584 - val_loss: 13.6403\n",
      "Epoch 1377/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 9.3433 - val_loss: 13.6163\n",
      "Epoch 1378/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 9.3282 - val_loss: 13.5921\n",
      "Epoch 1379/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 9.3138 - val_loss: 13.5673\n",
      "Epoch 1380/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 9.2981 - val_loss: 13.5432\n",
      "Epoch 1381/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 9.2845 - val_loss: 13.5177\n",
      "Epoch 1382/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 9.2690 - val_loss: 13.4936\n",
      "Epoch 1383/3000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 9.2542 - val_loss: 13.4699\n",
      "Epoch 1384/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 9.2395 - val_loss: 13.4450\n",
      "Epoch 1385/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 9.2247 - val_loss: 13.4202\n",
      "Epoch 1386/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 9.2096 - val_loss: 13.3955\n",
      "Epoch 1387/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 9.1946 - val_loss: 13.3711\n",
      "Epoch 1388/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 9.1805 - val_loss: 13.3468\n",
      "Epoch 1389/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9.1665 - val_loss: 13.3224\n",
      "Epoch 1390/3000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 9.1527 - val_loss: 13.2967\n",
      "Epoch 1391/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 9.1375 - val_loss: 13.2712\n",
      "Epoch 1392/3000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 9.1226 - val_loss: 13.2465\n",
      "Epoch 1393/3000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 9.1086 - val_loss: 13.2220\n",
      "Epoch 1394/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 9.0941 - val_loss: 13.1975\n",
      "Epoch 1395/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 9.0792 - val_loss: 13.1735\n",
      "Epoch 1396/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 9.0658 - val_loss: 13.1482\n",
      "Epoch 1397/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 9.0512 - val_loss: 13.1230\n",
      "Epoch 1398/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 9.0384 - val_loss: 13.0983\n",
      "Epoch 1399/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 9.0237 - val_loss: 13.0728\n",
      "Epoch 1400/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 9.0098 - val_loss: 13.0470\n",
      "Epoch 1401/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 8.9957 - val_loss: 13.0217\n",
      "Epoch 1402/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 8.9804 - val_loss: 12.9974\n",
      "Epoch 1403/3000\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 8.9669 - val_loss: 12.9739\n",
      "Epoch 1404/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 8.9539 - val_loss: 12.9483\n",
      "Epoch 1405/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 8.9393 - val_loss: 12.9225\n",
      "Epoch 1406/3000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 8.9252 - val_loss: 12.8971\n",
      "Epoch 1407/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 8.9116 - val_loss: 12.8715\n",
      "Epoch 1408/3000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 8.8985 - val_loss: 12.8451\n",
      "Epoch 1409/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 8.8836 - val_loss: 12.8196\n",
      "Epoch 1410/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 8.8706 - val_loss: 12.7943\n",
      "Epoch 1411/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 8.8558 - val_loss: 12.7687\n",
      "Epoch 1412/3000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 8.8431 - val_loss: 12.7428\n",
      "Epoch 1413/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 8.8288 - val_loss: 12.7179\n",
      "Epoch 1414/3000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 8.8147 - val_loss: 12.6961\n",
      "Epoch 1415/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 8.8010 - val_loss: 12.6738\n",
      "Epoch 1416/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 8.7877 - val_loss: 12.6514\n",
      "Epoch 1417/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 8.7736 - val_loss: 12.6300\n",
      "Epoch 1418/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 8.7586 - val_loss: 12.6088\n",
      "Epoch 1419/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 8.7462 - val_loss: 12.5866\n",
      "Epoch 1420/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 8.7320 - val_loss: 12.5644\n",
      "Epoch 1421/3000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 8.7184 - val_loss: 12.5419\n",
      "Epoch 1422/3000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 8.7040 - val_loss: 12.5199\n",
      "Epoch 1423/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 8.6893 - val_loss: 12.4982\n",
      "Epoch 1424/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 8.6756 - val_loss: 12.4760\n",
      "Epoch 1425/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 8.6628 - val_loss: 12.4533\n",
      "Epoch 1426/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 8.6490 - val_loss: 12.4316\n",
      "Epoch 1427/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 8.6349 - val_loss: 12.4089\n",
      "Epoch 1428/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 8.6202 - val_loss: 12.3873\n",
      "Epoch 1429/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 8.6063 - val_loss: 12.3655\n",
      "Epoch 1430/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 8.5931 - val_loss: 12.3437\n",
      "Epoch 1431/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 8.5792 - val_loss: 12.3218\n",
      "Epoch 1432/3000\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 8.5651 - val_loss: 12.2988\n",
      "Epoch 1433/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 8.5509 - val_loss: 12.2765\n",
      "Epoch 1434/3000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 8.5374 - val_loss: 12.2538\n",
      "Epoch 1435/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 8.5230 - val_loss: 12.2322\n",
      "Epoch 1436/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 8.5097 - val_loss: 12.2091\n",
      "Epoch 1437/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 8.4946 - val_loss: 12.1873\n",
      "Epoch 1438/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 8.4805 - val_loss: 12.1659\n",
      "Epoch 1439/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 8.4672 - val_loss: 12.1440\n",
      "Epoch 1440/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 8.4548 - val_loss: 12.1214\n",
      "Epoch 1441/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 8.4383 - val_loss: 12.1003\n",
      "Epoch 1442/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 8.4248 - val_loss: 12.0785\n",
      "Epoch 1443/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 8.4116 - val_loss: 12.0562\n",
      "Epoch 1444/3000\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 8.3989 - val_loss: 12.0332\n",
      "Epoch 1445/3000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 8.3828 - val_loss: 12.0124\n",
      "Epoch 1446/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 8.3695 - val_loss: 11.9902\n",
      "Epoch 1447/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 8.3564 - val_loss: 11.9671\n",
      "Epoch 1448/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 8.3413 - val_loss: 11.9453\n",
      "Epoch 1449/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 8.3283 - val_loss: 11.9231\n",
      "Epoch 1450/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 8.3145 - val_loss: 11.9002\n",
      "Epoch 1451/3000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 8.3010 - val_loss: 11.8784\n",
      "Epoch 1452/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 8.2869 - val_loss: 11.8562\n",
      "Epoch 1453/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 8.2748 - val_loss: 11.8334\n",
      "Epoch 1454/3000\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 8.2614 - val_loss: 11.8102\n",
      "Epoch 1455/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 8.2470 - val_loss: 11.7882\n",
      "Epoch 1456/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 8.2331 - val_loss: 11.7661\n",
      "Epoch 1457/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 7.696 - 0s 43ms/step - loss: 8.2203 - val_loss: 11.7433\n",
      "Epoch 1458/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 8.2079 - val_loss: 11.7198\n",
      "Epoch 1459/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 8.1943 - val_loss: 11.6967\n",
      "Epoch 1460/3000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 8.1823 - val_loss: 11.6728\n",
      "Epoch 1461/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 8.1676 - val_loss: 11.6504\n",
      "Epoch 1462/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 8.1568 - val_loss: 11.6271\n",
      "Epoch 1463/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 8.1428 - val_loss: 11.6050\n",
      "Epoch 1464/3000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 8.1311 - val_loss: 11.5825\n",
      "Epoch 1465/3000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 8.1182 - val_loss: 11.5603\n",
      "Epoch 1466/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 8.1067 - val_loss: 11.5382\n",
      "Epoch 1467/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 8.0926 - val_loss: 11.5163\n",
      "Epoch 1468/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 8.0811 - val_loss: 11.4944\n",
      "Epoch 1469/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 8.0695 - val_loss: 11.4716\n",
      "Epoch 1470/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 8.0565 - val_loss: 11.4492\n",
      "Epoch 1471/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 8.0442 - val_loss: 11.4269\n",
      "Epoch 1472/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 8.0323 - val_loss: 11.4039\n",
      "Epoch 1473/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 8.0205 - val_loss: 11.3806\n",
      "Epoch 1474/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 8.0092 - val_loss: 11.3565\n",
      "Epoch 1475/3000\n",
      "2/2 [==============================] - 0s 138ms/step - loss: 7.9952 - val_loss: 11.3335\n",
      "Epoch 1476/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 7.9834 - val_loss: 11.3102\n",
      "Epoch 1477/3000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 7.9710 - val_loss: 11.2871\n",
      "Epoch 1478/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 7.9572 - val_loss: 11.2648\n",
      "Epoch 1479/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 7.9469 - val_loss: 11.2418\n",
      "Epoch 1480/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 7.9346 - val_loss: 11.2188\n",
      "Epoch 1481/3000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 7.9196 - val_loss: 11.1977\n",
      "Epoch 1482/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 7.9105 - val_loss: 11.1741\n",
      "Epoch 1483/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 7.8957 - val_loss: 11.1518\n",
      "Epoch 1484/3000\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 7.8833 - val_loss: 11.1295\n",
      "Epoch 1485/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 7.8720 - val_loss: 11.1067\n",
      "Epoch 1486/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 7.8587 - val_loss: 11.0845\n",
      "Epoch 1487/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 7.8467 - val_loss: 11.0618\n",
      "Epoch 1488/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 7.8341 - val_loss: 11.0391\n",
      "Epoch 1489/3000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 7.8226 - val_loss: 11.0162\n",
      "Epoch 1490/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 7.8092 - val_loss: 10.9936\n",
      "Epoch 1491/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 7.7979 - val_loss: 10.9708\n",
      "Epoch 1492/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 7.7848 - val_loss: 10.9478\n",
      "Epoch 1493/3000\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 7.7719 - val_loss: 10.9251\n",
      "Epoch 1494/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 7.7610 - val_loss: 10.9014\n",
      "Epoch 1495/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 7.7487 - val_loss: 10.8780\n",
      "Epoch 1496/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 7.7352 - val_loss: 10.8556\n",
      "Epoch 1497/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 7.7233 - val_loss: 10.8328\n",
      "Epoch 1498/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 7.7107 - val_loss: 10.8096\n",
      "Epoch 1499/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 7.6984 - val_loss: 10.7867\n",
      "Epoch 1500/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 7.6847 - val_loss: 10.7646\n",
      "Epoch 1501/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 7.6732 - val_loss: 10.7416\n",
      "Epoch 1502/3000\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 7.6618 - val_loss: 10.7183\n",
      "Epoch 1503/3000\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 7.6485 - val_loss: 10.6957\n",
      "Epoch 1504/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 7.6357 - val_loss: 10.6734\n",
      "Epoch 1505/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 7.6229 - val_loss: 10.6510\n",
      "Epoch 1506/3000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 7.6118 - val_loss: 10.6274\n",
      "Epoch 1507/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 7.5988 - val_loss: 10.6048\n",
      "Epoch 1508/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 7.5853 - val_loss: 10.5823\n",
      "Epoch 1509/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 7.5737 - val_loss: 10.5592\n",
      "Epoch 1510/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 7.5617 - val_loss: 10.5357\n",
      "Epoch 1511/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 7.5486 - val_loss: 10.5125\n",
      "Epoch 1512/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 7.5357 - val_loss: 10.4899\n",
      "Epoch 1513/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 7.5231 - val_loss: 10.4677\n",
      "Epoch 1514/3000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 7.5116 - val_loss: 10.4456\n",
      "Epoch 1515/3000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 7.4985 - val_loss: 10.4243\n",
      "Epoch 1516/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 7.4872 - val_loss: 10.4020\n",
      "Epoch 1517/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 7.4739 - val_loss: 10.3807\n",
      "Epoch 1518/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 7.4611 - val_loss: 10.3595\n",
      "Epoch 1519/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 7.4480 - val_loss: 10.3386\n",
      "Epoch 1520/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 7.4377 - val_loss: 10.3166\n",
      "Epoch 1521/3000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 7.4239 - val_loss: 10.2958\n",
      "Epoch 1522/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 7.4132 - val_loss: 10.2740\n",
      "Epoch 1523/3000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 7.3999 - val_loss: 10.2528\n",
      "Epoch 1524/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 7.3869 - val_loss: 10.2321\n",
      "Epoch 1525/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 7.3752 - val_loss: 10.2107\n",
      "Epoch 1526/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 7.3627 - val_loss: 10.1894\n",
      "Epoch 1527/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 7.3513 - val_loss: 10.1672\n",
      "Epoch 1528/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 7.3396 - val_loss: 10.1452\n",
      "Epoch 1529/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 7.3255 - val_loss: 10.1244\n",
      "Epoch 1530/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 7.3133 - val_loss: 10.1029\n",
      "Epoch 1531/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 7.3008 - val_loss: 10.0815\n",
      "Epoch 1532/3000\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 7.2905 - val_loss: 10.0590\n",
      "Epoch 1533/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 7.2755 - val_loss: 10.0385\n",
      "Epoch 1534/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 7.2650 - val_loss: 10.0168\n",
      "Epoch 1535/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 7.2548 - val_loss: 9.9943\n",
      "Epoch 1536/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 7.2420 - val_loss: 9.9735\n",
      "Epoch 1537/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 7.2320 - val_loss: 9.9510\n",
      "Epoch 1538/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 7.2208 - val_loss: 9.9290\n",
      "Epoch 1539/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 7.2084 - val_loss: 9.9080\n",
      "Epoch 1540/3000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 7.1969 - val_loss: 9.8874\n",
      "Epoch 1541/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 7.1860 - val_loss: 9.8659\n",
      "Epoch 1542/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 7.1755 - val_loss: 9.8436\n",
      "Epoch 1543/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 7.1641 - val_loss: 9.8213\n",
      "Epoch 1544/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 7.1525 - val_loss: 9.7998\n",
      "Epoch 1545/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 7.1414 - val_loss: 9.7788\n",
      "Epoch 1546/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 7.1317 - val_loss: 9.7568\n",
      "Epoch 1547/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 7.1196 - val_loss: 9.7357\n",
      "Epoch 1548/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 7.1076 - val_loss: 9.7155\n",
      "Epoch 1549/3000\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 7.0969 - val_loss: 9.6952\n",
      "Epoch 1550/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 7.0860 - val_loss: 9.6738\n",
      "Epoch 1551/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 7.0765 - val_loss: 9.6518\n",
      "Epoch 1552/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 7.0649 - val_loss: 9.6306\n",
      "Epoch 1553/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 7.0519 - val_loss: 9.6109\n",
      "Epoch 1554/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 7.0422 - val_loss: 9.5901\n",
      "Epoch 1555/3000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 7.0312 - val_loss: 9.5693\n",
      "Epoch 1556/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 7.0190 - val_loss: 9.5484\n",
      "Epoch 1557/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 7.0090 - val_loss: 9.5264\n",
      "Epoch 1558/3000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 6.9971 - val_loss: 9.5055\n",
      "Epoch 1559/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 6.9856 - val_loss: 9.4860\n",
      "Epoch 1560/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 6.9752 - val_loss: 9.4660\n",
      "Epoch 1561/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 6.9669 - val_loss: 9.4432\n",
      "Epoch 1562/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 6.9536 - val_loss: 9.4218\n",
      "Epoch 1563/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 6.9427 - val_loss: 9.4007\n",
      "Epoch 1564/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 6.9303 - val_loss: 9.3806\n",
      "Epoch 1565/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 6.9205 - val_loss: 9.3590\n",
      "Epoch 1566/3000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 6.9094 - val_loss: 9.3369\n",
      "Epoch 1567/3000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 6.8982 - val_loss: 9.3156\n",
      "Epoch 1568/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 6.8885 - val_loss: 9.2937\n",
      "Epoch 1569/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 6.8757 - val_loss: 9.2729\n",
      "Epoch 1570/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 6.8655 - val_loss: 9.2527\n",
      "Epoch 1571/3000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 6.8551 - val_loss: 9.2326\n",
      "Epoch 1572/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 6.8450 - val_loss: 9.2117\n",
      "Epoch 1573/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 6.8336 - val_loss: 9.1915\n",
      "Epoch 1574/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 6.8225 - val_loss: 9.1716\n",
      "Epoch 1575/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 6.8123 - val_loss: 9.1514\n",
      "Epoch 1576/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 6.8021 - val_loss: 9.1308\n",
      "Epoch 1577/3000\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 6.7903 - val_loss: 9.1106\n",
      "Epoch 1578/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 6.7796 - val_loss: 9.0907\n",
      "Epoch 1579/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 6.7698 - val_loss: 9.0694\n",
      "Epoch 1580/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 6.7582 - val_loss: 9.0490\n",
      "Epoch 1581/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 6.7485 - val_loss: 9.0299\n",
      "Epoch 1582/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 6.7374 - val_loss: 9.0098\n",
      "Epoch 1583/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 6.7259 - val_loss: 8.9899\n",
      "Epoch 1584/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 6.7153 - val_loss: 8.9706\n",
      "Epoch 1585/3000\n",
      "2/2 [==============================] - 0s 205ms/step - loss: 6.7047 - val_loss: 8.9505\n",
      "Epoch 1586/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 6.6939 - val_loss: 8.9311\n",
      "Epoch 1587/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 6.6840 - val_loss: 8.9111\n",
      "Epoch 1588/3000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 6.6722 - val_loss: 8.8918\n",
      "Epoch 1589/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 6.6624 - val_loss: 8.8715\n",
      "Epoch 1590/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 6.6514 - val_loss: 8.8518\n",
      "Epoch 1591/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 6.6405 - val_loss: 8.8316\n",
      "Epoch 1592/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 6.6309 - val_loss: 8.8115\n",
      "Epoch 1593/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 6.6196 - val_loss: 8.7909\n",
      "Epoch 1594/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 6.6101 - val_loss: 8.7699\n",
      "Epoch 1595/3000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 6.5984 - val_loss: 8.7502\n",
      "Epoch 1596/3000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 6.5866 - val_loss: 8.7303\n",
      "Epoch 1597/3000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 6.5768 - val_loss: 8.7106\n",
      "Epoch 1598/3000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 6.5652 - val_loss: 8.6909\n",
      "Epoch 1599/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 6.5546 - val_loss: 8.6701\n",
      "Epoch 1600/3000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 6.5448 - val_loss: 8.6492\n",
      "Epoch 1601/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 6.5335 - val_loss: 8.6285\n",
      "Epoch 1602/3000\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 6.5226 - val_loss: 8.6081\n",
      "Epoch 1603/3000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 6.5115 - val_loss: 8.5879\n",
      "Epoch 1604/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 6.5007 - val_loss: 8.5675\n",
      "Epoch 1605/3000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 6.4908 - val_loss: 8.5466\n",
      "Epoch 1606/3000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 6.4797 - val_loss: 8.5261\n",
      "Epoch 1607/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 6.4698 - val_loss: 8.5053\n",
      "Epoch 1608/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 6.4606 - val_loss: 8.4850\n",
      "Epoch 1609/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 6.4492 - val_loss: 8.4667\n",
      "Epoch 1610/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 6.4395 - val_loss: 8.4478\n",
      "Epoch 1611/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 6.4290 - val_loss: 8.4303\n",
      "Epoch 1612/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 6.4196 - val_loss: 8.4120\n",
      "Epoch 1613/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 6.4101 - val_loss: 8.3929\n",
      "Epoch 1614/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 6.3999 - val_loss: 8.3740\n",
      "Epoch 1615/3000\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 6.3923 - val_loss: 8.3545\n",
      "Epoch 1616/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 6.3811 - val_loss: 8.3361\n",
      "Epoch 1617/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 6.3702 - val_loss: 8.3179\n",
      "Epoch 1618/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 6.3602 - val_loss: 8.2998\n",
      "Epoch 1619/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 6.3527 - val_loss: 8.2805\n",
      "Epoch 1620/3000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 6.3400 - val_loss: 8.2629\n",
      "Epoch 1621/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 6.265 - 0s 30ms/step - loss: 6.3301 - val_loss: 8.2455\n",
      "Epoch 1622/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 6.3214 - val_loss: 8.2271\n",
      "Epoch 1623/3000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 6.3116 - val_loss: 8.2087\n",
      "Epoch 1624/3000\n",
      "2/2 [==============================] - 0s 201ms/step - loss: 6.3027 - val_loss: 8.1901\n",
      "Epoch 1625/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 6.2912 - val_loss: 8.1713\n",
      "Epoch 1626/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 6.2819 - val_loss: 8.1530\n",
      "Epoch 1627/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 6.2719 - val_loss: 8.1340\n",
      "Epoch 1628/3000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 6.2628 - val_loss: 8.1152\n",
      "Epoch 1629/3000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 6.2532 - val_loss: 8.0963\n",
      "Epoch 1630/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 6.2436 - val_loss: 8.0775\n",
      "Epoch 1631/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 6.2334 - val_loss: 8.0589\n",
      "Epoch 1632/3000\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 6.2238 - val_loss: 8.0403\n",
      "Epoch 1633/3000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 6.2132 - val_loss: 8.0228\n",
      "Epoch 1634/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 6.2031 - val_loss: 8.0045\n",
      "Epoch 1635/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 6.1935 - val_loss: 7.9863\n",
      "Epoch 1636/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 6.1858 - val_loss: 7.9673\n",
      "Epoch 1637/3000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 6.1746 - val_loss: 7.9485\n",
      "Epoch 1638/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 5.859 - 0s 41ms/step - loss: 6.1652 - val_loss: 7.9296\n",
      "Epoch 1639/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 6.1556 - val_loss: 7.9110\n",
      "Epoch 1640/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 6.1456 - val_loss: 7.8921\n",
      "Epoch 1641/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 6.1358 - val_loss: 7.8736\n",
      "Epoch 1642/3000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 6.1248 - val_loss: 7.8557\n",
      "Epoch 1643/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 6.1165 - val_loss: 7.8364\n",
      "Epoch 1644/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 6.1063 - val_loss: 7.8178\n",
      "Epoch 1645/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 6.0955 - val_loss: 7.7995\n",
      "Epoch 1646/3000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 6.0851 - val_loss: 7.7813\n",
      "Epoch 1647/3000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 6.0749 - val_loss: 7.7636\n",
      "Epoch 1648/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 6.0663 - val_loss: 7.7447\n",
      "Epoch 1649/3000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 6.0567 - val_loss: 7.7262\n",
      "Epoch 1650/3000\n",
      "2/2 [==============================] - 0s 136ms/step - loss: 6.0456 - val_loss: 7.7084\n",
      "Epoch 1651/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 6.0368 - val_loss: 7.6896\n",
      "Epoch 1652/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 6.0281 - val_loss: 7.6701\n",
      "Epoch 1653/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 6.0180 - val_loss: 7.6506\n",
      "Epoch 1654/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 6.0065 - val_loss: 7.6324\n",
      "Epoch 1655/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 5.9990 - val_loss: 7.6132\n",
      "Epoch 1656/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 5.9875 - val_loss: 7.5945\n",
      "Epoch 1657/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 5.9769 - val_loss: 7.5767\n",
      "Epoch 1658/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 5.9670 - val_loss: 7.5580\n",
      "Epoch 1659/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 5.9571 - val_loss: 7.5408\n",
      "Epoch 1660/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 5.9507 - val_loss: 7.5218\n",
      "Epoch 1661/3000\n",
      "2/2 [==============================] - 0s 124ms/step - loss: 5.9392 - val_loss: 7.5041\n",
      "Epoch 1662/3000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 5.9279 - val_loss: 7.4877\n",
      "Epoch 1663/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 5.9202 - val_loss: 7.4707\n",
      "Epoch 1664/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 5.9099 - val_loss: 7.4544\n",
      "Epoch 1665/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 5.9021 - val_loss: 7.4367\n",
      "Epoch 1666/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 5.8902 - val_loss: 7.4203\n",
      "Epoch 1667/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 5.8812 - val_loss: 7.4035\n",
      "Epoch 1668/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 5.8707 - val_loss: 7.3868\n",
      "Epoch 1669/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 5.8630 - val_loss: 7.3691\n",
      "Epoch 1670/3000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 5.8543 - val_loss: 7.3507\n",
      "Epoch 1671/3000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 5.8420 - val_loss: 7.3340\n",
      "Epoch 1672/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 5.8337 - val_loss: 7.3164\n",
      "Epoch 1673/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 5.8251 - val_loss: 7.2989\n",
      "Epoch 1674/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 5.8135 - val_loss: 7.2824\n",
      "Epoch 1675/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 5.949 - 0s 72ms/step - loss: 5.8051 - val_loss: 7.2653\n",
      "Epoch 1676/3000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 5.7944 - val_loss: 7.2498\n",
      "Epoch 1677/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 5.7854 - val_loss: 7.2338\n",
      "Epoch 1678/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 5.7766 - val_loss: 7.2171\n",
      "Epoch 1679/3000\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 5.7658 - val_loss: 7.1996\n",
      "Epoch 1680/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 5.7555 - val_loss: 7.1830\n",
      "Epoch 1681/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 5.7487 - val_loss: 7.1658\n",
      "Epoch 1682/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 5.7374 - val_loss: 7.1489\n",
      "Epoch 1683/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 5.7286 - val_loss: 7.1316\n",
      "Epoch 1684/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 5.7202 - val_loss: 7.1146\n",
      "Epoch 1685/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 5.7100 - val_loss: 7.0982\n",
      "Epoch 1686/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 5.6980 - val_loss: 7.0819\n",
      "Epoch 1687/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 5.6893 - val_loss: 7.0652\n",
      "Epoch 1688/3000\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 5.6801 - val_loss: 7.0480\n",
      "Epoch 1689/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 5.6706 - val_loss: 7.0314\n",
      "Epoch 1690/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 5.6611 - val_loss: 7.0143\n",
      "Epoch 1691/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 5.6512 - val_loss: 6.9982\n",
      "Epoch 1692/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 5.6433 - val_loss: 6.9809\n",
      "Epoch 1693/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 5.6316 - val_loss: 6.9647\n",
      "Epoch 1694/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 5.6232 - val_loss: 6.9481\n",
      "Epoch 1695/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 5.6129 - val_loss: 6.9321\n",
      "Epoch 1696/3000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 5.6044 - val_loss: 6.9151\n",
      "Epoch 1697/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 5.5958 - val_loss: 6.8983\n",
      "Epoch 1698/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 5.5843 - val_loss: 6.8823\n",
      "Epoch 1699/3000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 5.5758 - val_loss: 6.8654\n",
      "Epoch 1700/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 5.5653 - val_loss: 6.8495\n",
      "Epoch 1701/3000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 5.5558 - val_loss: 6.8325\n",
      "Epoch 1702/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 5.5458 - val_loss: 6.8162\n",
      "Epoch 1703/3000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 5.5365 - val_loss: 6.7994\n",
      "Epoch 1704/3000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 5.5292 - val_loss: 6.7825\n",
      "Epoch 1705/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 5.5180 - val_loss: 6.7667\n",
      "Epoch 1706/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 5.5090 - val_loss: 6.7519\n",
      "Epoch 1707/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 5.4985 - val_loss: 6.7362\n",
      "Epoch 1708/3000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 5.4890 - val_loss: 6.7206\n",
      "Epoch 1709/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 5.4795 - val_loss: 6.7040\n",
      "Epoch 1710/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 5.4729 - val_loss: 6.6867\n",
      "Epoch 1711/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 5.4596 - val_loss: 6.6709\n",
      "Epoch 1712/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 5.4523 - val_loss: 6.6544\n",
      "Epoch 1713/3000\n",
      "2/2 [==============================] - 0s 134ms/step - loss: 5.4423 - val_loss: 6.6376\n",
      "Epoch 1714/3000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 5.4314 - val_loss: 6.6219\n",
      "Epoch 1715/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 5.4226 - val_loss: 6.6057\n",
      "Epoch 1716/3000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 5.4124 - val_loss: 6.5896\n",
      "Epoch 1717/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 5.4050 - val_loss: 6.5733\n",
      "Epoch 1718/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 5.3948 - val_loss: 6.5577\n",
      "Epoch 1719/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 5.3842 - val_loss: 6.5419\n",
      "Epoch 1720/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 5.3765 - val_loss: 6.5254\n",
      "Epoch 1721/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 5.3645 - val_loss: 6.5095\n",
      "Epoch 1722/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 5.3567 - val_loss: 6.4929\n",
      "Epoch 1723/3000\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 5.3466 - val_loss: 6.4775\n",
      "Epoch 1724/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 5.3379 - val_loss: 6.4610\n",
      "Epoch 1725/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 5.3272 - val_loss: 6.4454\n",
      "Epoch 1726/3000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 5.3190 - val_loss: 6.4294\n",
      "Epoch 1727/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 5.3105 - val_loss: 6.4121\n",
      "Epoch 1728/3000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 5.2998 - val_loss: 6.3952\n",
      "Epoch 1729/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 5.2894 - val_loss: 6.3787\n",
      "Epoch 1730/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 5.2813 - val_loss: 6.3623\n",
      "Epoch 1731/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 5.2725 - val_loss: 6.3464\n",
      "Epoch 1732/3000\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 5.2642 - val_loss: 6.3302\n",
      "Epoch 1733/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 5.2519 - val_loss: 6.3147\n",
      "Epoch 1734/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 5.2429 - val_loss: 6.2989\n",
      "Epoch 1735/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 5.2333 - val_loss: 6.2818\n",
      "Epoch 1736/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 5.2228 - val_loss: 6.2659\n",
      "Epoch 1737/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 5.2161 - val_loss: 6.2482\n",
      "Epoch 1738/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 5.2041 - val_loss: 6.2313\n",
      "Epoch 1739/3000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 5.1951 - val_loss: 6.2153\n",
      "Epoch 1740/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 5.1863 - val_loss: 6.1991\n",
      "Epoch 1741/3000\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 5.1769 - val_loss: 6.1829\n",
      "Epoch 1742/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 5.1652 - val_loss: 6.1673\n",
      "Epoch 1743/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 5.1565 - val_loss: 6.1522\n",
      "Epoch 1744/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 5.1476 - val_loss: 6.1363\n",
      "Epoch 1745/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 5.1400 - val_loss: 6.1194\n",
      "Epoch 1746/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 5.1288 - val_loss: 6.1026\n",
      "Epoch 1747/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 5.1194 - val_loss: 6.0863\n",
      "Epoch 1748/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 5.1099 - val_loss: 6.0696\n",
      "Epoch 1749/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 5.0985 - val_loss: 6.0537\n",
      "Epoch 1750/3000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 5.0910 - val_loss: 6.0371\n",
      "Epoch 1751/3000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 5.0812 - val_loss: 6.0212\n",
      "Epoch 1752/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 5.0718 - val_loss: 6.0050\n",
      "Epoch 1753/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 5.0622 - val_loss: 5.9883\n",
      "Epoch 1754/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 5.0519 - val_loss: 5.9717\n",
      "Epoch 1755/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 5.0442 - val_loss: 5.9563\n",
      "Epoch 1756/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 5.0337 - val_loss: 5.9406\n",
      "Epoch 1757/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 5.0228 - val_loss: 5.9242\n",
      "Epoch 1758/3000\n",
      "2/2 [==============================] - 0s 128ms/step - loss: 5.0144 - val_loss: 5.9073\n",
      "Epoch 1759/3000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 5.0038 - val_loss: 5.8907\n",
      "Epoch 1760/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 4.9943 - val_loss: 5.8746\n",
      "Epoch 1761/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 4.9859 - val_loss: 5.8583\n",
      "Epoch 1762/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 4.9755 - val_loss: 5.8426\n",
      "Epoch 1763/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 4.9658 - val_loss: 5.8274\n",
      "Epoch 1764/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 4.9566 - val_loss: 5.8119\n",
      "Epoch 1765/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 4.9460 - val_loss: 5.7961\n",
      "Epoch 1766/3000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 4.9381 - val_loss: 5.7793\n",
      "Epoch 1767/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 4.9270 - val_loss: 5.7636\n",
      "Epoch 1768/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 4.9181 - val_loss: 5.7473\n",
      "Epoch 1769/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 4.9085 - val_loss: 5.7311\n",
      "Epoch 1770/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 4.8987 - val_loss: 5.7148\n",
      "Epoch 1771/3000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 4.8901 - val_loss: 5.6981\n",
      "Epoch 1772/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 4.8790 - val_loss: 5.6832\n",
      "Epoch 1773/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 4.8712 - val_loss: 5.6653\n",
      "Epoch 1774/3000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 4.8606 - val_loss: 5.6480\n",
      "Epoch 1775/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 4.8510 - val_loss: 5.6325\n",
      "Epoch 1776/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 4.8426 - val_loss: 5.6158\n",
      "Epoch 1777/3000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 4.8325 - val_loss: 5.6003\n",
      "Epoch 1778/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 4.8208 - val_loss: 5.5846\n",
      "Epoch 1779/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 4.8125 - val_loss: 5.5679\n",
      "Epoch 1780/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 4.8016 - val_loss: 5.5514\n",
      "Epoch 1781/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 4.7924 - val_loss: 5.5354\n",
      "Epoch 1782/3000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 4.7844 - val_loss: 5.5183\n",
      "Epoch 1783/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 4.7739 - val_loss: 5.5021\n",
      "Epoch 1784/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 4.7647 - val_loss: 5.4865\n",
      "Epoch 1785/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 4.7538 - val_loss: 5.4710\n",
      "Epoch 1786/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 4.7451 - val_loss: 5.4541\n",
      "Epoch 1787/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 4.7364 - val_loss: 5.4376\n",
      "Epoch 1788/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 4.7246 - val_loss: 5.4220\n",
      "Epoch 1789/3000\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 4.7160 - val_loss: 5.4053\n",
      "Epoch 1790/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 4.7063 - val_loss: 5.3882\n",
      "Epoch 1791/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 4.6962 - val_loss: 5.3713\n",
      "Epoch 1792/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 4.6872 - val_loss: 5.3540\n",
      "Epoch 1793/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 4.6777 - val_loss: 5.3369\n",
      "Epoch 1794/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 4.6694 - val_loss: 5.3201\n",
      "Epoch 1795/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 4.6580 - val_loss: 5.3025\n",
      "Epoch 1796/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 4.6480 - val_loss: 5.2858\n",
      "Epoch 1797/3000\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 4.6384 - val_loss: 5.2700\n",
      "Epoch 1798/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 4.6301 - val_loss: 5.2532\n",
      "Epoch 1799/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 4.6195 - val_loss: 5.2365\n",
      "Epoch 1800/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 4.6109 - val_loss: 5.2191\n",
      "Epoch 1801/3000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 4.5998 - val_loss: 5.2023\n",
      "Epoch 1802/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 4.5914 - val_loss: 5.1854\n",
      "Epoch 1803/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 4.5825 - val_loss: 5.1681\n",
      "Epoch 1804/3000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 4.5730 - val_loss: 5.1515\n",
      "Epoch 1805/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 4.5632 - val_loss: 5.1337\n",
      "Epoch 1806/3000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 4.5533 - val_loss: 5.1172\n",
      "Epoch 1807/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 4.5432 - val_loss: 5.1003\n",
      "Epoch 1808/3000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 4.5341 - val_loss: 5.0828\n",
      "Epoch 1809/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 4.5254 - val_loss: 5.0656\n",
      "Epoch 1810/3000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 4.5145 - val_loss: 5.0489\n",
      "Epoch 1811/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 4.5051 - val_loss: 5.0321\n",
      "Epoch 1812/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 4.4951 - val_loss: 5.0150\n",
      "Epoch 1813/3000\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 4.4876 - val_loss: 4.9976\n",
      "Epoch 1814/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 4.4788 - val_loss: 4.9799\n",
      "Epoch 1815/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 4.4688 - val_loss: 4.9621\n",
      "Epoch 1816/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 4.4571 - val_loss: 4.9455\n",
      "Epoch 1817/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 4.4459 - val_loss: 4.9289\n",
      "Epoch 1818/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 4.4375 - val_loss: 4.9118\n",
      "Epoch 1819/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 4.4298 - val_loss: 4.8951\n",
      "Epoch 1820/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 4.4176 - val_loss: 4.8782\n",
      "Epoch 1821/3000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 4.4092 - val_loss: 4.8611\n",
      "Epoch 1822/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 4.4003 - val_loss: 4.8432\n",
      "Epoch 1823/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 4.3896 - val_loss: 4.8269\n",
      "Epoch 1824/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 4.3801 - val_loss: 4.8104\n",
      "Epoch 1825/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 4.3720 - val_loss: 4.7927\n",
      "Epoch 1826/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 4.3618 - val_loss: 4.7747\n",
      "Epoch 1827/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 4.3518 - val_loss: 4.7578\n",
      "Epoch 1828/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 4.3414 - val_loss: 4.7413\n",
      "Epoch 1829/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 4.3325 - val_loss: 4.7245\n",
      "Epoch 1830/3000\n",
      "2/2 [==============================] - 0s 191ms/step - loss: 4.3227 - val_loss: 4.7077\n",
      "Epoch 1831/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 4.3135 - val_loss: 4.6909\n",
      "Epoch 1832/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 4.3038 - val_loss: 4.6744\n",
      "Epoch 1833/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 4.2946 - val_loss: 4.6585\n",
      "Epoch 1834/3000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 4.2906 - val_loss: 4.6435\n",
      "Epoch 1835/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 4.2845 - val_loss: 4.6308\n",
      "Epoch 1836/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 4.2781 - val_loss: 4.6199\n",
      "Epoch 1837/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 4.2727 - val_loss: 4.6095\n",
      "Epoch 1838/3000\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 4.2660 - val_loss: 4.6008\n",
      "Epoch 1839/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 4.2599 - val_loss: 4.5920\n",
      "Epoch 1840/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 4.2545 - val_loss: 4.5830\n",
      "Epoch 1841/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 4.2488 - val_loss: 4.5742\n",
      "Epoch 1842/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 4.2431 - val_loss: 4.5659\n",
      "Epoch 1843/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 4.2380 - val_loss: 4.5581\n",
      "Epoch 1844/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 4.2325 - val_loss: 4.5501\n",
      "Epoch 1845/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 4.2265 - val_loss: 4.5433\n",
      "Epoch 1846/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 4.2219 - val_loss: 4.5349\n",
      "Epoch 1847/3000\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 4.2154 - val_loss: 4.5267\n",
      "Epoch 1848/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 4.2095 - val_loss: 4.5194\n",
      "Epoch 1849/3000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 4.2048 - val_loss: 4.5138\n",
      "Epoch 1850/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 4.2003 - val_loss: 4.5077\n",
      "Epoch 1851/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 4.1936 - val_loss: 4.5017\n",
      "Epoch 1852/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 4.1894 - val_loss: 4.4957\n",
      "Epoch 1853/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 4.1834 - val_loss: 4.4903\n",
      "Epoch 1854/3000\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 4.1787 - val_loss: 4.4856\n",
      "Epoch 1855/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 4.1738 - val_loss: 4.4821\n",
      "Epoch 1856/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 4.1681 - val_loss: 4.4781\n",
      "Epoch 1857/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 4.1646 - val_loss: 4.4739\n",
      "Epoch 1858/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 4.1605 - val_loss: 4.4709\n",
      "Epoch 1859/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 4.1574 - val_loss: 4.4674\n",
      "Epoch 1860/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 4.1524 - val_loss: 4.4617\n",
      "Epoch 1861/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 4.1490 - val_loss: 4.4562\n",
      "Epoch 1862/3000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 4.1456 - val_loss: 4.4495\n",
      "Epoch 1863/3000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 4.1429 - val_loss: 4.4442\n",
      "Epoch 1864/3000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 4.1387 - val_loss: 4.4404\n",
      "Epoch 1865/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 4.1359 - val_loss: 4.4362\n",
      "Epoch 1866/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 4.1317 - val_loss: 4.4311\n",
      "Epoch 1867/3000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 4.1285 - val_loss: 4.4236\n",
      "Epoch 1868/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 4.1253 - val_loss: 4.4173\n",
      "Epoch 1869/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 4.1210 - val_loss: 4.4112\n",
      "Epoch 1870/3000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 4.1182 - val_loss: 4.4029\n",
      "Epoch 1871/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 4.1141 - val_loss: 4.3950\n",
      "Epoch 1872/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 4.1105 - val_loss: 4.3885\n",
      "Epoch 1873/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 4.1079 - val_loss: 4.3829\n",
      "Epoch 1874/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 4.1059 - val_loss: 4.3785\n",
      "Epoch 1875/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 4.1001 - val_loss: 4.3723\n",
      "Epoch 1876/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 4.0970 - val_loss: 4.3657\n",
      "Epoch 1877/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 4.0933 - val_loss: 4.3585\n",
      "Epoch 1878/3000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 4.0912 - val_loss: 4.3516\n",
      "Epoch 1879/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 4.0864 - val_loss: 4.3443\n",
      "Epoch 1880/3000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 4.0825 - val_loss: 4.3371\n",
      "Epoch 1881/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 4.0791 - val_loss: 4.3298\n",
      "Epoch 1882/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 4.0763 - val_loss: 4.3234\n",
      "Epoch 1883/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 4.0725 - val_loss: 4.3151\n",
      "Epoch 1884/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 4.0688 - val_loss: 4.3088\n",
      "Epoch 1885/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 4.0655 - val_loss: 4.3046\n",
      "Epoch 1886/3000\n",
      "2/2 [==============================] - 0s 179ms/step - loss: 4.0623 - val_loss: 4.2991\n",
      "Epoch 1887/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 4.0586 - val_loss: 4.2931\n",
      "Epoch 1888/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 4.0547 - val_loss: 4.2866\n",
      "Epoch 1889/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 4.0513 - val_loss: 4.2800\n",
      "Epoch 1890/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 4.0485 - val_loss: 4.2730\n",
      "Epoch 1891/3000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 4.0445 - val_loss: 4.2646\n",
      "Epoch 1892/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 4.0411 - val_loss: 4.2572\n",
      "Epoch 1893/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 4.0372 - val_loss: 4.2483\n",
      "Epoch 1894/3000\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 4.0336 - val_loss: 4.2428\n",
      "Epoch 1895/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 4.0303 - val_loss: 4.2363\n",
      "Epoch 1896/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 4.0263 - val_loss: 4.2309\n",
      "Epoch 1897/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 4.0239 - val_loss: 4.2270\n",
      "Epoch 1898/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 4.0202 - val_loss: 4.2212\n",
      "Epoch 1899/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 4.0169 - val_loss: 4.2146\n",
      "Epoch 1900/3000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 4.0134 - val_loss: 4.2080\n",
      "Epoch 1901/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 4.0089 - val_loss: 4.2012\n",
      "Epoch 1902/3000\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 4.0054 - val_loss: 4.1942\n",
      "Epoch 1903/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 4.0024 - val_loss: 4.1875\n",
      "Epoch 1904/3000\n",
      "2/2 [==============================] - 0s 227ms/step - loss: 3.9983 - val_loss: 4.1793\n",
      "Epoch 1905/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.9954 - val_loss: 4.1706\n",
      "Epoch 1906/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.9914 - val_loss: 4.1633\n",
      "Epoch 1907/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 3.9876 - val_loss: 4.1584\n",
      "Epoch 1908/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.9842 - val_loss: 4.1515\n",
      "Epoch 1909/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.9819 - val_loss: 4.1456\n",
      "Epoch 1910/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.9770 - val_loss: 4.1382\n",
      "Epoch 1911/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 4.145 - 0s 37ms/step - loss: 3.9735 - val_loss: 4.1316\n",
      "Epoch 1912/3000\n",
      "2/2 [==============================] - 0s 147ms/step - loss: 3.9696 - val_loss: 4.1248\n",
      "Epoch 1913/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 3.9660 - val_loss: 4.1167\n",
      "Epoch 1914/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.9630 - val_loss: 4.1096\n",
      "Epoch 1915/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.9590 - val_loss: 4.1020\n",
      "Epoch 1916/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.9551 - val_loss: 4.0967\n",
      "Epoch 1917/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 3.9516 - val_loss: 4.0911\n",
      "Epoch 1918/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3.9483 - val_loss: 4.0847\n",
      "Epoch 1919/3000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 3.9445 - val_loss: 4.0770\n",
      "Epoch 1920/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.9414 - val_loss: 4.0689\n",
      "Epoch 1921/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.9376 - val_loss: 4.0622\n",
      "Epoch 1922/3000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 3.9342 - val_loss: 4.0557\n",
      "Epoch 1923/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3.9300 - val_loss: 4.0496\n",
      "Epoch 1924/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.9265 - val_loss: 4.0434\n",
      "Epoch 1925/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.9232 - val_loss: 4.0362\n",
      "Epoch 1926/3000\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 3.9194 - val_loss: 4.0282\n",
      "Epoch 1927/3000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 3.9163 - val_loss: 4.0213\n",
      "Epoch 1928/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.9127 - val_loss: 4.0145\n",
      "Epoch 1929/3000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 3.9084 - val_loss: 4.0084\n",
      "Epoch 1930/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.9047 - val_loss: 4.0026\n",
      "Epoch 1931/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.9014 - val_loss: 3.9955\n",
      "Epoch 1932/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.8975 - val_loss: 3.9891\n",
      "Epoch 1933/3000\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 3.8944 - val_loss: 3.9811\n",
      "Epoch 1934/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.8905 - val_loss: 3.9769\n",
      "Epoch 1935/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.8866 - val_loss: 3.9732\n",
      "Epoch 1936/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 3.8829 - val_loss: 3.9679\n",
      "Epoch 1937/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.8799 - val_loss: 3.9625\n",
      "Epoch 1938/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.8763 - val_loss: 3.9563\n",
      "Epoch 1939/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.8731 - val_loss: 3.9518\n",
      "Epoch 1940/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 3.8705 - val_loss: 3.9481\n",
      "Epoch 1941/3000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 3.8678 - val_loss: 3.9464\n",
      "Epoch 1942/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3.8659 - val_loss: 3.9445\n",
      "Epoch 1943/3000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 3.8634 - val_loss: 3.9422\n",
      "Epoch 1944/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 3.8609 - val_loss: 3.9382\n",
      "Epoch 1945/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.8589 - val_loss: 3.9362\n",
      "Epoch 1946/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 3.8565 - val_loss: 3.9346\n",
      "Epoch 1947/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.8549 - val_loss: 3.9336\n",
      "Epoch 1948/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 3.8519 - val_loss: 3.9312\n",
      "Epoch 1949/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 3.8505 - val_loss: 3.9286\n",
      "Epoch 1950/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.8486 - val_loss: 3.9273\n",
      "Epoch 1951/3000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 3.8466 - val_loss: 3.9270\n",
      "Epoch 1952/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3.8437 - val_loss: 3.9277\n",
      "Epoch 1953/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.8420 - val_loss: 3.9268\n",
      "Epoch 1954/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.8401 - val_loss: 3.9243\n",
      "Epoch 1955/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.8384 - val_loss: 3.9230\n",
      "Epoch 1956/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.8363 - val_loss: 3.9210\n",
      "Epoch 1957/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.8337 - val_loss: 3.9188\n",
      "Epoch 1958/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.8314 - val_loss: 3.9175\n",
      "Epoch 1959/3000\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 3.8299 - val_loss: 3.9174\n",
      "Epoch 1960/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.8280 - val_loss: 3.9188\n",
      "Epoch 1961/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3.8263 - val_loss: 3.9183\n",
      "Epoch 1962/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 3.8252 - val_loss: 3.9163\n",
      "Epoch 1963/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.8234 - val_loss: 3.9149\n",
      "Epoch 1964/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 3.8219 - val_loss: 3.9138\n",
      "Epoch 1965/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.8211 - val_loss: 3.9112\n",
      "Epoch 1966/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.8201 - val_loss: 3.9093\n",
      "Epoch 1967/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.8188 - val_loss: 3.9056\n",
      "Epoch 1968/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.8179 - val_loss: 3.9007\n",
      "Epoch 1969/3000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 3.8170 - val_loss: 3.8970\n",
      "Epoch 1970/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.8163 - val_loss: 3.8939\n",
      "Epoch 1971/3000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 3.8152 - val_loss: 3.8909\n",
      "Epoch 1972/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 3.8141 - val_loss: 3.8898\n",
      "Epoch 1973/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 3.8129 - val_loss: 3.8871\n",
      "Epoch 1974/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.8123 - val_loss: 3.8834\n",
      "Epoch 1975/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.8113 - val_loss: 3.8791\n",
      "Epoch 1976/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.8103 - val_loss: 3.8772\n",
      "Epoch 1977/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.8093 - val_loss: 3.8758\n",
      "Epoch 1978/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 3.8088 - val_loss: 3.8731\n",
      "Epoch 1979/3000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 3.8075 - val_loss: 3.8682\n",
      "Epoch 1980/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.8069 - val_loss: 3.8641\n",
      "Epoch 1981/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.8057 - val_loss: 3.8606\n",
      "Epoch 1982/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.8048 - val_loss: 3.8580\n",
      "Epoch 1983/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 3.812 - 0s 45ms/step - loss: 3.8039 - val_loss: 3.8562\n",
      "Epoch 1984/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.8034 - val_loss: 3.8534\n",
      "Epoch 1985/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 3.8018 - val_loss: 3.8500\n",
      "Epoch 1986/3000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 3.8010 - val_loss: 3.8440\n",
      "Epoch 1987/3000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 3.8007 - val_loss: 3.8382\n",
      "Epoch 1988/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.8000 - val_loss: 3.8329\n",
      "Epoch 1989/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.7994 - val_loss: 3.8283\n",
      "Epoch 1990/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7983 - val_loss: 3.8253\n",
      "Epoch 1991/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 3.7973 - val_loss: 3.8232\n",
      "Epoch 1992/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7972 - val_loss: 3.8219\n",
      "Epoch 1993/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 3.7959 - val_loss: 3.8197\n",
      "Epoch 1994/3000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 3.7960 - val_loss: 3.8157\n",
      "Epoch 1995/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 3.7952 - val_loss: 3.8093\n",
      "Epoch 1996/3000\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 3.7945 - val_loss: 3.8049\n",
      "Epoch 1997/3000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 3.7939 - val_loss: 3.8007\n",
      "Epoch 1998/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.7937 - val_loss: 3.7973\n",
      "Epoch 1999/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.7925 - val_loss: 3.7945\n",
      "Epoch 2000/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.7919 - val_loss: 3.7927\n",
      "Epoch 2001/3000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 3.7914 - val_loss: 3.7908\n",
      "Epoch 2002/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7906 - val_loss: 3.7894\n",
      "Epoch 2003/3000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 3.7909 - val_loss: 3.7856\n",
      "Epoch 2004/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7905 - val_loss: 3.7816\n",
      "Epoch 2005/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 4.436 - 0s 41ms/step - loss: 3.7899 - val_loss: 3.7776\n",
      "Epoch 2006/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7895 - val_loss: 3.7747\n",
      "Epoch 2007/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 3.7891 - val_loss: 3.7726\n",
      "Epoch 2008/3000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 3.7888 - val_loss: 3.7709\n",
      "Epoch 2009/3000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 3.7882 - val_loss: 3.7695\n",
      "Epoch 2010/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7879 - val_loss: 3.7687\n",
      "Epoch 2011/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 3.7877 - val_loss: 3.7668\n",
      "Epoch 2012/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.7880 - val_loss: 3.7658\n",
      "Epoch 2013/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 3.7871 - val_loss: 3.7618\n",
      "Epoch 2014/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.7865 - val_loss: 3.7583\n",
      "Epoch 2015/3000\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 3.7865 - val_loss: 3.7563\n",
      "Epoch 2016/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.7859 - val_loss: 3.7544\n",
      "Epoch 2017/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3.7857 - val_loss: 3.7523\n",
      "Epoch 2018/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7854 - val_loss: 3.7514\n",
      "Epoch 2019/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7850 - val_loss: 3.7495\n",
      "Epoch 2020/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.7846 - val_loss: 3.7467\n",
      "Epoch 2021/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7842 - val_loss: 3.7433\n",
      "Epoch 2022/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7837 - val_loss: 3.7405\n",
      "Epoch 2023/3000\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 3.7840 - val_loss: 3.7385\n",
      "Epoch 2024/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7839 - val_loss: 3.7350\n",
      "Epoch 2025/3000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 3.7834 - val_loss: 3.7311\n",
      "Epoch 2026/3000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 3.7830 - val_loss: 3.7285\n",
      "Epoch 2027/3000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 3.7828 - val_loss: 3.7256\n",
      "Epoch 2028/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.7824 - val_loss: 3.7228\n",
      "Epoch 2029/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 3.7821 - val_loss: 3.7197\n",
      "Epoch 2030/3000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 3.7815 - val_loss: 3.7174\n",
      "Epoch 2031/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.7810 - val_loss: 3.7160\n",
      "Epoch 2032/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.7806 - val_loss: 3.7149\n",
      "Epoch 2033/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 3.7806 - val_loss: 3.7139\n",
      "Epoch 2034/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7807 - val_loss: 3.7137\n",
      "Epoch 2035/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 3.7800 - val_loss: 3.7105\n",
      "Epoch 2036/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 3.7791 - val_loss: 3.7073\n",
      "Epoch 2037/3000\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 3.7790 - val_loss: 3.7043\n",
      "Epoch 2038/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.7789 - val_loss: 3.7011\n",
      "Epoch 2039/3000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 3.7786 - val_loss: 3.6993\n",
      "Epoch 2040/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.7784 - val_loss: 3.6971\n",
      "Epoch 2041/3000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 3.7782 - val_loss: 3.6941\n",
      "Epoch 2042/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.7777 - val_loss: 3.6929\n",
      "Epoch 2043/3000\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 3.7776 - val_loss: 3.6912\n",
      "Epoch 2044/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.7770 - val_loss: 3.6883\n",
      "Epoch 2045/3000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 3.7770 - val_loss: 3.6863\n",
      "Epoch 2046/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 3.7770 - val_loss: 3.6849\n",
      "Epoch 2047/3000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 3.7771 - val_loss: 3.6810\n",
      "Epoch 2048/3000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 3.7766 - val_loss: 3.6785\n",
      "Epoch 2049/3000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 3.7764 - val_loss: 3.6767\n",
      "Epoch 2050/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 3.7769 - val_loss: 3.6729\n",
      "Epoch 2051/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7765 - val_loss: 3.6710\n",
      "Epoch 2052/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.7760 - val_loss: 3.6699\n",
      "Epoch 2053/3000\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 3.7761 - val_loss: 3.6698\n",
      "Epoch 2054/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3.7751 - val_loss: 3.6687\n",
      "Epoch 2055/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.7750 - val_loss: 3.6669\n",
      "Epoch 2056/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3.7759 - val_loss: 3.6648\n",
      "Epoch 2057/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.7752 - val_loss: 3.6614\n",
      "Epoch 2058/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.7750 - val_loss: 3.6581\n",
      "Epoch 2059/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7746 - val_loss: 3.6560\n",
      "Epoch 2060/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.7746 - val_loss: 3.6553\n",
      "Epoch 2061/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.7755 - val_loss: 3.6530\n",
      "Epoch 2062/3000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 3.7746 - val_loss: 3.6517\n",
      "Epoch 2063/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7747 - val_loss: 3.6505\n",
      "Epoch 2064/3000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 3.7742 - val_loss: 3.6480\n",
      "Epoch 2065/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.7737 - val_loss: 3.6456\n",
      "Epoch 2066/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7737 - val_loss: 3.6434\n",
      "Epoch 2067/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7736 - val_loss: 3.6425\n",
      "Epoch 2068/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 3.7732 - val_loss: 3.6405\n",
      "Epoch 2069/3000\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 3.7729 - val_loss: 3.6406\n",
      "Epoch 2070/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7728 - val_loss: 3.6411\n",
      "Epoch 2071/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.7729 - val_loss: 3.6390\n",
      "Epoch 2072/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7727 - val_loss: 3.6354\n",
      "Epoch 2073/3000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 3.7724 - val_loss: 3.6325\n",
      "Epoch 2074/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 3.7722 - val_loss: 3.6297\n",
      "Epoch 2075/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.7721 - val_loss: 3.6274\n",
      "Epoch 2076/3000\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 3.7719 - val_loss: 3.6260\n",
      "Epoch 2077/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 3.7717 - val_loss: 3.6250\n",
      "Epoch 2078/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 3.7712 - val_loss: 3.6252\n",
      "Epoch 2079/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7711 - val_loss: 3.6242\n",
      "Epoch 2080/3000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 3.7709 - val_loss: 3.6236\n",
      "Epoch 2081/3000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 3.7714 - val_loss: 3.6226\n",
      "Epoch 2082/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 3.7711 - val_loss: 3.6212\n",
      "Epoch 2083/3000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 3.7708 - val_loss: 3.6178\n",
      "Epoch 2084/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.7704 - val_loss: 3.6140\n",
      "Epoch 2085/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.7702 - val_loss: 3.6106\n",
      "Epoch 2086/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7699 - val_loss: 3.6077\n",
      "Epoch 2087/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7707 - val_loss: 3.6040\n",
      "Epoch 2088/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 3.7702 - val_loss: 3.6028\n",
      "Epoch 2089/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.7699 - val_loss: 3.6016\n",
      "Epoch 2090/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7696 - val_loss: 3.5999\n",
      "Epoch 2091/3000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 3.7699 - val_loss: 3.5983\n",
      "Epoch 2092/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 3.7697 - val_loss: 3.5968\n",
      "Epoch 2093/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3.7690 - val_loss: 3.5972\n",
      "Epoch 2094/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 3.537 - 0s 53ms/step - loss: 3.7686 - val_loss: 3.5969\n",
      "Epoch 2095/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7687 - val_loss: 3.5957\n",
      "Epoch 2096/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7693 - val_loss: 3.5958\n",
      "Epoch 2097/3000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 3.7689 - val_loss: 3.5935\n",
      "Epoch 2098/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7685 - val_loss: 3.5910\n",
      "Epoch 2099/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7683 - val_loss: 3.5882\n",
      "Epoch 2100/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7683 - val_loss: 3.5872\n",
      "Epoch 2101/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7681 - val_loss: 3.5860\n",
      "Epoch 2102/3000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 3.7679 - val_loss: 3.5839\n",
      "Epoch 2103/3000\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 3.7678 - val_loss: 3.5828\n",
      "Epoch 2104/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7675 - val_loss: 3.5802\n",
      "Epoch 2105/3000\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 3.7674 - val_loss: 3.5790\n",
      "Epoch 2106/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7671 - val_loss: 3.5784\n",
      "Epoch 2107/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 3.7677 - val_loss: 3.5778\n",
      "Epoch 2108/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3.7668 - val_loss: 3.5771\n",
      "Epoch 2109/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7665 - val_loss: 3.5749\n",
      "Epoch 2110/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7666 - val_loss: 3.5716\n",
      "Epoch 2111/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3.7664 - val_loss: 3.5692\n",
      "Epoch 2112/3000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 3.7663 - val_loss: 3.5671\n",
      "Epoch 2113/3000\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 3.7658 - val_loss: 3.5662\n",
      "Epoch 2114/3000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 3.7661 - val_loss: 3.5653\n",
      "Epoch 2115/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.7658 - val_loss: 3.5639\n",
      "Epoch 2116/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 3.7655 - val_loss: 3.5628\n",
      "Epoch 2117/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7655 - val_loss: 3.5601\n",
      "Epoch 2118/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7654 - val_loss: 3.5565\n",
      "Epoch 2119/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.7654 - val_loss: 3.5535\n",
      "Epoch 2120/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7652 - val_loss: 3.5525\n",
      "Epoch 2121/3000\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 3.7650 - val_loss: 3.5507\n",
      "Epoch 2122/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7648 - val_loss: 3.5492\n",
      "Epoch 2123/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7647 - val_loss: 3.5468\n",
      "Epoch 2124/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7646 - val_loss: 3.5457\n",
      "Epoch 2125/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.7642 - val_loss: 3.5449\n",
      "Epoch 2126/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7644 - val_loss: 3.5448\n",
      "Epoch 2127/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3.7639 - val_loss: 3.5425\n",
      "Epoch 2128/3000\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 3.7644 - val_loss: 3.5386\n",
      "Epoch 2129/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7638 - val_loss: 3.5373\n",
      "Epoch 2130/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3.7640 - val_loss: 3.5344\n",
      "Epoch 2131/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7632 - val_loss: 3.5331\n",
      "Epoch 2132/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.7634 - val_loss: 3.5305\n",
      "Epoch 2133/3000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 3.7631 - val_loss: 3.5297\n",
      "Epoch 2134/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.7627 - val_loss: 3.5293\n",
      "Epoch 2135/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7630 - val_loss: 3.5297\n",
      "Epoch 2136/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7626 - val_loss: 3.5290\n",
      "Epoch 2137/3000\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 3.7627 - val_loss: 3.5266\n",
      "Epoch 2138/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.7621 - val_loss: 3.5232\n",
      "Epoch 2139/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7625 - val_loss: 3.5197\n",
      "Epoch 2140/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 3.7621 - val_loss: 3.5165\n",
      "Epoch 2141/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7623 - val_loss: 3.5131\n",
      "Epoch 2142/3000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 3.7619 - val_loss: 3.5116\n",
      "Epoch 2143/3000\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 3.7617 - val_loss: 3.5096\n",
      "Epoch 2144/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.7614 - val_loss: 3.5083\n",
      "Epoch 2145/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.7615 - val_loss: 3.5061\n",
      "Epoch 2146/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3.7610 - val_loss: 3.5056\n",
      "Epoch 2147/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7610 - val_loss: 3.5037\n",
      "Epoch 2148/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.7606 - val_loss: 3.5024\n",
      "Epoch 2149/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7606 - val_loss: 3.5012\n",
      "Epoch 2150/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 3.7609 - val_loss: 3.5010\n",
      "Epoch 2151/3000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 3.7604 - val_loss: 3.5004\n",
      "Epoch 2152/3000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 3.7604 - val_loss: 3.4981\n",
      "Epoch 2153/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7597 - val_loss: 3.4937\n",
      "Epoch 2154/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7596 - val_loss: 3.4902\n",
      "Epoch 2155/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.7603 - val_loss: 3.4884\n",
      "Epoch 2156/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.7597 - val_loss: 3.4860\n",
      "Epoch 2157/3000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 3.7594 - val_loss: 3.4843\n",
      "Epoch 2158/3000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 3.7595 - val_loss: 3.4845\n",
      "Epoch 2159/3000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 3.7592 - val_loss: 3.4834\n",
      "Epoch 2160/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 3.7592 - val_loss: 3.4807\n",
      "Epoch 2161/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7587 - val_loss: 3.4787\n",
      "Epoch 2162/3000\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 3.7588 - val_loss: 3.4765\n",
      "Epoch 2163/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 3.7583 - val_loss: 3.4760\n",
      "Epoch 2164/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 3.7584 - val_loss: 3.4741\n",
      "Epoch 2165/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7579 - val_loss: 3.4731\n",
      "Epoch 2166/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 3.7578 - val_loss: 3.4722\n",
      "Epoch 2167/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7576 - val_loss: 3.4712\n",
      "Epoch 2168/3000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 3.7575 - val_loss: 3.4683\n",
      "Epoch 2169/3000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 3.7573 - val_loss: 3.4658\n",
      "Epoch 2170/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.7574 - val_loss: 3.4639\n",
      "Epoch 2171/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.7572 - val_loss: 3.4624\n",
      "Epoch 2172/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7572 - val_loss: 3.4602\n",
      "Epoch 2173/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 3.7567 - val_loss: 3.4585\n",
      "Epoch 2174/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7570 - val_loss: 3.4576\n",
      "Epoch 2175/3000\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 3.7565 - val_loss: 3.4558\n",
      "Epoch 2176/3000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 3.7565 - val_loss: 3.4548\n",
      "Epoch 2177/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 3.7560 - val_loss: 3.4537\n",
      "Epoch 2178/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7560 - val_loss: 3.4515\n",
      "Epoch 2179/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 3.7554 - val_loss: 3.4495\n",
      "Epoch 2180/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.7559 - val_loss: 3.4474\n",
      "Epoch 2181/3000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 3.7552 - val_loss: 3.4470\n",
      "Epoch 2182/3000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 3.7552 - val_loss: 3.4454\n",
      "Epoch 2183/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7552 - val_loss: 3.4437\n",
      "Epoch 2184/3000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 3.7549 - val_loss: 3.4416\n",
      "Epoch 2185/3000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 3.7546 - val_loss: 3.4396\n",
      "Epoch 2186/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3.7547 - val_loss: 3.4363\n",
      "Epoch 2187/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 3.7545 - val_loss: 3.4332\n",
      "Epoch 2188/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 3.7552 - val_loss: 3.4308\n",
      "Epoch 2189/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7542 - val_loss: 3.4300\n",
      "Epoch 2190/3000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 3.7542 - val_loss: 3.4283\n",
      "Epoch 2191/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.7547 - val_loss: 3.4262\n",
      "Epoch 2192/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7538 - val_loss: 3.4235\n",
      "Epoch 2193/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7537 - val_loss: 3.4220\n",
      "Epoch 2194/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 3.7538 - val_loss: 3.4205\n",
      "Epoch 2195/3000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 3.7534 - val_loss: 3.4194\n",
      "Epoch 2196/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7541 - val_loss: 3.4167\n",
      "Epoch 2197/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7529 - val_loss: 3.4153\n",
      "Epoch 2198/3000\n",
      "2/2 [==============================] - 0s 187ms/step - loss: 3.7527 - val_loss: 3.4134\n",
      "Epoch 2199/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.7529 - val_loss: 3.4129\n",
      "Epoch 2200/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7524 - val_loss: 3.4121\n",
      "Epoch 2201/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 3.7525 - val_loss: 3.4104\n",
      "Epoch 2202/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 3.7524 - val_loss: 3.4082\n",
      "Epoch 2203/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 3.7523 - val_loss: 3.4071\n",
      "Epoch 2204/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7519 - val_loss: 3.4059\n",
      "Epoch 2205/3000\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 3.7515 - val_loss: 3.4047\n",
      "Epoch 2206/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7514 - val_loss: 3.4034\n",
      "Epoch 2207/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7515 - val_loss: 3.4025\n",
      "Epoch 2208/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.7516 - val_loss: 3.4004\n",
      "Epoch 2209/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.7510 - val_loss: 3.3985\n",
      "Epoch 2210/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7506 - val_loss: 3.3966\n",
      "Epoch 2211/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7506 - val_loss: 3.3947\n",
      "Epoch 2212/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 3.7506 - val_loss: 3.3936\n",
      "Epoch 2213/3000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 3.7505 - val_loss: 3.3914\n",
      "Epoch 2214/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7504 - val_loss: 3.3892\n",
      "Epoch 2215/3000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 3.7502 - val_loss: 3.3888\n",
      "Epoch 2216/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7495 - val_loss: 3.3883\n",
      "Epoch 2217/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 3.7502 - val_loss: 3.3869\n",
      "Epoch 2218/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7496 - val_loss: 3.3866\n",
      "Epoch 2219/3000\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 3.7493 - val_loss: 3.3860\n",
      "Epoch 2220/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 3.7493 - val_loss: 3.3846\n",
      "Epoch 2221/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7490 - val_loss: 3.3838\n",
      "Epoch 2222/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7488 - val_loss: 3.3828\n",
      "Epoch 2223/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.7488 - val_loss: 3.3812\n",
      "Epoch 2224/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 3.7488 - val_loss: 3.3797\n",
      "Epoch 2225/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 3.7482 - val_loss: 3.3775\n",
      "Epoch 2226/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 3.7490 - val_loss: 3.3747\n",
      "Epoch 2227/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7485 - val_loss: 3.3729\n",
      "Epoch 2228/3000\n",
      "2/2 [==============================] - 0s 226ms/step - loss: 3.7478 - val_loss: 3.3718\n",
      "Epoch 2229/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7475 - val_loss: 3.3709\n",
      "Epoch 2230/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 3.7481 - val_loss: 3.3690\n",
      "Epoch 2231/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.7474 - val_loss: 3.3685\n",
      "Epoch 2232/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.7474 - val_loss: 3.3677\n",
      "Epoch 2233/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 3.7469 - val_loss: 3.3661\n",
      "Epoch 2234/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3.7470 - val_loss: 3.3645\n",
      "Epoch 2235/3000\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 3.7468 - val_loss: 3.3626\n",
      "Epoch 2236/3000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 3.7467 - val_loss: 3.3617\n",
      "Epoch 2237/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 3.911 - 0s 67ms/step - loss: 3.7466 - val_loss: 3.3598\n",
      "Epoch 2238/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3.7464 - val_loss: 3.3598\n",
      "Epoch 2239/3000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 3.7457 - val_loss: 3.3589\n",
      "Epoch 2240/3000\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 3.7462 - val_loss: 3.3577\n",
      "Epoch 2241/3000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 3.7459 - val_loss: 3.3569\n",
      "Epoch 2242/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.7459 - val_loss: 3.3563\n",
      "Epoch 2243/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7463 - val_loss: 3.3547\n",
      "Epoch 2244/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.7459 - val_loss: 3.3528\n",
      "Epoch 2245/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 3.7453 - val_loss: 3.3516\n",
      "Epoch 2246/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 3.7453 - val_loss: 3.3503\n",
      "Epoch 2247/3000\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 3.7449 - val_loss: 3.3492\n",
      "Epoch 2248/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.7450 - val_loss: 3.3478\n",
      "Epoch 2249/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7446 - val_loss: 3.3462\n",
      "Epoch 2250/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7445 - val_loss: 3.3442\n",
      "Epoch 2251/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7442 - val_loss: 3.3428\n",
      "Epoch 2252/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3.7444 - val_loss: 3.3411\n",
      "Epoch 2253/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.7439 - val_loss: 3.3403\n",
      "Epoch 2254/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7441 - val_loss: 3.3394\n",
      "Epoch 2255/3000\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 3.7437 - val_loss: 3.3384\n",
      "Epoch 2256/3000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 3.7438 - val_loss: 3.3370\n",
      "Epoch 2257/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7439 - val_loss: 3.3347\n",
      "Epoch 2258/3000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 3.7435 - val_loss: 3.3338\n",
      "Epoch 2259/3000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 3.7434 - val_loss: 3.3323\n",
      "Epoch 2260/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.7435 - val_loss: 3.3320\n",
      "Epoch 2261/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.7430 - val_loss: 3.3326\n",
      "Epoch 2262/3000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 3.7433 - val_loss: 3.3332\n",
      "Epoch 2263/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.7437 - val_loss: 3.3348\n",
      "Epoch 2264/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 3.7438 - val_loss: 3.3353\n",
      "Epoch 2265/3000\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 3.7434 - val_loss: 3.3343\n",
      "Epoch 2266/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7436 - val_loss: 3.3326\n",
      "Epoch 2267/3000\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 3.7431 - val_loss: 3.3311\n",
      "Epoch 2268/3000\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 3.7431 - val_loss: 3.3303\n",
      "Epoch 2269/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.7429 - val_loss: 3.3292\n",
      "Epoch 2270/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3.7429 - val_loss: 3.3285\n",
      "Epoch 2271/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7428 - val_loss: 3.3283\n",
      "Epoch 2272/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 3.7431 - val_loss: 3.3279\n",
      "Epoch 2273/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7427 - val_loss: 3.3281\n",
      "Epoch 2274/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7427 - val_loss: 3.3285\n",
      "Epoch 2275/3000\n",
      "2/2 [==============================] - 0s 195ms/step - loss: 3.7432 - val_loss: 3.3267\n",
      "Epoch 2276/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7427 - val_loss: 3.3257\n",
      "Epoch 2277/3000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 3.7424 - val_loss: 3.3258\n",
      "Epoch 2278/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7426 - val_loss: 3.3249\n",
      "Epoch 2279/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7427 - val_loss: 3.3239\n",
      "Epoch 2280/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7423 - val_loss: 3.3241\n",
      "Epoch 2281/3000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 3.7424 - val_loss: 3.3236\n",
      "Epoch 2282/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7422 - val_loss: 3.3222\n",
      "Epoch 2283/3000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 3.7422 - val_loss: 3.3207\n",
      "Epoch 2284/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 3.7429 - val_loss: 3.3207\n",
      "Epoch 2285/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 3.7423 - val_loss: 3.3225\n",
      "Epoch 2286/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7419 - val_loss: 3.3233\n",
      "Epoch 2287/3000\n",
      "2/2 [==============================] - 0s 126ms/step - loss: 3.7425 - val_loss: 3.3238\n",
      "Epoch 2288/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7425 - val_loss: 3.3231\n",
      "Epoch 2289/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.7426 - val_loss: 3.3221\n",
      "Epoch 2290/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 4.622 - 0s 52ms/step - loss: 3.7423 - val_loss: 3.3207\n",
      "Epoch 2291/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7420 - val_loss: 3.3197\n",
      "Epoch 2292/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3.7420 - val_loss: 3.3192\n",
      "Epoch 2293/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7421 - val_loss: 3.3180\n",
      "Epoch 2294/3000\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 3.7419 - val_loss: 3.3177\n",
      "Epoch 2295/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7419 - val_loss: 3.3172\n",
      "Epoch 2296/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7420 - val_loss: 3.3171\n",
      "Epoch 2297/3000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 3.7423 - val_loss: 3.3174\n",
      "Epoch 2298/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7420 - val_loss: 3.3166\n",
      "Epoch 2299/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.7416 - val_loss: 3.3160\n",
      "Epoch 2300/3000\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 3.7419 - val_loss: 3.3162\n",
      "Epoch 2301/3000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 3.7416 - val_loss: 3.3153\n",
      "Epoch 2302/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7415 - val_loss: 3.3139\n",
      "Epoch 2303/3000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 3.7415 - val_loss: 3.3129\n",
      "Epoch 2304/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.7424 - val_loss: 3.3116\n",
      "Epoch 2305/3000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 3.7415 - val_loss: 3.3118\n",
      "Epoch 2306/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 3.7416 - val_loss: 3.3125\n",
      "Epoch 2307/3000\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 3.7413 - val_loss: 3.3120\n",
      "Epoch 2308/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.7413 - val_loss: 3.3118\n",
      "Epoch 2309/3000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 3.7413 - val_loss: 3.3106\n",
      "Epoch 2310/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.7413 - val_loss: 3.3097\n",
      "Epoch 2311/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 3.7417 - val_loss: 3.3097\n",
      "Epoch 2312/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7412 - val_loss: 3.3084\n",
      "Epoch 2313/3000\n",
      "2/2 [==============================] - 0s 179ms/step - loss: 3.7411 - val_loss: 3.3071\n",
      "Epoch 2314/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7408 - val_loss: 3.3066\n",
      "Epoch 2315/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.7409 - val_loss: 3.3060\n",
      "Epoch 2316/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.7407 - val_loss: 3.3058\n",
      "Epoch 2317/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 3.7406 - val_loss: 3.3059\n",
      "Epoch 2318/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 3.7409 - val_loss: 3.3062\n",
      "Epoch 2319/3000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 3.7410 - val_loss: 3.3065\n",
      "Epoch 2320/3000\n",
      "2/2 [==============================] - 0s 204ms/step - loss: 3.7410 - val_loss: 3.3052\n",
      "Epoch 2321/3000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 3.7410 - val_loss: 3.3049\n",
      "Epoch 2322/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.7405 - val_loss: 3.3034\n",
      "Epoch 2323/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7408 - val_loss: 3.3029\n",
      "Epoch 2324/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 3.7407 - val_loss: 3.3012\n",
      "Epoch 2325/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7407 - val_loss: 3.3005\n",
      "Epoch 2326/3000\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 3.7406 - val_loss: 3.3001\n",
      "Epoch 2327/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7403 - val_loss: 3.2998\n",
      "Epoch 2328/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7402 - val_loss: 3.2998\n",
      "Epoch 2329/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7408 - val_loss: 3.2988\n",
      "Epoch 2330/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3.7406 - val_loss: 3.2993\n",
      "Epoch 2331/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7403 - val_loss: 3.2980\n",
      "Epoch 2332/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 3.7400 - val_loss: 3.2975\n",
      "Epoch 2333/3000\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 3.7405 - val_loss: 3.2973\n",
      "Epoch 2334/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.7403 - val_loss: 3.2965\n",
      "Epoch 2335/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3.7398 - val_loss: 3.2963\n",
      "Epoch 2336/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 3.7399 - val_loss: 3.2961\n",
      "Epoch 2337/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 3.7399 - val_loss: 3.2954\n",
      "Epoch 2338/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7400 - val_loss: 3.2947\n",
      "Epoch 2339/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7398 - val_loss: 3.2935\n",
      "Epoch 2340/3000\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 3.7397 - val_loss: 3.2926\n",
      "Epoch 2341/3000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 3.7398 - val_loss: 3.2918\n",
      "Epoch 2342/3000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 3.7398 - val_loss: 3.2911\n",
      "Epoch 2343/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.7399 - val_loss: 3.2916\n",
      "Epoch 2344/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7401 - val_loss: 3.2916\n",
      "Epoch 2345/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 3.7396 - val_loss: 3.2908\n",
      "Epoch 2346/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.7395 - val_loss: 3.2895\n",
      "Epoch 2347/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 3.7393 - val_loss: 3.2888\n",
      "Epoch 2348/3000\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 3.7393 - val_loss: 3.2888\n",
      "Epoch 2349/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.7392 - val_loss: 3.2891\n",
      "Epoch 2350/3000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 3.7394 - val_loss: 3.2895\n",
      "Epoch 2351/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 3.7398 - val_loss: 3.2891\n",
      "Epoch 2352/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.7394 - val_loss: 3.2877\n",
      "Epoch 2353/3000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 3.7398 - val_loss: 3.2864\n",
      "Epoch 2354/3000\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 3.7391 - val_loss: 3.2863\n",
      "Epoch 2355/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.7395 - val_loss: 3.2861\n",
      "Epoch 2356/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7392 - val_loss: 3.2856\n",
      "Epoch 2357/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7389 - val_loss: 3.2853\n",
      "Epoch 2358/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.7389 - val_loss: 3.2848\n",
      "Epoch 2359/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7389 - val_loss: 3.2842\n",
      "Epoch 2360/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3.7393 - val_loss: 3.2825\n",
      "Epoch 2361/3000\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 3.7391 - val_loss: 3.2810\n",
      "Epoch 2362/3000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 3.7388 - val_loss: 3.2805\n",
      "Epoch 2363/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7388 - val_loss: 3.2802\n",
      "Epoch 2364/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 3.7388 - val_loss: 3.2803\n",
      "Epoch 2365/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 3.7392 - val_loss: 3.2812\n",
      "Epoch 2366/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7387 - val_loss: 3.2810\n",
      "Epoch 2367/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.7389 - val_loss: 3.2797\n",
      "Epoch 2368/3000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 3.7384 - val_loss: 3.2781\n",
      "Epoch 2369/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 3.7385 - val_loss: 3.2772\n",
      "Epoch 2370/3000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 3.7387 - val_loss: 3.2760\n",
      "Epoch 2371/3000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 3.7385 - val_loss: 3.2760\n",
      "Epoch 2372/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.7386 - val_loss: 3.2757\n",
      "Epoch 2373/3000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 3.7383 - val_loss: 3.2763\n",
      "Epoch 2374/3000\n",
      "2/2 [==============================] - 0s 125ms/step - loss: 3.7385 - val_loss: 3.2779\n",
      "Epoch 2375/3000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 3.7388 - val_loss: 3.2776\n",
      "Epoch 2376/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7384 - val_loss: 3.2768\n",
      "Epoch 2377/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7382 - val_loss: 3.2759\n",
      "Epoch 2378/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.7383 - val_loss: 3.2753\n",
      "Epoch 2379/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7380 - val_loss: 3.2738\n",
      "Epoch 2380/3000\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 3.7380 - val_loss: 3.2729\n",
      "Epoch 2381/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7381 - val_loss: 3.2728\n",
      "Epoch 2382/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7383 - val_loss: 3.2722\n",
      "Epoch 2383/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.7382 - val_loss: 3.2723\n",
      "Epoch 2384/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7379 - val_loss: 3.2730\n",
      "Epoch 2385/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7383 - val_loss: 3.2738\n",
      "Epoch 2386/3000\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 3.7381 - val_loss: 3.2741\n",
      "Epoch 2387/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.7383 - val_loss: 3.2753\n",
      "Epoch 2388/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 3.7378 - val_loss: 3.2749\n",
      "Epoch 2389/3000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 3.7377 - val_loss: 3.2758\n",
      "Epoch 2390/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7377 - val_loss: 3.2753\n",
      "Epoch 2391/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 3.7374 - val_loss: 3.2762\n",
      "Epoch 2392/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7380 - val_loss: 3.2775\n",
      "Epoch 2393/3000\n",
      "2/2 [==============================] - 0s 160ms/step - loss: 3.7375 - val_loss: 3.2774\n",
      "Epoch 2394/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 3.7374 - val_loss: 3.2788\n",
      "Epoch 2395/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 3.7375 - val_loss: 3.2789\n",
      "Epoch 2396/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.7371 - val_loss: 3.2787\n",
      "Epoch 2397/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7375 - val_loss: 3.2791\n",
      "Epoch 2398/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7374 - val_loss: 3.2790\n",
      "Epoch 2399/3000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 3.7374 - val_loss: 3.2795\n",
      "Epoch 2400/3000\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 3.7373 - val_loss: 3.2804\n",
      "Epoch 2401/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3.7372 - val_loss: 3.2798\n",
      "Epoch 2402/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7371 - val_loss: 3.2792\n",
      "Epoch 2403/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7370 - val_loss: 3.2793\n",
      "Epoch 2404/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7371 - val_loss: 3.2798\n",
      "Epoch 2405/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 3.7372 - val_loss: 3.2812\n",
      "Epoch 2406/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7367 - val_loss: 3.2815\n",
      "Epoch 2407/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.7369 - val_loss: 3.2823\n",
      "Epoch 2408/3000\n",
      "2/2 [==============================] - 0s 169ms/step - loss: 3.7369 - val_loss: 3.2831\n",
      "Epoch 2409/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7368 - val_loss: 3.2838\n",
      "Epoch 2410/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7366 - val_loss: 3.2846\n",
      "Epoch 2411/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7368 - val_loss: 3.2862\n",
      "Epoch 2412/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7374 - val_loss: 3.2871\n",
      "Epoch 2413/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7364 - val_loss: 3.2875\n",
      "Epoch 2414/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 3.7367 - val_loss: 3.2874\n",
      "Epoch 2415/3000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 3.7366 - val_loss: 3.2876\n",
      "Epoch 2416/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.7363 - val_loss: 3.2884\n",
      "Epoch 2417/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 3.7367 - val_loss: 3.2884\n",
      "Epoch 2418/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 3.7364 - val_loss: 3.2889\n",
      "Epoch 2419/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7364 - val_loss: 3.2897\n",
      "Epoch 2420/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.7362 - val_loss: 3.2904\n",
      "Epoch 2421/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 3.7360 - val_loss: 3.2902\n",
      "Epoch 2422/3000\n",
      "2/2 [==============================] - 0s 150ms/step - loss: 3.7364 - val_loss: 3.2905\n",
      "Epoch 2423/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7363 - val_loss: 3.2908\n",
      "Epoch 2424/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3.7364 - val_loss: 3.2913\n",
      "Epoch 2425/3000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 3.7359 - val_loss: 3.2926\n",
      "Epoch 2426/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7359 - val_loss: 3.2935\n",
      "Epoch 2427/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.7360 - val_loss: 3.2932\n",
      "Epoch 2428/3000\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 3.7361 - val_loss: 3.2939\n",
      "Epoch 2429/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.7358 - val_loss: 3.2945\n",
      "Epoch 2430/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.7358 - val_loss: 3.2955\n",
      "Epoch 2431/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 3.7360 - val_loss: 3.2957\n",
      "Epoch 2432/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.7355 - val_loss: 3.2964\n",
      "Epoch 2433/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.7358 - val_loss: 3.2971\n",
      "Epoch 2434/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.7356 - val_loss: 3.2984\n",
      "Epoch 2435/3000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 3.7360 - val_loss: 3.2990\n",
      "Epoch 2436/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7356 - val_loss: 3.2990\n",
      "Epoch 2437/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.7352 - val_loss: 3.2992\n",
      "Epoch 2438/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7357 - val_loss: 3.2998\n",
      "Epoch 2439/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.7357 - val_loss: 3.2999\n",
      "Epoch 2440/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7357 - val_loss: 3.3009\n",
      "Epoch 2441/3000\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 3.7358 - val_loss: 3.3014\n",
      "Epoch 2442/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7355 - val_loss: 3.3021\n",
      "Epoch 2443/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7352 - val_loss: 3.3023\n",
      "Epoch 2444/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7354 - val_loss: 3.3021\n",
      "Epoch 2445/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7355 - val_loss: 3.3015\n",
      "Epoch 2446/3000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 3.7355 - val_loss: 3.3013\n",
      "Epoch 2447/3000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 3.7357 - val_loss: 3.3016\n",
      "Epoch 2448/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.7351 - val_loss: 3.3022\n",
      "Epoch 2449/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.7351 - val_loss: 3.3031\n",
      "Epoch 2450/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7349 - val_loss: 3.3037\n",
      "Epoch 2451/3000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 3.7352 - val_loss: 3.3057\n",
      "Epoch 2452/3000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 3.7347 - val_loss: 3.3069\n",
      "Epoch 2453/3000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 3.7347 - val_loss: 3.3079\n",
      "Epoch 2454/3000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 3.7348 - val_loss: 3.3091\n",
      "Epoch 2455/3000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 3.7348 - val_loss: 3.3104\n",
      "Epoch 2456/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7347 - val_loss: 3.3112\n",
      "Epoch 2457/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7346 - val_loss: 3.3132\n",
      "Epoch 2458/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.7345 - val_loss: 3.3146\n",
      "Epoch 2459/3000\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 3.7349 - val_loss: 3.3148\n",
      "Epoch 2460/3000\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 3.7345 - val_loss: 3.3148\n",
      "Epoch 2461/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.7346 - val_loss: 3.3145\n",
      "Epoch 2462/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7347 - val_loss: 3.3147\n",
      "Epoch 2463/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3.7345 - val_loss: 3.3146\n",
      "Epoch 2464/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7343 - val_loss: 3.3149\n",
      "Epoch 2465/3000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 3.7343 - val_loss: 3.3156\n",
      "Epoch 2466/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7345 - val_loss: 3.3172\n",
      "Epoch 2467/3000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 3.7342 - val_loss: 3.3185\n",
      "Epoch 2468/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.7339 - val_loss: 3.3196\n",
      "Epoch 2469/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7343 - val_loss: 3.3202\n",
      "Epoch 2470/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7345 - val_loss: 3.3201\n",
      "Epoch 2471/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 3.7340 - val_loss: 3.3199\n",
      "Epoch 2472/3000\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 3.7340 - val_loss: 3.3201\n",
      "Epoch 2473/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.7342 - val_loss: 3.3208\n",
      "Epoch 2474/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7339 - val_loss: 3.3217\n",
      "Epoch 2475/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7339 - val_loss: 3.3234\n",
      "Epoch 2476/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.7340 - val_loss: 3.3252\n",
      "Epoch 2477/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 3.7337 - val_loss: 3.3260\n",
      "Epoch 2478/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7339 - val_loss: 3.3271\n",
      "Epoch 2479/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.7338 - val_loss: 3.3265\n",
      "Epoch 2480/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7340 - val_loss: 3.3268\n",
      "Epoch 2481/3000\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 3.7337 - val_loss: 3.3271\n",
      "Epoch 2482/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7335 - val_loss: 3.3274\n",
      "Epoch 2483/3000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 3.7340 - val_loss: 3.3286\n",
      "Epoch 2484/3000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 3.7338 - val_loss: 3.3292\n",
      "Epoch 2485/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 3.7336 - val_loss: 3.3299\n",
      "Epoch 2486/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7334 - val_loss: 3.3312\n",
      "Epoch 2487/3000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 3.7334 - val_loss: 3.3324\n",
      "Epoch 2488/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.7336 - val_loss: 3.3340\n",
      "Epoch 2489/3000\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 3.7335 - val_loss: 3.3352\n",
      "Epoch 2490/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7332 - val_loss: 3.3351\n",
      "Epoch 2491/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.7332 - val_loss: 3.3353\n",
      "Epoch 2492/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 3.7332 - val_loss: 3.3356\n",
      "Epoch 2493/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7333 - val_loss: 3.3363\n",
      "Epoch 2494/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7331 - val_loss: 3.3369\n",
      "Epoch 2495/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 3.7331 - val_loss: 3.3371\n",
      "Epoch 2496/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 3.7331 - val_loss: 3.3374\n",
      "Epoch 2497/3000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 3.7329 - val_loss: 3.3371\n",
      "Epoch 2498/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.7330 - val_loss: 3.3374\n",
      "Epoch 2499/3000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 3.7328 - val_loss: 3.3385\n",
      "Epoch 2500/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7335 - val_loss: 3.3397\n",
      "Epoch 2501/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7330 - val_loss: 3.3412\n",
      "Epoch 2502/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 3.7328 - val_loss: 3.3421\n",
      "Epoch 2503/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7326 - val_loss: 3.3428\n",
      "Epoch 2504/3000\n",
      "2/2 [==============================] - 0s 192ms/step - loss: 3.7328 - val_loss: 3.3434\n",
      "Epoch 2505/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 3.7327 - val_loss: 3.3437\n",
      "Epoch 2506/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.7325 - val_loss: 3.3440\n",
      "Epoch 2507/3000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 3.7324 - val_loss: 3.3443\n",
      "Epoch 2508/3000\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 3.7325 - val_loss: 3.3451\n",
      "Epoch 2509/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7324 - val_loss: 3.3463\n",
      "Epoch 2510/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7323 - val_loss: 3.3473\n",
      "Epoch 2511/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.7330 - val_loss: 3.3490\n",
      "Epoch 2512/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.7323 - val_loss: 3.3501\n",
      "Epoch 2513/3000\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 3.7330 - val_loss: 3.3506\n",
      "Epoch 2514/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 3.7326 - val_loss: 3.3512\n",
      "Epoch 2515/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7321 - val_loss: 3.3517\n",
      "Epoch 2516/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 3.7321 - val_loss: 3.3516\n",
      "Epoch 2517/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 3.7321 - val_loss: 3.3523\n",
      "Epoch 2518/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 3.7323 - val_loss: 3.3531\n",
      "Epoch 2519/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3.7321 - val_loss: 3.3544\n",
      "Epoch 2520/3000\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 3.7320 - val_loss: 3.3555\n",
      "Epoch 2521/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.7321 - val_loss: 3.3575\n",
      "Epoch 2522/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7318 - val_loss: 3.3583\n",
      "Epoch 2523/3000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 3.7319 - val_loss: 3.3586\n",
      "Epoch 2524/3000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 3.7315 - val_loss: 3.3597\n",
      "Epoch 2525/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.7316 - val_loss: 3.3602\n",
      "Epoch 2526/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.7317 - val_loss: 3.3611\n",
      "Epoch 2527/3000\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 3.7321 - val_loss: 3.3610\n",
      "Epoch 2528/3000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 3.7319 - val_loss: 3.3605\n",
      "Epoch 2529/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7317 - val_loss: 3.3605\n",
      "Epoch 2530/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7321 - val_loss: 3.3621\n",
      "Epoch 2531/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7318 - val_loss: 3.3627\n",
      "Epoch 2532/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 3.7322 - val_loss: 3.3635\n",
      "Epoch 2533/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.7316 - val_loss: 3.3641\n",
      "Epoch 2534/3000\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 3.7321 - val_loss: 3.3643\n",
      "Epoch 2535/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7316 - val_loss: 3.3645\n",
      "Epoch 2536/3000\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 3.7315 - val_loss: 3.3652\n",
      "Epoch 2537/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.7311 - val_loss: 3.3656\n",
      "Epoch 2538/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.7319 - val_loss: 3.3677\n",
      "Epoch 2539/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7310 - val_loss: 3.3685\n",
      "Epoch 2540/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.7315 - val_loss: 3.3696\n",
      "Epoch 2541/3000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 3.7311 - val_loss: 3.3696\n",
      "Epoch 2542/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7324 - val_loss: 3.3711\n",
      "Epoch 2543/3000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 3.7317 - val_loss: 3.3715\n",
      "Epoch 2544/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7310 - val_loss: 3.3721\n",
      "Epoch 2545/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7309 - val_loss: 3.3738\n",
      "Epoch 2546/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7312 - val_loss: 3.3749\n",
      "Epoch 2547/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7309 - val_loss: 3.3755\n",
      "Epoch 2548/3000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 3.7308 - val_loss: 3.3757\n",
      "Epoch 2549/3000\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 3.7306 - val_loss: 3.3760\n",
      "Epoch 2550/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3.7306 - val_loss: 3.3765\n",
      "Epoch 2551/3000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 3.7306 - val_loss: 3.3772\n",
      "Epoch 2552/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.7305 - val_loss: 3.3783\n",
      "Epoch 2553/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7305 - val_loss: 3.3792\n",
      "Epoch 2554/3000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 3.7306 - val_loss: 3.3795\n",
      "Epoch 2555/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7304 - val_loss: 3.3792\n",
      "Epoch 2556/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 3.7303 - val_loss: 3.3794\n",
      "Epoch 2557/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7305 - val_loss: 3.3797\n",
      "Epoch 2558/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7306 - val_loss: 3.3805\n",
      "Epoch 2559/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 3.7307 - val_loss: 3.3810\n",
      "Epoch 2560/3000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 3.7301 - val_loss: 3.3817\n",
      "Epoch 2561/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7303 - val_loss: 3.3833\n",
      "Epoch 2562/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7303 - val_loss: 3.3839\n",
      "Epoch 2563/3000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 3.7300 - val_loss: 3.3845\n",
      "Epoch 2564/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7308 - val_loss: 3.3866\n",
      "Epoch 2565/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7304 - val_loss: 3.3875\n",
      "Epoch 2566/3000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 3.7301 - val_loss: 3.3877\n",
      "Epoch 2567/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.7307 - val_loss: 3.3880\n",
      "Epoch 2568/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 3.7304 - val_loss: 3.3885\n",
      "Epoch 2569/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7300 - val_loss: 3.3893\n",
      "Epoch 2570/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3.7301 - val_loss: 3.3906\n",
      "Epoch 2571/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 3.7300 - val_loss: 3.3910\n",
      "Epoch 2572/3000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 3.7300 - val_loss: 3.3915\n",
      "Epoch 2573/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.7295 - val_loss: 3.3919\n",
      "Epoch 2574/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 3.7298 - val_loss: 3.3923\n",
      "Epoch 2575/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7304 - val_loss: 3.3934\n",
      "Epoch 2576/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7304 - val_loss: 3.3946\n",
      "Epoch 2577/3000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 3.7295 - val_loss: 3.3953\n",
      "Epoch 2578/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 3.7293 - val_loss: 3.3960\n",
      "Epoch 2579/3000\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 3.7295 - val_loss: 3.3965\n",
      "Epoch 2580/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.7302 - val_loss: 3.3965\n",
      "Epoch 2581/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7299 - val_loss: 3.3968\n",
      "Epoch 2582/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.7296 - val_loss: 3.3966\n",
      "Epoch 2583/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7300 - val_loss: 3.3969\n",
      "Epoch 2584/3000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 3.7296 - val_loss: 3.3976\n",
      "Epoch 2585/3000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 3.7296 - val_loss: 3.3983\n",
      "Epoch 2586/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7296 - val_loss: 3.3987\n",
      "Epoch 2587/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.7301 - val_loss: 3.3984\n",
      "Epoch 2588/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7298 - val_loss: 3.3980\n",
      "Epoch 2589/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.7294 - val_loss: 3.3979\n",
      "Epoch 2590/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7295 - val_loss: 3.3981\n",
      "Epoch 2591/3000\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 3.7294 - val_loss: 3.3978\n",
      "Epoch 2592/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7298 - val_loss: 3.3974\n",
      "Epoch 2593/3000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 3.7294 - val_loss: 3.3969\n",
      "Epoch 2594/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7295 - val_loss: 3.3960\n",
      "Epoch 2595/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 3.7298 - val_loss: 3.3955\n",
      "Epoch 2596/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 3.7295 - val_loss: 3.3956\n",
      "Epoch 2597/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7295 - val_loss: 3.3957\n",
      "Epoch 2598/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7296 - val_loss: 3.3956\n",
      "Epoch 2599/3000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 3.7304 - val_loss: 3.3950\n",
      "Epoch 2600/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.7301 - val_loss: 3.3958\n",
      "Epoch 2601/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7294 - val_loss: 3.3954\n",
      "Epoch 2602/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.7298 - val_loss: 3.3955\n",
      "Epoch 2603/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7297 - val_loss: 3.3951\n",
      "Epoch 2604/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 3.7295 - val_loss: 3.3951\n",
      "Epoch 2605/3000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 3.7295 - val_loss: 3.3956\n",
      "Epoch 2606/3000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 3.7297 - val_loss: 3.3964\n",
      "Epoch 2607/3000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 3.7302 - val_loss: 3.3971\n",
      "Epoch 2608/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7297 - val_loss: 3.3971\n",
      "Epoch 2609/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7295 - val_loss: 3.3971\n",
      "Epoch 2610/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.7303 - val_loss: 3.3974\n",
      "Epoch 2611/3000\n",
      "2/2 [==============================] - 0s 253ms/step - loss: 3.7295 - val_loss: 3.3975\n",
      "Epoch 2612/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.7299 - val_loss: 3.3982\n",
      "Epoch 2613/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7296 - val_loss: 3.3982\n",
      "Epoch 2614/3000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 3.7295 - val_loss: 3.3974\n",
      "Epoch 2615/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.7297 - val_loss: 3.3966\n",
      "Epoch 2616/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7295 - val_loss: 3.3958\n",
      "Epoch 2617/3000\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 3.7297 - val_loss: 3.3941\n",
      "Epoch 2618/3000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 3.7299 - val_loss: 3.3928\n",
      "Epoch 2619/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.7298 - val_loss: 3.3923\n",
      "Epoch 2620/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7298 - val_loss: 3.3923\n",
      "Epoch 2621/3000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 3.7296 - val_loss: 3.3927\n",
      "Epoch 2622/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7297 - val_loss: 3.3935\n",
      "Epoch 2623/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 3.938 - 0s 39ms/step - loss: 3.7297 - val_loss: 3.3939\n",
      "Epoch 2624/3000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 3.7295 - val_loss: 3.3934\n",
      "Epoch 2625/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.7296 - val_loss: 3.3937\n",
      "Epoch 2626/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7298 - val_loss: 3.3947\n",
      "Epoch 2627/3000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 3.7298 - val_loss: 3.3951\n",
      "Epoch 2628/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 3.7295 - val_loss: 3.3958\n",
      "Epoch 2629/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7297 - val_loss: 3.3949\n",
      "Epoch 2630/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 3.674 - 0s 184ms/step - loss: 3.7295 - val_loss: 3.3956\n",
      "Epoch 2631/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7293 - val_loss: 3.3954\n",
      "Epoch 2632/3000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 3.7296 - val_loss: 3.3951\n",
      "Epoch 2633/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.7298 - val_loss: 3.3957\n",
      "Epoch 2634/3000\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 3.7296 - val_loss: 3.3970\n",
      "Epoch 2635/3000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 3.7295 - val_loss: 3.3972\n",
      "Epoch 2636/3000\n",
      "2/2 [==============================] - 0s 155ms/step - loss: 3.7299 - val_loss: 3.3964\n",
      "Epoch 2637/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7294 - val_loss: 3.3955\n",
      "Epoch 2638/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.7294 - val_loss: 3.3950\n",
      "Epoch 2639/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.7292 - val_loss: 3.3952\n",
      "Epoch 2640/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7295 - val_loss: 3.3952\n",
      "Epoch 2641/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 3.7295 - val_loss: 3.3959\n",
      "Epoch 2642/3000\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 3.7296 - val_loss: 3.3968\n",
      "Epoch 2643/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7298 - val_loss: 3.3984\n",
      "Epoch 2644/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.7296 - val_loss: 3.3989\n",
      "Epoch 2645/3000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 3.7300 - val_loss: 3.3989\n",
      "Epoch 2646/3000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 3.7298 - val_loss: 3.3984\n",
      "Epoch 2647/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7298 - val_loss: 3.3969\n",
      "Epoch 2648/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7298 - val_loss: 3.3956\n",
      "Epoch 2649/3000\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 3.7298 - val_loss: 3.3939\n",
      "Epoch 2650/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7296 - val_loss: 3.3931\n",
      "Epoch 2651/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7298 - val_loss: 3.3924\n",
      "Epoch 2652/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 3.7296 - val_loss: 3.3923\n",
      "Epoch 2653/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7300 - val_loss: 3.3932\n",
      "Epoch 2654/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 3.7297 - val_loss: 3.3943\n",
      "Epoch 2655/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7297 - val_loss: 3.3955\n",
      "Epoch 2656/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.7294 - val_loss: 3.3966\n",
      "Epoch 2657/3000\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 3.7297 - val_loss: 3.3979\n",
      "Epoch 2658/3000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 3.7301 - val_loss: 3.3996\n",
      "Epoch 2659/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 3.670 - 0s 58ms/step - loss: 3.7296 - val_loss: 3.3993\n",
      "Epoch 2660/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7299 - val_loss: 3.3989\n",
      "Epoch 2661/3000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 3.7298 - val_loss: 3.3981\n",
      "Epoch 2662/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7296 - val_loss: 3.3981\n",
      "Epoch 2663/3000\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 3.7294 - val_loss: 3.3967\n",
      "Epoch 2664/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7298 - val_loss: 3.3961\n",
      "Epoch 2665/3000\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 3.7298 - val_loss: 3.3950\n",
      "Epoch 2666/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 3.7297 - val_loss: 3.3952\n",
      "Epoch 2667/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3.7298 - val_loss: 3.3945\n",
      "Epoch 2668/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7298 - val_loss: 3.3951\n",
      "Epoch 2669/3000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 3.7297 - val_loss: 3.3960\n",
      "Epoch 2670/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7294 - val_loss: 3.3954\n",
      "Epoch 2671/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7296 - val_loss: 3.3952\n",
      "Epoch 2672/3000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 3.7297 - val_loss: 3.3957\n",
      "Epoch 2673/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 3.7294 - val_loss: 3.3964\n",
      "Epoch 2674/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7298 - val_loss: 3.3969\n",
      "Epoch 2675/3000\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 3.7300 - val_loss: 3.3958\n",
      "Epoch 2676/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7296 - val_loss: 3.3945\n",
      "Epoch 2677/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7299 - val_loss: 3.3949\n",
      "Epoch 2678/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7299 - val_loss: 3.3956\n",
      "Epoch 2679/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7294 - val_loss: 3.3961\n",
      "Epoch 2680/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3.7293 - val_loss: 3.3963\n",
      "Epoch 2681/3000\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 3.7298 - val_loss: 3.3970\n",
      "Epoch 2682/3000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 3.7297 - val_loss: 3.3958\n",
      "Epoch 2683/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7295 - val_loss: 3.3946\n",
      "Epoch 2684/3000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 3.7296 - val_loss: 3.3936\n",
      "Epoch 2685/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 3.7296 - val_loss: 3.3934\n",
      "Epoch 2686/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 3.7295 - val_loss: 3.3941\n",
      "Epoch 2687/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 3.7297 - val_loss: 3.3947\n",
      "Epoch 2688/3000\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 3.7299 - val_loss: 3.3945\n",
      "Epoch 2689/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 3.7295 - val_loss: 3.3952\n",
      "Epoch 2690/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7295 - val_loss: 3.3967\n",
      "Epoch 2691/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 3.7295 - val_loss: 3.3979\n",
      "Epoch 2692/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7298 - val_loss: 3.3981\n",
      "Epoch 2693/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.7294 - val_loss: 3.3977\n",
      "Epoch 2694/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7302 - val_loss: 3.3964\n",
      "Epoch 2695/3000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 3.7295 - val_loss: 3.3960\n",
      "Epoch 2696/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7301 - val_loss: 3.3962\n",
      "Epoch 2697/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.7301 - val_loss: 3.3960\n",
      "Epoch 2698/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.7300 - val_loss: 3.3956\n",
      "Epoch 2699/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 3.7296 - val_loss: 3.3951\n",
      "Epoch 2700/3000\n",
      "2/2 [==============================] - 0s 165ms/step - loss: 3.7299 - val_loss: 3.3955\n",
      "Epoch 2701/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.7298 - val_loss: 3.3960\n",
      "Epoch 2702/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7296 - val_loss: 3.3967\n",
      "Epoch 2703/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 3.7295 - val_loss: 3.3959\n",
      "Epoch 2704/3000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 3.7294 - val_loss: 3.3949\n",
      "Epoch 2705/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7294 - val_loss: 3.3950\n",
      "Epoch 2706/3000\n",
      "2/2 [==============================] - 0s 151ms/step - loss: 3.7297 - val_loss: 3.3957\n",
      "Epoch 2707/3000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 3.7294 - val_loss: 3.3962\n",
      "Epoch 2708/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 3.7303 - val_loss: 3.3976\n",
      "Epoch 2709/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 3.7300 - val_loss: 3.3981\n",
      "Epoch 2710/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.7296 - val_loss: 3.3982\n",
      "Epoch 2711/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7295 - val_loss: 3.3979\n",
      "Epoch 2712/3000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 3.7296 - val_loss: 3.3979\n",
      "Epoch 2713/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7300 - val_loss: 3.3984\n",
      "Epoch 2714/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7297 - val_loss: 3.3971\n",
      "Epoch 2715/3000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 3.7294 - val_loss: 3.3966\n",
      "Epoch 2716/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7300 - val_loss: 3.3960\n",
      "Epoch 2717/3000\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 3.7296 - val_loss: 3.3958\n",
      "Epoch 2718/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7297 - val_loss: 3.3954\n",
      "Epoch 2719/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 3.7295 - val_loss: 3.3958\n",
      "Epoch 2720/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7301 - val_loss: 3.3971\n",
      "Epoch 2721/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7295 - val_loss: 3.3967\n",
      "Epoch 2722/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.7295 - val_loss: 3.3967\n",
      "Epoch 2723/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 3.7296 - val_loss: 3.3964\n",
      "Epoch 2724/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 3.7294 - val_loss: 3.3965\n",
      "Epoch 2725/3000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 3.7299 - val_loss: 3.3961\n",
      "Epoch 2726/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7300 - val_loss: 3.3964\n",
      "Epoch 2727/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.7296 - val_loss: 3.3964\n",
      "Epoch 2728/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3.7297 - val_loss: 3.3972\n",
      "Epoch 2729/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7298 - val_loss: 3.3969\n",
      "Epoch 2730/3000\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 3.7299 - val_loss: 3.3969\n",
      "Epoch 2731/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7297 - val_loss: 3.3977\n",
      "Epoch 2732/3000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 3.7299 - val_loss: 3.3982\n",
      "Epoch 2733/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7296 - val_loss: 3.3983\n",
      "Epoch 2734/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7303 - val_loss: 3.3981\n",
      "Epoch 2735/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.7296 - val_loss: 3.3978\n",
      "Epoch 2736/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7300 - val_loss: 3.3963\n",
      "Epoch 2737/3000\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 3.7300 - val_loss: 3.3952\n",
      "Epoch 2738/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7297 - val_loss: 3.3941\n",
      "Epoch 2739/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7295 - val_loss: 3.3940\n",
      "Epoch 2740/3000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 3.7295 - val_loss: 3.3945\n",
      "Epoch 2741/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7296 - val_loss: 3.3954\n",
      "Epoch 2742/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.7296 - val_loss: 3.3963\n",
      "Epoch 2743/3000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 3.7297 - val_loss: 3.3970\n",
      "Epoch 2744/3000\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 3.7294 - val_loss: 3.3976\n",
      "Epoch 2745/3000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 3.7296 - val_loss: 3.3984\n",
      "Epoch 2746/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7302 - val_loss: 3.3982\n",
      "Epoch 2747/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7297 - val_loss: 3.3984\n",
      "Epoch 2748/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7299 - val_loss: 3.3978\n",
      "Epoch 2749/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7297 - val_loss: 3.3968\n",
      "Epoch 2750/3000\n",
      "2/2 [==============================] - 0s 242ms/step - loss: 3.7296 - val_loss: 3.3964\n",
      "Epoch 2751/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7294 - val_loss: 3.3958\n",
      "Epoch 2752/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.7293 - val_loss: 3.3953\n",
      "Epoch 2753/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.7299 - val_loss: 3.3957\n",
      "Epoch 2754/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7297 - val_loss: 3.3949\n",
      "Epoch 2755/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.7296 - val_loss: 3.3944\n",
      "Epoch 2756/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 3.7298 - val_loss: 3.3952\n",
      "Epoch 2757/3000\n",
      "2/2 [==============================] - 0s 168ms/step - loss: 3.7296 - val_loss: 3.3953\n",
      "Epoch 2758/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.7294 - val_loss: 3.3951\n",
      "Epoch 2759/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7296 - val_loss: 3.3947\n",
      "Epoch 2760/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.7297 - val_loss: 3.3954\n",
      "Epoch 2761/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7298 - val_loss: 3.3954\n",
      "Epoch 2762/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 3.7296 - val_loss: 3.3950\n",
      "Epoch 2763/3000\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 3.7294 - val_loss: 3.3949\n",
      "Epoch 2764/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.7295 - val_loss: 3.3942\n",
      "Epoch 2765/3000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 3.7295 - val_loss: 3.3948\n",
      "Epoch 2766/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.7302 - val_loss: 3.3955\n",
      "Epoch 2767/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7298 - val_loss: 3.3960\n",
      "Epoch 2768/3000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 3.7294 - val_loss: 3.3965\n",
      "Epoch 2769/3000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 3.7299 - val_loss: 3.3971\n",
      "Epoch 2770/3000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 3.7297 - val_loss: 3.3977\n",
      "Epoch 2771/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 3.7296 - val_loss: 3.3982\n",
      "Epoch 2772/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7298 - val_loss: 3.3985\n",
      "Epoch 2773/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 3.524 - 0s 53ms/step - loss: 3.7295 - val_loss: 3.3982\n",
      "Epoch 2774/3000\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 3.7296 - val_loss: 3.3986\n",
      "Epoch 2775/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7297 - val_loss: 3.3985\n",
      "Epoch 2776/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7302 - val_loss: 3.3982\n",
      "Epoch 2777/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7294 - val_loss: 3.3971\n",
      "Epoch 2778/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3.7294 - val_loss: 3.3961\n",
      "Epoch 2779/3000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 3.7297 - val_loss: 3.3947\n",
      "Epoch 2780/3000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 3.7301 - val_loss: 3.3951\n",
      "Epoch 2781/3000\n",
      "2/2 [==============================] - 0s 193ms/step - loss: 3.7296 - val_loss: 3.3936\n",
      "Epoch 2782/3000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 3.7296 - val_loss: 3.3936\n",
      "Epoch 2783/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7299 - val_loss: 3.3925\n",
      "Epoch 2784/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7297 - val_loss: 3.3925\n",
      "Epoch 2785/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 3.7302 - val_loss: 3.3936\n",
      "Epoch 2786/3000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 3.7298 - val_loss: 3.3944\n",
      "Epoch 2787/3000\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 3.7295 - val_loss: 3.3943\n",
      "Epoch 2788/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 3.7298 - val_loss: 3.3943\n",
      "Epoch 2789/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7295 - val_loss: 3.3953\n",
      "Epoch 2790/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7298 - val_loss: 3.3957\n",
      "Epoch 2791/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 3.7300 - val_loss: 3.3963\n",
      "Epoch 2792/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 3.7296 - val_loss: 3.3955\n",
      "Epoch 2793/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7300 - val_loss: 3.3958\n",
      "Epoch 2794/3000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 3.7295 - val_loss: 3.3958\n",
      "Epoch 2795/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7295 - val_loss: 3.3950\n",
      "Epoch 2796/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.7298 - val_loss: 3.3951\n",
      "Epoch 2797/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7295 - val_loss: 3.3945\n",
      "Epoch 2798/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 3.7296 - val_loss: 3.3952\n",
      "Epoch 2799/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.7295 - val_loss: 3.3950\n",
      "Epoch 2800/3000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 3.7293 - val_loss: 3.3950\n",
      "Epoch 2801/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.7298 - val_loss: 3.3945\n",
      "Epoch 2802/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.7294 - val_loss: 3.3952\n",
      "Epoch 2803/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 3.7295 - val_loss: 3.3960\n",
      "Epoch 2804/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7295 - val_loss: 3.3967\n",
      "Epoch 2805/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7294 - val_loss: 3.3967\n",
      "Epoch 2806/3000\n",
      "2/2 [==============================] - 0s 141ms/step - loss: 3.7294 - val_loss: 3.3968\n",
      "Epoch 2807/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7293 - val_loss: 3.3968\n",
      "Epoch 2808/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.7296 - val_loss: 3.3968\n",
      "Epoch 2809/3000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 3.7296 - val_loss: 3.3968\n",
      "Epoch 2810/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7299 - val_loss: 3.3957\n",
      "Epoch 2811/3000\n",
      "2/2 [==============================] - 0s 161ms/step - loss: 3.7295 - val_loss: 3.3958\n",
      "Epoch 2812/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7294 - val_loss: 3.3956\n",
      "Epoch 2813/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.7294 - val_loss: 3.3952\n",
      "Epoch 2814/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.7297 - val_loss: 3.3960\n",
      "Epoch 2815/3000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 3.7295 - val_loss: 3.3967\n",
      "Epoch 2816/3000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 3.7295 - val_loss: 3.3979\n",
      "Epoch 2817/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.7294 - val_loss: 3.3983\n",
      "Epoch 2818/3000\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 3.7297 - val_loss: 3.3988\n",
      "Epoch 2819/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7298 - val_loss: 3.3982\n",
      "Epoch 2820/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7298 - val_loss: 3.3968\n",
      "Epoch 2821/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7295 - val_loss: 3.3959\n",
      "Epoch 2822/3000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 3.7300 - val_loss: 3.3951\n",
      "Epoch 2823/3000\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 3.7298 - val_loss: 3.3949\n",
      "Epoch 2824/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7297 - val_loss: 3.3947\n",
      "Epoch 2825/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7296 - val_loss: 3.3954\n",
      "Epoch 2826/3000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 3.7300 - val_loss: 3.3956\n",
      "Epoch 2827/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7296 - val_loss: 3.3956\n",
      "Epoch 2828/3000\n",
      "2/2 [==============================] - 0s 196ms/step - loss: 3.7295 - val_loss: 3.3951\n",
      "Epoch 2829/3000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 3.7299 - val_loss: 3.3961\n",
      "Epoch 2830/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7298 - val_loss: 3.3968\n",
      "Epoch 2831/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7297 - val_loss: 3.3968\n",
      "Epoch 2832/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7293 - val_loss: 3.3974\n",
      "Epoch 2833/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7299 - val_loss: 3.3986\n",
      "Epoch 2834/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7299 - val_loss: 3.3986\n",
      "Epoch 2835/3000\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 3.7297 - val_loss: 3.3985\n",
      "Epoch 2836/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.7305 - val_loss: 3.3990\n",
      "Epoch 2837/3000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 3.7301 - val_loss: 3.3990\n",
      "Epoch 2838/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.7305 - val_loss: 3.3988\n",
      "Epoch 2839/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7299 - val_loss: 3.3991\n",
      "Epoch 2840/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7298 - val_loss: 3.3984\n",
      "Epoch 2841/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.7304 - val_loss: 3.3963\n",
      "Epoch 2842/3000\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 3.7296 - val_loss: 3.3955\n",
      "Epoch 2843/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7296 - val_loss: 3.3947\n",
      "Epoch 2844/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.7301 - val_loss: 3.3939\n",
      "Epoch 2845/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7295 - val_loss: 3.3942\n",
      "Epoch 2846/3000\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 3.7294 - val_loss: 3.3947\n",
      "Epoch 2847/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7296 - val_loss: 3.3954\n",
      "Epoch 2848/3000\n",
      "2/2 [==============================] - 0s 185ms/step - loss: 3.7297 - val_loss: 3.3965\n",
      "Epoch 2849/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.7295 - val_loss: 3.3968\n",
      "Epoch 2850/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.7295 - val_loss: 3.3972\n",
      "Epoch 2851/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7301 - val_loss: 3.3978\n",
      "Epoch 2852/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 3.7297 - val_loss: 3.3973\n",
      "Epoch 2853/3000\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 3.7295 - val_loss: 3.3961\n",
      "Epoch 2854/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 3.7296 - val_loss: 3.3954\n",
      "Epoch 2855/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.7297 - val_loss: 3.3952\n",
      "Epoch 2856/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 3.7300 - val_loss: 3.3950\n",
      "Epoch 2857/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7297 - val_loss: 3.3959\n",
      "Epoch 2858/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.7297 - val_loss: 3.3965\n",
      "Epoch 2859/3000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 3.7295 - val_loss: 3.3967\n",
      "Epoch 2860/3000\n",
      "2/2 [==============================] - 0s 140ms/step - loss: 3.7296 - val_loss: 3.3958\n",
      "Epoch 2861/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.7301 - val_loss: 3.3952\n",
      "Epoch 2862/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7301 - val_loss: 3.3956\n",
      "Epoch 2863/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7294 - val_loss: 3.3957\n",
      "Epoch 2864/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 3.7296 - val_loss: 3.3961\n",
      "Epoch 2865/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7298 - val_loss: 3.3951\n",
      "Epoch 2866/3000\n",
      "2/2 [==============================] - 0s 142ms/step - loss: 3.7294 - val_loss: 3.3950\n",
      "Epoch 2867/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.7295 - val_loss: 3.3954\n",
      "Epoch 2868/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.7297 - val_loss: 3.3962\n",
      "Epoch 2869/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7298 - val_loss: 3.3965\n",
      "Epoch 2870/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7297 - val_loss: 3.3975\n",
      "Epoch 2871/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7298 - val_loss: 3.3979\n",
      "Epoch 2872/3000\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 3.7299 - val_loss: 3.3980\n",
      "Epoch 2873/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.7295 - val_loss: 3.3976\n",
      "Epoch 2874/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7293 - val_loss: 3.3967\n",
      "Epoch 2875/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7293 - val_loss: 3.3961\n",
      "Epoch 2876/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7295 - val_loss: 3.3950\n",
      "Epoch 2877/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7296 - val_loss: 3.3947\n",
      "Epoch 2878/3000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 3.7299 - val_loss: 3.3943\n",
      "Epoch 2879/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.7298 - val_loss: 3.3951\n",
      "Epoch 2880/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7295 - val_loss: 3.3951\n",
      "Epoch 2881/3000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 3.7293 - val_loss: 3.3958\n",
      "Epoch 2882/3000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 3.7293 - val_loss: 3.3961\n",
      "Epoch 2883/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 3.7295 - val_loss: 3.3972\n",
      "Epoch 2884/3000\n",
      "2/2 [==============================] - 0s 163ms/step - loss: 3.7293 - val_loss: 3.3969\n",
      "Epoch 2885/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7294 - val_loss: 3.3966\n",
      "Epoch 2886/3000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 3.7294 - val_loss: 3.3961\n",
      "Epoch 2887/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.7293 - val_loss: 3.3964\n",
      "Epoch 2888/3000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 3.7294 - val_loss: 3.3963\n",
      "Epoch 2889/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7293 - val_loss: 3.3965\n",
      "Epoch 2890/3000\n",
      "2/2 [==============================] - 0s 154ms/step - loss: 3.7296 - val_loss: 3.3966\n",
      "Epoch 2891/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.7296 - val_loss: 3.3959\n",
      "Epoch 2892/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.7294 - val_loss: 3.3954\n",
      "Epoch 2893/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.7293 - val_loss: 3.3953\n",
      "Epoch 2894/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 3.7295 - val_loss: 3.3960\n",
      "Epoch 2895/3000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 3.7294 - val_loss: 3.3957\n",
      "Epoch 2896/3000\n",
      "2/2 [==============================] - 0s 236ms/step - loss: 3.7294 - val_loss: 3.3963\n",
      "Epoch 2897/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7293 - val_loss: 3.3963\n",
      "Epoch 2898/3000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 3.7297 - val_loss: 3.3960\n",
      "Epoch 2899/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7293 - val_loss: 3.3961\n",
      "Epoch 2900/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7298 - val_loss: 3.3963\n",
      "Epoch 2901/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7298 - val_loss: 3.3953\n",
      "Epoch 2902/3000\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 3.7294 - val_loss: 3.3945\n",
      "Epoch 2903/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7297 - val_loss: 3.3934\n",
      "Epoch 2904/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.7299 - val_loss: 3.3927\n",
      "Epoch 2905/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7297 - val_loss: 3.3936\n",
      "Epoch 2906/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7295 - val_loss: 3.3946\n",
      "Epoch 2907/3000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 3.7297 - val_loss: 3.3945\n",
      "Epoch 2908/3000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 3.7295 - val_loss: 3.3955\n",
      "Epoch 2909/3000\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 3.7294 - val_loss: 3.3954\n",
      "Epoch 2910/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3.7299 - val_loss: 3.3952\n",
      "Epoch 2911/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7301 - val_loss: 3.3962\n",
      "Epoch 2912/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7295 - val_loss: 3.3965\n",
      "Epoch 2913/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7294 - val_loss: 3.3962\n",
      "Epoch 2914/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7295 - val_loss: 3.3960\n",
      "Epoch 2915/3000\n",
      "2/2 [==============================] - 0s 152ms/step - loss: 3.7295 - val_loss: 3.3951\n",
      "Epoch 2916/3000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 3.7297 - val_loss: 3.3943\n",
      "Epoch 2917/3000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 3.7296 - val_loss: 3.3938\n",
      "Epoch 2918/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.7300 - val_loss: 3.3942\n",
      "Epoch 2919/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.7297 - val_loss: 3.3948\n",
      "Epoch 2920/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.7294 - val_loss: 3.3955\n",
      "Epoch 2921/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.7293 - val_loss: 3.3964\n",
      "Epoch 2922/3000\n",
      "2/2 [==============================] - 0s 159ms/step - loss: 3.7295 - val_loss: 3.3969\n",
      "Epoch 2923/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7294 - val_loss: 3.3966\n",
      "Epoch 2924/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.7295 - val_loss: 3.3967\n",
      "Epoch 2925/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.7295 - val_loss: 3.3960\n",
      "Epoch 2926/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.7294 - val_loss: 3.3962\n",
      "Epoch 2927/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7294 - val_loss: 3.3967\n",
      "Epoch 2928/3000\n",
      "2/2 [==============================] - 0s 169ms/step - loss: 3.7293 - val_loss: 3.3963\n",
      "Epoch 2929/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.7296 - val_loss: 3.3964\n",
      "Epoch 2930/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7297 - val_loss: 3.3962\n",
      "Epoch 2931/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7294 - val_loss: 3.3965\n",
      "Epoch 2932/3000\n",
      "2/2 [==============================] - ETA: 0s - loss: 4.023 - 0s 52ms/step - loss: 3.7298 - val_loss: 3.3955\n",
      "Epoch 2933/3000\n",
      "2/2 [==============================] - 0s 178ms/step - loss: 3.7297 - val_loss: 3.3962\n",
      "Epoch 2934/3000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 3.7293 - val_loss: 3.3960\n",
      "Epoch 2935/3000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 3.7297 - val_loss: 3.3963\n",
      "Epoch 2936/3000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 3.7296 - val_loss: 3.3964\n",
      "Epoch 2937/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7298 - val_loss: 3.3955\n",
      "Epoch 2938/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7299 - val_loss: 3.3949\n",
      "Epoch 2939/3000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 3.7297 - val_loss: 3.3952\n",
      "Epoch 2940/3000\n",
      "2/2 [==============================] - 0s 148ms/step - loss: 3.7298 - val_loss: 3.3955\n",
      "Epoch 2941/3000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 3.7296 - val_loss: 3.3962\n",
      "Epoch 2942/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7295 - val_loss: 3.3969\n",
      "Epoch 2943/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3.7295 - val_loss: 3.3968\n",
      "Epoch 2944/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7295 - val_loss: 3.3971\n",
      "Epoch 2945/3000\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 3.7298 - val_loss: 3.3966\n",
      "Epoch 2946/3000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 3.7296 - val_loss: 3.3970\n",
      "Epoch 2947/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7299 - val_loss: 3.3964\n",
      "Epoch 2948/3000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 3.7302 - val_loss: 3.3961\n",
      "Epoch 2949/3000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 3.7298 - val_loss: 3.3964\n",
      "Epoch 2950/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.7295 - val_loss: 3.3960\n",
      "Epoch 2951/3000\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 3.7296 - val_loss: 3.3955\n",
      "Epoch 2952/3000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 3.7299 - val_loss: 3.3945\n",
      "Epoch 2953/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 3.7299 - val_loss: 3.3947\n",
      "Epoch 2954/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7296 - val_loss: 3.3957\n",
      "Epoch 2955/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 3.7294 - val_loss: 3.3965\n",
      "Epoch 2956/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7298 - val_loss: 3.3976\n",
      "Epoch 2957/3000\n",
      "2/2 [==============================] - 0s 171ms/step - loss: 3.7295 - val_loss: 3.3972\n",
      "Epoch 2958/3000\n",
      "2/2 [==============================] - 0s 186ms/step - loss: 3.7301 - val_loss: 3.3963\n",
      "Epoch 2959/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 3.7297 - val_loss: 3.3961\n",
      "Epoch 2960/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7296 - val_loss: 3.3969\n",
      "Epoch 2961/3000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 3.7298 - val_loss: 3.3976\n",
      "Epoch 2962/3000\n",
      "2/2 [==============================] - 0s 174ms/step - loss: 3.7297 - val_loss: 3.3972\n",
      "Epoch 2963/3000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 3.7295 - val_loss: 3.3963\n",
      "Epoch 2964/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7297 - val_loss: 3.3955\n",
      "Epoch 2965/3000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 3.7295 - val_loss: 3.3955\n",
      "Epoch 2966/3000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 3.7294 - val_loss: 3.3953\n",
      "Epoch 2967/3000\n",
      "2/2 [==============================] - 0s 153ms/step - loss: 3.7295 - val_loss: 3.3950\n",
      "Epoch 2968/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7297 - val_loss: 3.3948\n",
      "Epoch 2969/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7298 - val_loss: 3.3943\n",
      "Epoch 2970/3000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 3.7296 - val_loss: 3.3941\n",
      "Epoch 2971/3000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 3.7304 - val_loss: 3.3948\n",
      "Epoch 2972/3000\n",
      "2/2 [==============================] - 0s 198ms/step - loss: 3.7302 - val_loss: 3.3958\n",
      "Epoch 2973/3000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 3.7300 - val_loss: 3.3962\n",
      "Epoch 2974/3000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 3.7296 - val_loss: 3.3959\n",
      "Epoch 2975/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7299 - val_loss: 3.3954\n",
      "Epoch 2976/3000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 3.7296 - val_loss: 3.3955\n",
      "Epoch 2977/3000\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 3.7293 - val_loss: 3.3958\n",
      "Epoch 2978/3000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 3.7296 - val_loss: 3.3966\n",
      "Epoch 2979/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7297 - val_loss: 3.3966\n",
      "Epoch 2980/3000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 3.7300 - val_loss: 3.3972\n",
      "Epoch 2981/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7295 - val_loss: 3.3976\n",
      "Epoch 2982/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7301 - val_loss: 3.3985\n",
      "Epoch 2983/3000\n",
      "2/2 [==============================] - 0s 177ms/step - loss: 3.7295 - val_loss: 3.3979\n",
      "Epoch 2984/3000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 3.7298 - val_loss: 3.3973\n",
      "Epoch 2985/3000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 3.7296 - val_loss: 3.3973\n",
      "Epoch 2986/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7298 - val_loss: 3.3965\n",
      "Epoch 2987/3000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 3.7296 - val_loss: 3.3958\n",
      "Epoch 2988/3000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 3.7295 - val_loss: 3.3956\n",
      "Epoch 2989/3000\n",
      "2/2 [==============================] - 0s 144ms/step - loss: 3.7294 - val_loss: 3.3957\n",
      "Epoch 2990/3000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 3.7295 - val_loss: 3.3957\n",
      "Epoch 2991/3000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 3.7295 - val_loss: 3.3956\n",
      "Epoch 2992/3000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 3.7299 - val_loss: 3.3958\n",
      "Epoch 2993/3000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 3.7304 - val_loss: 3.3957\n",
      "Epoch 2994/3000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 3.7296 - val_loss: 3.3957\n",
      "Epoch 2995/3000\n",
      "2/2 [==============================] - 0s 166ms/step - loss: 3.7295 - val_loss: 3.3961\n",
      "Epoch 2996/3000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 3.7295 - val_loss: 3.3962\n",
      "Epoch 2997/3000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 3.7295 - val_loss: 3.3957\n",
      "Epoch 2998/3000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 3.7296 - val_loss: 3.3955\n",
      "Epoch 2999/3000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 3.7295 - val_loss: 3.3944\n",
      "Epoch 3000/3000\n",
      "2/2 [==============================] - 0s 183ms/step - loss: 3.7294 - val_loss: 3.3945\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to Data\n",
    "history = feature_model.fit(\n",
    "    train_features, train_labels,\n",
    "    epochs=3000,\n",
    "    verbose=1,\n",
    "    # Use 20% of data for validation\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the History**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    #plt.ylim([0,25])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error[Final]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step - loss: 4.2287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.228664398193359"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_model.evaluate(\n",
    "    test_features, test_labels,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 1) (50, 1)\n"
     ]
    }
   ],
   "source": [
    "feature = \"Mid\"\n",
    "range_min = np.min(test_features[feature])\n",
    "#print(range_min)\n",
    "range_max = np.max(test_features[feature])\n",
    "#print(range_max)\n",
    "x = tf.linspace([range_min], [range_max], 100)\n",
    "#x = [[23],[29],[19]]\n",
    "y = abs(feature_model.predict(x))\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAAE9CAYAAADaqWzvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAvbElEQVR4nO3deXSc1X3/8ffXkmzJq7zjRcYL2HiX7bEszQQC5AemCQlLgB9LwJTFoUAKuCExBdKSk/xCCw1J6TmhTkmPszRpSonJSUiIA7hJrcWWLNsy3jDYxvuKvApby/39ofHgMZJsgea5o3k+r3M4mnlmRs/3zqMZPr73Pvcx5xwiIiIiknpdfBcgIiIiEhYKXiIiIiIBUfASERERCYiCl4iIiEhAFLxEREREAqLgJSIiIhKQbN8FnIsBAwa4kSNH+i5DRERE5Kyqqqr2O+cGtvRYpwheI0eOpLKy0ncZIiIiImdlZltbe0xDjSIiIiIBUfASERERCYiCl4iIiEhAOsUcr5bU19ezfft2PvjgA9+lZIzc3FyGDx9OTk6O71JEREQyUqcNXtu3b6dXr16MHDkSM/NdTqfnnOPAgQNs376dUaNG+S5HREQkI3XaocYPPviA/v37K3R1EDOjf//+6kEUERFJoU4bvACFrg6m91NERCS1OnXw8i0rK4vCwkImTpzI1KlT+ad/+ieamprafM2WLVv4j//4j4AqFBERkXSi4PUJ5OXlsXLlSt566y0WL17M7373O5566qk2X6PgJSIiEl6hCV6LqncQe/oNRs3/LbGn32BR9Y4O/f2DBg1iwYIF/Mu//AvOObZs2cLFF1/M9OnTmT59OqWlpQDMnz+fP//5zxQWFvLcc8+1+jwREZGOdPDgQX7729/y0ksv+S4l1DrtWY3tsah6B4+9XENdfSMAO2rreOzlGgCunTasw/YzevRoGhsb2bt3L4MGDWLx4sXk5uby9ttvc8stt1BZWcnTTz/Ns88+y29+8xsAjh8/3uLzREREPq6mpiY2btxIaWkppaWlLF26lPXr1wNw0UUXccMNN3iuMLxCEbyeeW1DInSdUlffyDOvbejQ4HW6+vp6HnzwQVauXElWVhYbN278RM8TERFpzbFjx1i+fHkiaJWVlXHw4EEA+vXrRzQa5Y477iAajRKJRDxXG26hCF47a+vatf3jevfdd8nKymLQoEE89dRTDB48mFWrVtHU1ERubm6Lr3nuuefO6XkiIiLQvO7itm3bEiGrtLSUlStX0tjY3MEwYcIErr/+eqLRKNFolLFjx+qs9TQSiuA1ND+PHS2ErKH5eR22j3379nHffffx4IMPYmYcOnSI4cOH06VLFxYuXJj4QPTq1YsjR44kXtfa80RERABOnjzJypUrk4LWjh3N85S7d+/OrFmzmD9/PtFolOLiYvr16+e5YmlLKILXo7PHJc3xAsjLyeLR2eM+0e+tq6ujsLCQ+vp6srOzuf3225k3bx4A999/P1/84hf58Y9/zFVXXUWPHj0AmDJlCllZWUydOpU777yz1eeJiEg47d+/n7KyMpYuXUppaSnLly9PLG49YsQILrnkkkRv1pQpU8jODsX/yjOGOed813BWkUjEnTnhfN26dYwfP/6cf8ei6h0889oGdtbWMTQ/j0dnj0vZ/K7OrL3vq4iIfHxNTU2sW7cuqTfr1FzfnJwcpk+fnghZJSUlDBum/291BmZW5ZxrcTJdaGLytdOGKWiJiIhXR44cYdmyZYmQVV5eTm1tLQADBgwgGo1y1113JSbB5+V13JQYSQ+hCV4iIiJBcs6xdevWpCUdVq9eTVNTE2bGxIkTuemmmxI9WhdccIEmwYeAgpeIiEgHOHHiBNXV1UnDhrt27QKgZ8+eFBUV8fjjjycmwefn5/stWLxIafAys4eAewEDfuic+56Z9QP+ExgJbAFucs69n8o6REREOtqePXsoKytLrJu1fPlyTpw4AcCoUaO4/PLLE71ZkyZN0iR4AVIYvMxsEs2hqwg4CfzezH4DzAVed849bWbzgfnA11NVh4iIyCfV2NjI2rVrE0OGpaWlvPPOOwB07dqVGTNm8MADDxCLxSgpKWHIkCGeK5Z0lcr4PR6ocM4dBzCz/wGuB64BLo0/ZyGwBAUvERFJI4cPH6aioiJpEvzhw4eB5mvzxmIx7rvvPqLRKNOnT9fi13LOUhm81gDfNrP+QB3wWaASGOyc2xV/zm5gcAprSKmsrCwmT55MQ0MD48ePZ+HChXTv3v1j/a4777yTq6++mhtuuIF77rmHefPmMWHChBafu2TJErp27Uo0GgXghRdeoHv37txxxx0fuy0iImHlnOPdd99NmptVU1ODcw4zY/Lkydxyyy3EYjGi0SijR4/WJHj52FIWvJxz68zsH4A/AMeAlUDjGc9xZtbiQmJmNpfmYUlGjBiRqjI/kby8PFauXAnAbbfdxgsvvJBYQBWgoaHhY43p/9u//Vubjy9ZsoSePXsmgtd9993X7n2IiITVBx98QFVVVVLQ2rt3LwC9e/emuLg4ccmdWbNm0bt3b88VSyZJ6Uw/59yLwIsAZvb/gO3AHjMb4pzbZWZDgL2tvHYBsACaF1BNZZ0d4eKLL2b16tUsWbKEJ598kr59+7J+/XrWrVvH/PnzWbJkCSdOnOCBBx7gy1/+Ms45vvKVr7B48WIKCgro2rVr4nddeumlPPvss0QiEX7/+9/zt3/7tzQ2NjJgwABefPFFXnjhBbKysvjpT3/K888/z+uvv07Pnj356le/ysqVK7nvvvs4fvw4Y8aM4Uc/+hF9+/bl0ksvZdasWbz55pvU1tby4osvcvHFF3t8x0REgrF79+6kJR2qqqqor68H4IILLuCqq66ipKSEWCzGhAkTyMrK8lyxZLJUn9U4yDm318xG0Dy/qxgYBcwBno7/fCWVNQShoaGB3/3ud1x11VUArFixgjVr1jBq1CgWLFhAnz59Eme7xGIxrrzySqqrq9mwYQNr165lz549TJgwgbvuuivp9+7bt497772XP/3pT4waNYqDBw/Sr18/7rvvvkTQAnj99dcTr7njjjt4/vnn+fSnP803vvENnnrqKb73ve8l6ly2bBmvvvoqTz31FH/84x+DeYNERALS0NDAmjVrknqzNm/eDEC3bt2YOXMmjzzySGIl+EGDBnmuWMIm1ee2/nd8jlc98IBzrtbMngZ+aWZ3A1uBmz7pTh5++OHEkF9HKSwsTASW1py6ViM093jdfffdlJaWUlRUxKhRowD4wx/+wOrVq3nppZeA5otiv/322/zpT3/illtuISsri6FDh3L55Zd/5PeXl5dzySWXJH7X2S58eujQIWpra/n0pz8NwJw5c7jxxhsTj19//fUAzJgxgy1btpz1PRARSXe1tbWUl5cnQlZFRQVHjx4FYMiQIcRiMR588EFisRjTpk1LGl0Q8SHVQ40fGctyzh0APpPK/Qbl9Dlepzv9QtfOOZ5//nlmz56d9JxXX3011eV9RLdu3YDmkwIaGhoC37+IyCfhnGPTpk2J5RxKS0tZu3Ytzjm6dOnC1KlTmTNnTmLtrPPPP1+T4CXtZMRqbmfrmfJp9uzZ/OAHP+Dyyy8nJyeHjRs3MmzYMC655BL+9V//lTlz5rB3717efPNNbr311qTXFhcXc//997N58+akocZevXolTms+XZ8+fejbty9//vOfufjii/nJT36S6P0SEels6urqqKysTBo23L9/PwD5+fmUlJRw8803U1JSwqxZs+jZs6fnikXOLiOCVzq755572LJlC9OnT8c5x8CBA1m0aBHXXXcdb7zxBhMmTGDEiBGUlJR85LUDBw5kwYIFXH/99TQ1NTFo0CAWL17M5z//eW644QZeeeUVnn/++aTXLFy4MDG5fvTo0fz7v/97UE0VEflEduzYkRSyVqxYkeidHzt2LJ///OcTvVkXXXQRXbp08VyxSPuZc2l/wiCRSMRVVlYmbVu3bh3jx4/3VFHm0vsqIkFoaGhg1apVSUHrvffeAyA3N5eioqJEyCopKWHAgAGeKxY5d2ZW5ZyLtPSYerxERCTlDh48+JFJ8MePHwdg2LBhxGIx5s2bRzQaZerUqZoELxlLwUtERDqUc46NGzcmXddw3bp1QPPJPYWFhdx9992JHq10XSRbJBUUvERE5BM5fvw4y5cvTxo2PHjwIAB9+/YlGo3ypS99iWg0ysyZM5PO/BYJm04dvE5dR0s6RmeY7yci/m3bti0pZFVXV9PY2HxFuPHjx3PdddclerPGjh2rSfAip+m0wSs3N5cDBw7Qv39/ha8O4JzjwIED5Obm+i5FRNJIfX09K1euTApa27dvB5rXMpw1axZf//rXE5Pgz7bQs0jYddrgNXz4cLZv386+fft8l5IxcnNzGT58uO8yRMSj/fv3U1ZWlghZy5cvp66uDoARI0bwqU99KtGbNWXKFHJycjxXLNK5dNrglZOTk7iUjoiItF9TUxPr1q1L6s3auHEjANnZ2UybNo0vf/nLid4s/cNM5JPrtMFLRETa5+jRoyxbtiwRssrKyqitrQVgwIABRKNR7rrrLqLRKJFIhLy8PL8Fi2QgBS8RkQzknGPr1q1JvVmrVq2iqakJM2PixInceOONxGIxotEoF1xwgebLigRAwUtEJAOcOHGC6urqpKC1a9cuAHr06EFxcTGPP/440WiU4uJi8vPz/RYsElIKXiIindDevXs/Mgn+xIkTAIwaNYrLLrss0Zs1adIksrP1dS+SDvRJFBFJc42NjaxduzapN2vTpk0AdO3alRkzZvDggw8mJsEPGTLEc8Ui0hoFLxGRNHP48GGWLVuWuNxOeXk5hw8fBmDQoEFEo1Hmzp1LLBZj+vTpWn9PpBNR8BIR8cg5x+bNm5N6s2pqahKT4CdPnsytt96aWDtr9OjRmgQv0okpeImIBOjEiRNUVVUlBa09e/YA0KtXL4qLi3nyySeJxWLMmjWL3r17e65YRDqSgpeISArt3r07KWRVVVVx8uRJAMaMGcOVV16Z6M2aOHEiWVlZnisWkVRS8BIR6SCNjY3U1NQkBa3NmzcD0K1bNyKRCA899BAlJSVEo1EGDx7suWIRCZqCl4jIx1RbW0tFRUViEnxFRQVHjx4F4LzzziMWiyXONpw2bRrdunXzXLGI+KbgJSJyDpxzbNq0Kak366233sI5R5cuXZg6dSpz5syhpKSEWCzG+eefr0nwIvIRCl4iIi2oq6ujsrIyKWjt378fgD59+lBSUsJNN91ELBajqKiInj17eq5YRDoDBS8REWDnzp1JIWvFihXU19cDMHbsWK6++urEAqUTJkygS5cunisWkc5IwUtEQqehoYHVq1cnBa2tW7cCkJubS1FREX/zN3+TuK7hwIEDPVcsIplCwUtEMt7BgwcpLy9PhKyKigqOHz8OwNChQ4nFYjzyyCNEo1GmTp1K165dPVcsIplKwUtEMopzjo0bN1JaWpo423DdunUAZGVlUVhYyN13351YO6ugoECT4EUkMApeItKpHT9+nOXLlycNGx48eBCAvn37Eo1G+dKXvkQ0GmXmzJn06NHDc8UiEmYpDV5m9ghwD+CAGuAvgSHAL4D+QBVwu3PuZCrrEJHMsW3btqSQtXLlShoaGgC46KKLuO666xK9WWPHjtUkeBFJKykLXmY2DPhrYIJzrs7MfgncDHwWeM459wszewG4G/hBquoQkc6rvr6eVatWJYYMS0tL2b59OwDdu3enqKiIr33ta4lJ8P379/dcsYhI21I91JgN5JlZPdAd2AVcDtwaf3wh8PcoeIkIcODAAcrKyhIha9myZdTV1QEwfPhwYrEYsViMaDTKlClTyMnJ8VyxiEj7pCx4Oed2mNmzwHtAHfAHmocWa51zDfGnbQeGpaoGEUlfTU1NrF+/PhG0li5dyoYNGwDIzs5m2rRpzJ07N7F2VkFBgeeKRUQ+uVQONfYFrgFGAbXAfwFXteP1c4G5ACNGjEhBhSISpKNHj7Js2bJEb1ZZWRm1tbUA9O/fn5KSEu68806i0SiRSITu3bv7LVhEJAVSOdT4f4DNzrl9AGb2MhAD8s0sO97rNRzY0dKLnXMLgAUAkUjEpbBOEelgzjm2bt2aCFilpaWsWrWKxsZGACZOnMiNN96YmAR/4YUXakkHEQmFVAav94BiM+tO81DjZ4BK4E3gBprPbJwDvJLCGkQkACdPnqS6ujrpbMOdO3cC0KNHD4qLi3nssceIxWLMmjWLvn37eq5YRMSPVM7xqjCzl4AVQANQTXMP1m+BX5jZt+LbXkxVDSKSGvv27UsKWcuXL+fEiRMAjBw5kssuuyzRmzVp0iSys7VkoIgIgDmX/qN4kUjEVVZW+i5DJJSamppYu3ZtUtB6++23AcjJyWHGjBmUlJQQi8UoKSlh6NChnisWEfHLzKqcc5GWHtM/Q0UkyeHDh5MmwZeXl3Po0CEABg4cSCwW49577yUajTJjxgxyc3M9Vywi0nkoeImEmHOOzZs3J/Vm1dTU0NTUhJkxadIkbr755sSw4ZgxYzQJXkTkE1DwEgmREydOUFVVlRS09uzZA0CvXr0oLi7miSeeSEyC79Onj+eKRUQyi4KXSAbbvXt30krwlZWVnDzZfGnUMWPGcOWVVybmZ02cOJGsrCzPFYuIZDYFL5EM0djYyJo1a5J6s959910AunXrRiQS4aGHHkqsBD948GDPFYuIhI+Cl0gndejQIcrLyxMhq6KigiNHjgAwePBgYrEY999/P9FolOnTp9OtWzfPFYuIiIKXSCfgnGPTpk1JvVlvvfUWzjm6dOnClClTuP322xOT4EeOHKlJ8CIiaUjBSyQN1dXVUVlZmRS09u/fD0CfPn0oLi5OXHKnqKiI3r17e65YRETOhYKXSBrYuXNnUshasWIF9fX1AIwdO5arr7460Zs1fvx4unTp4rliERH5OBS8RALW0NBATU0NpaWlLF26lNLSUrZu3QpAbm4uM2fOZN68eYlJ8AMHDvRcsYiIdBQFL5EUe//99z8yCf7YsWMADB06lFgsxsMPP0w0GqWwsJCuXbt6rlhERFJFwUukAznn2LhxY9Kw4dq1awHIysqisLCQu+66KzFsWFBQoEnwIiIhouAl8gkcP36c5cuXJ0JWWVkZBw4cACA/P59oNMqtt95KNBpl5syZ9OzZ03PFIiLik4KXSDts3749qTerurqahoYGAC666CKuueaaRG/WuHHjNAleRESSKHiJtKK+vp5Vq1YlBa1t27YBkJeXR1FREV/72teIRqMUFxfTv39/zxWLiEi6U/ASiTtw4EDSdQ2XLVtGXV0dAAUFBYmerFgsxpQpU8jJyfFcsYiIdDYKXhJKTU1NbNiwIak3a/369QBkZ2dTWFjI3LlzE0s6FBQUeK5YREQygYKXhMKxY8dYtmxZ0iT4999/H4D+/fsTjUaZM2cO0WiUSCRC9+7dPVcsIiKZSMFLMo5zjvfeey+pN2vVqlU0NjYCMGHCBL74xS8Si8WIRqNceOGFWtJBREQCoeAlnd7Jkyeprq5OClo7d+4EoEePHsyaNYvHHnssMQm+b9++nisWEZGwUvCSTmfv3r1Jk+ArKyv54IMPABg5ciSXXnopJSUlxGIxJk+eTHa2/sxFRCQ96P9IktaamppYu3ZtImQtXbqUTZs2AZCTk8P06dO5//77E5Pghw4d6rliERGR1il4SVo5cuQIFRUViaBVXl7OoUOHABg4cCDRaJR77rmHWCzGjBkzyMvL81yxiIjIuVPwEm+cc2zevDlpblZNTQ1NTU2YGZMmTeLmm29OrJ81ZswYTYIXEZFOTcFLAnPixAlWrFiRGDIsLS1lz549APTq1Yvi4mKefPJJSkpKKC4upk+fPp4rFhER6VgKXpIye/bsSerNqqys5OTJkwCMHj2aK664IrGkw8SJE8nKyvJcsYiISGopeEmHaGxs5K233kqaBP/uu+8C0LVrVyKRCH/9139NSUkJ0WiU8847z3PFIiIiwVPwko/l0KFDH5kEf+TIEQAGDx5MLBZLnG04ffp0unXr5rliERER/xS85Kycc7zzzjtJw4Zr1qzBOUeXLl2YMmUKt99+e2JJh1GjRmkSvIiISAtSFrzMbBzwn6dtGg18A/hxfPtIYAtwk3Pu/VTVIe33wQcfUFlZmRS09u3bB0Dv3r0pKSnhhhtuIBqNUlRURO/evT1XLCIi0jmkLHg55zYAhQBmlgXsAH4FzAded849bWbz4/e/nqo65Ox27dqVFLKqqqqor68H4MILL+Szn/1sYkmH8ePHaxK8iIjIxxTUUONngHecc1vN7Brg0vj2hcASFLwC09DQQE1NTVLQ2rJlCwC5ubnMnDmTefPmJYYNBw4c6LdgERGRDBJU8LoZ+Hn89mDn3K747d3A4JZeYGZzgbkAI0aMSHmBmer999+nvLw8EbIqKio4duwYAEOHDiUWi/HQQw8RjUYpLCyka9eunisWERHJXOacS+0OzLoCO4GJzrk9ZlbrnMs/7fH3nXN92/odkUjEVVZWprTOTOCcY+PGjUm9WWvXrgUgKyuLqVOnJtbNikajFBQUaBK8iIhIBzOzKudcpKXHgujx+gtghXNuT/z+HjMb4pzbZWZDgL0B1JCRjh8/npgEv3TpUsrKyjhw4AAA+fn5RKNRbr31VqLRKDNnzqRnz56eKxYREQm3IILXLXw4zAjwa2AO8HT85ysB1JARtm/fntSbVV1dTUNDAwBjx47lC1/4AtFolFgsxrhx4+jSpYvnikVEROR0KQ1eZtYDuAL48mmbnwZ+aWZ3A1uBm1JZQ2dVX1/P6tWrk1aC37ZtGwB5eXkUFRXx6KOPEo1GKS4uZsCAAZ4rFhERkbNJafByzh0D+p+x7QDNZznKaQ4ePEhZWVkiaC1btozjx48DUFBQQElJCV/96leJRqNMnTqVnJwczxWLiIhIe2nles+ccxQXF7Ns2TIAsrOzmTZtGvfee29iSYeCggLPVYqIiEhHUPDyzMyYPXs21113HdFolEgkQvfu3X2XJSIiIimg4JUGvvnNb/ouQURERAKg095EREREAqLgJSIiIhIQBS8RERGRgCh4iYiIiAREwUtEREQkIApeIiIiIgFR8BIREREJiIKXiIiISEAUvEREREQCouAlIiIiEhAFLxEREZGAKHiJiIiIBETBS0RERCQgCl4iIiIiAVHwEhEREQmIgpeIiIhIQBS8RERERAKi4CUiIiISEAUvERERkYBkt/WgmV3f1uPOuZc7thwRERGRzNVm8AI+38ZjDlDwEhERETlHbQYv59xfBlWIiIiISKY7W49Xgpl9DpgI5J7a5pz7ZiqKEhEREclE5zS53sxeAP4v8BXAgBuB81NYl4iIiEjGOdezGqPOuTuA951zTwElwNjUlSUiIiKSec41eNXFfx43s6FAPTDkbC8ys3wze8nM1pvZOjMrMbN+ZrbYzN6O/+z7cYsXERER6UzONXj9xszygWeAFcAW4Ofn8LrvA793zl0ETAXWAfOB151zFwKvx++LiIiIZDxzzrXvBWbdgFzn3KGzPK8PsBIY7U7biZltAC51zu0ysyHAEufcuLZ+VyQScZWVle2qU0RERMQHM6tyzkVaeqw9ZzVGgZGnXmNmOOd+3MZLRgH7gH83s6lAFfAQMNg5tyv+nN3A4HOtQURERKQzO6fgZWY/AcbQ3IPVGN/sgLaCVzYwHfiKc67CzL7PGcOKzjlnZi12uZnZXGAuwIgRI86lTBEREZG0dq49XhFggmvfuOR2YLtzriJ+/yWag9ceMxty2lDj3pZe7JxbACyA5qHGduxXREREJC2d6+T6NcB57fnFzrndwDYzOzV/6zPAWuDXwJz4tjnAK+35vSIiIiKd1bn2eA0A1prZMuDEqY3OuS+c5XVfAX5mZl2Bd4G/pDns/dLM7ga2Aje1u2oRERGRTuhcg9fff5xf7pxbSfMw5Zk+83F+n4iIiEhndk7Byzn3P6kuRERERCTTtRm8zOx/nXOfMrMjNJ/FmHiI5pMSe6e0OhEREZEMcrYer9sAnHO9AqhFREREJKOd7azGX526YWb/neJaRERERDLa2YKXnXZ7dCoLEREREcl0ZwterpXbIiIiItJOZ5vjNdXMDtPc85UXvw2aXC8iIiLSbm0GL+dcVlCFiIiIiGS6c71kkIiIiIh8QgpeIiIiIgFR8BIREREJiIKXiIiISEAUvEREREQCouAlIiIiEhAFLxEREZGAKHiJiIiIBETBS0RERCQgCl4iIiIiAVHwEhEREQmIgpeIiIhIQBS8RERERAKi4CUiIiISEAUvERERkYAoeImIiIgERMFLREREJCAKXiIiIiIBUfASERERCYiCl4iIiEhAslP5y81sC3AEaAQanHMRM+sH/CcwEtgC3OScez+VdYiIiIikgyB6vC5zzhU65yLx+/OB151zFwKvx++LiIiIZDwfQ43XAAvjtxcC13qoQURERCRwqQ5eDviDmVWZ2dz4tsHOuV3x27uBwSmuQURERCQtpHSOF/Ap59wOMxsELDaz9ac/6JxzZuZaemE8qM0FGDFiRIrLFBEREUm9lPZ4Oed2xH/uBX4FFAF7zGwIQPzn3lZeu8A5F3HORQYOHJjKMkVEREQCkbLgZWY9zKzXqdvAlcAa4NfAnPjT5gCvpKoGERERkXSSyqHGwcCvzOzUfv7DOfd7M1sO/NLM7ga2AjelsAYRERGRtJGy4OWcexeY2sL2A8BnUrVfERERkXSlletFREREAqLgJSIiIhIQBS8RERGRgCh4iYiIiAREwUtEREQkIApeIiIiIgFR8BIREREJiIKXiIiISEAUvEREREQCouAlIiIiEhAFLxEREZGAKHiJiIiIBETBS0RERCQgCl4iIiIiAcn2XYCIhM+i6h0889oGdtbWMTQ/j0dnj+PaacN8lyUiknIKXiISqEXVO3js5Rrq6hsB2FFbx2Mv1wAofIlIxtNQo4gE6pnXNiRC1yl19Y0889oGTxWJiARHwUtEArWztq5d20VEMomCl4gEamh+Xru2i4hkEgUvEQnUo7PHkZeTlbQtLyeLR2eP81SRiEhwNLleRAJ1agK9zmoUkTBS8BKRwF07bZiCloiEkoKXhJbWkvLniUU1/LxiG43OkWXGLbMK+Na1k32XJZLRrvjuEt7eeyxx/8JBPVg871J/BYWU5nhJKJ1aS2pHbR2OD9eSWlS9w3dpGe+JRTX8tPw9Gp0DoNE5flr+Hk8sqvFcmUjmOjN0Aby99xhXfHeJn4JCTMFLQklrSfnz84pt7douIp/cmaHrbNsldRS8JJS0lpQ/p3q6znW7iEgmUfCSUNJaUv5kmbVru4hIJlHwklDSWlL+3DKroF3bReSTu3BQj3Ztl9RJefAysywzqzaz38TvjzKzCjPbZGb/aWZdU12DyJmunTaM71w/mWH5eRgwLD+P71w/WWc1BuBb107mS8UjEj1cWWZ8qXiEzmoUSaHF8y79SMjSWY1+BLGcxEPAOqB3/P4/AM85535hZi8AdwM/CKAOaUGYT+sP81pSo+b/ltNnVBmw+enPBbb/xW/tTjqrcfFbuwP9uwvzUiJhbjuEu/0PXHZhUtsfuOzCQPcf5vf+dCnt8TKz4cDngH+L3zfgcuCl+FMWAtemsgZpnU7rD6czQxeAi28PwqxvL2bPkZNJ2/YcOcmsby8OZP9hXkokzG2HcLffd9t97z+dpHqo8XvA14Cm+P3+QK1zriF+fzsQvribJnRafzi1du5gUOcUnhm6zra9o4V5KZEwtx3C3X7fbfe9/3SSsuBlZlcDe51zVR/z9XPNrNLMKvft29fB1QnotH4JpzAvJRLmtkO42++77b73n05SOccrBnzBzD4L5NI8x+v7QL6ZZcd7vYYDLfYzOucWAAsAIpGIkkAKZJm1GLJ0Wr9ksqH5eexo4cs+yKVEfM2tDHPbIT3a74vvtvvefzrNL0tZj5dz7jHn3HDn3EjgZuAN59xtwJvADfGnzQFeSVUN0jad1h9OrcXqoOL24F4tn8jc2vaOdtlFA9u1vaP5nFvpexkV3/NKfbffJ99t97n/dJtf5mMdr68D88xsE81zvl70UIOg0/rDavPTn/tIyAryrMaKx6/4SMga3KsrFY9fEcj+31zf8tSF1rZ3NJ9zK30vo+J7Xqnv9vvku+0+959u88uCWE4C59wSYEn89rtAURD7lbP71rWTFbRCKMilI1oSVMhqie+5Jr7nVvpcRsV328PO9xI6vvbv+zN/Jq1cLyKh4vtyUWG+ZJLvtqfbkJMEw/dn/kwKXiISKr7nuoR5bqXvtqfbkJMEw/dn/kyBDDWKiKSLU0Mdvs5wOjW0H8YrRvhue7oNOUkwfH/mzxT64JVOp5iKBCXsf/e+57ps3nc06cy+zfuOBrZv38feZ9t9L2kg/vj+zJ8u1EONGu+XMNLfvV+3/bCMpe8cTNq29J2D3PbDspTv2/ex99l2SL8hJwmnUAcvjfdLGOnv3q8zg8fZtnck38feZ9vB/5IKIhDyoUaN90sY6e8+vHTs02vIScIp1D1e6XaKqUgQ9HcfXjr2Iv6FOnhpvF/CSH/3fsXG9GvX9o7k+9j7bLtIugh18NJ4v4SR/u79+tm9JR8JGrEx/fjZvSUp37fvY++z7SLpwlwnuFRDJBJxlZWVvssQEREROSszq3LORVp6LNQ9XiIiIiJBUvASERERCYiCl4iIiEhAFLxEREREAqLgJSIiIhIQBS8RERGRgCh4iYiIiAQk1NdqBFhUvYNnXtvAzto6hubn8ejscVpIMiB67/257YdlSRcmDnoRS9/HPuz7Fz+u+O4S3t57LHH/wkE9WDzvUn8FiReh7vFaVL2Dx16uYUdtHQ7YUVvHYy/XsKh6h+/SMp7ee3/ODF0AS985yG0/LAtk/76Pfdj3L36cGboA3t57jCu+u8RPQeJNqIPXM69toK6+MWlbXX0jz7y2wVNF4aH33p8zQ9fZtnc038c+7PsXP84MXWfbLpkr1MFrZ21du7ZLx9F7H16+j33Y9y8ifoU6eA3Nz2vXduk4eu/Dy/exD/v+JbwWVe8g9vQbjJr/W2JPv6HhbU9CHbwenT2OvJyspG15OVk8Onucp4rC47KLBrZru3Scwb26tmt7R/N97H1/7n3vX/zw/bnT3ML0Eergde20YXzn+skMy8/DgGH5eXzn+sk6uygAb67f167t0nH2H61v1/aO5vvY+/7c+96/+JGdldWu7R1NcwvTR+iXk7h22jB94XmgeS7+NDrXru0dLR2Ove/Pve/9S/B8/9373r98KNQ9XuKP5rn4k2XWru0dTcdewsj3373v/cuHFLzEC81z8eeWWQXt2t7RdOwljHz/3fvev3woZUONZpYL/AnoFt/PS865vzOzUcAvgP5AFXC7c+5kquqQ9HRqmEWrdwfvW9dOBuDnFdtodI4sM26ZVZDYnmo69hJGvv/ufe9fPpTKOV4ngMudc0fNLAf4XzP7HTAPeM459wszewG4G/hBCuuQNvi8dInveS6+L9vic/+R8/vx5vp97Kyt47w+uUTO7xfIfk/xfezFnycW1XgL/WH3nVfXsudIcz/Hjto6vvPqWn0OPUjZUKNrdjR+Nyf+nwMuB16Kb18IXJuqGqRtYT692Hfbfe7fd9slvJ5YVMNPy99LnMjR6Bw/LX+PJxbVeK4s9Xx/7mZ9e3EidJ2y58hJZn17cSD7lw+ldI6XmWWZ2UpgL7AYeAeodc41xJ+yHVDc9iTMpxf7brvP/ftuu4TXzyu2tWt7JvH9uTszdJ1tu6ROSoOXc67ROVcIDAeKgIvO9bVmNtfMKs2sct8+re2UCmE+vdh3233u33fbJbx8L2Xikz53ckogZzU652qBN4ESIN/MTs0tGw602M/qnFvgnIs45yIDB2o181QI8+nFvtvuc/++2y7h5XspE5/0uZNTUha8zGygmeXHb+cBVwDraA5gN8SfNgd4JVU1SNvCfHqx77b73L/vtkt4+V7KxCffnzvflyySD6XyrMYhwEIzy6I54P3SOfcbM1sL/MLMvgVUAy+msAZpQ5hPL/bddp/79912CS/fS5n45PtzV/H4FR+ZYD+4V1cqHr8ikP3Lh8x1grH1SCTiKisrfZchIiIiclZmVuWci7T0mFauFxEREQmIgpeIiIhIQBS8RERERAKSysn1IpKmfF8uKez0/oeT7+Me9v2nCwUvkZA5demSU6ton7p0CRDKL8Gg6f0PJ9/HPez7TycaahQJGd+XLgk7vf/h5Pu4h33/6UTBSyRkdOkSv/T+h5Pv4x72/acTBS+RkNGlS/zS+x9Ovo972PefThS8RELG96VLwk7vfzj5Pu5h33860eR6kZDxfemSsNP7H06+j3vY959OdMkgERERkQ6kSwaJiIiIpAEFLxEREZGAKHiJiIiIBETBS0RERCQgCl4iIiIiAVHwEhEREQmIgpeIiIhIQBS8RERERALSKRZQNbN9wFbfdaTYAGC/7yI8CXPbIdztD3PbIdztV9vDKwztP985N7ClBzpF8AoDM6tsbZXbTBfmtkO42x/mtkO426+2h7PtoPZrqFFEREQkIApeIiIiIgFR8EofC3wX4FGY2w7hbn+Y2w7hbr/aHl6hbr/meImIiIgERD1eIiIiIgFR8PLAzH5kZnvNbE0Lj/2NmTkzG+CjtlRrre1m9hUzW29mb5nZP/qqL9Vaar+ZFZpZuZmtNLNKMyvyWWOqmFmBmb1pZmvjx/mh+PZ+ZrbYzN6O/+zru9aO1kbbn4n/3a82s1+ZWb7nUjtca20/7fFM/85rtf2Z/r3Xxt99KL7zWuWc038B/wdcAkwH1pyxvQB4jeY1ywb4rjOotgOXAX8EusXvD/JdZ8Dt/wPwF/HbnwWW+K4zRW0fAkyP3+4FbAQmAP8IzI9vnw/8g+9aA2z7lUB2fPs/hKnt8fth+M5r7dhn/PdeG20PxXdea/+px8sD59yfgIMtPPQc8DUgYyfetdL2vwKeds6diD9nb+CFBaSV9jugd/x2H2BnoEUFxDm3yzm3In77CLAOGAZcAyyMP20hcK2XAlOotbY75/7gnGuIP60cGO6rxlRp47hDOL7zWmt/xn/vtdH2UHzntUbBK02Y2TXADufcKt+1eDAWuNjMKszsf8xspu+CAvYw8IyZbQOeBR7zW07qmdlIYBpQAQx2zu2KP7QbGOyrriCc0fbT3QX8LvCCAnR628P4nXfGsQ/V994ZbX+YkH3nnU7BKw2YWXfgb4Fv+K7Fk2ygH1AMPAr80szMb0mB+ivgEedcAfAI8KLnelLKzHoC/w087Jw7fPpjrnnsIWN7P1pru5k9DjQAP/NVW6qd3naa2xqq77wWjn1ovvdaaHuovvPOpOCVHsYAo4BVZraF5uGGFWZ2nteqgrMdeNk1WwY00Xwtr7CYA7wcv/1fQMZONDWzHJq/gH/mnDvV5j1mNiT++BAg44ZcoNW2Y2Z3AlcDt8WDZ8Zpoe2h+s5r5diH4nuvlbaH5juvJQpeacA5V+OcG+ScG+mcG0nzB3K6c26359KCsojmiaaY2VigK5l/AdXT7QQ+Hb99OfC2x1pSJv6v+ReBdc6575720K9p/iIm/vOVoGtLtdbabmZX0TzH6QvOueO+6kulltoepu+8Nv7uF5Hh33tttD0U33mt0QKqHpjZz4FLaf7XzR7g75xzL572+BYg4pzLqA8htNx24CfAj4BC4CTwVefcG55KTKlW2r8B+D7NQw8fAPc756p81ZgqZvYp4M9ADc3/uofm4aYK4JfACJrPbrvJOdfSySedVhtt/2egG3Agvq3cOXdf8BWmTmttd869etpztpC533mtHfs/kuHfe220/TAh+M5rjYKXiIiISEA01CgiIiISEAUvERERkYAoeImIiIgERMFLREREJCAKXiIiIiIBUfASkYxlZs7Mfnra/Wwz22dmv4nf/4KZzW/ltUeDqlNEwiPbdwEiIil0DJhkZnnOuTrgCmDHqQedc7+meQFXEZFAqMdLRDLdq8Dn4rdvAX5+6gEzu9PM/iV+e5SZlZlZjZl9y0OdIhICCl4ikul+AdxsZrnAFJpXym/J94EfOOcmA7uCKk5EwkXBS0QymnNuNTCS5t6uV9t4aowPe8N+kuKyRCSkNMdLRMLg18CzNF8ns38bz9M11EQkpdTjJSJh8CPgKedcTRvPWQrcHL99W+pLEpEwUvASkYznnNvunPvnszztIeABM6sBhgVQloiEkDmnnnURERGRIKjHS0RERCQgCl4iIiIiAVHwEhEREQmIgpeIiIhIQBS8RERERAKi4CUiIiISEAUvERERkYAoeImIiIgE5P8D+PPyJeIZH8IAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(feature, x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24d7359adec4ffe2916680474ceb48a86338759ffb8252cd67d6683f84078a4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
