{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Linear Regression**\n",
    "###### **In this tutorial we will deal with a regression problem and we will learn how to load the data, analyze the data and apply some pre-processing and apply a linear regression model(having only one layer). And further this tutorial we will extend this to a deep neural network. This will help us deep understanding of keras dense layer and activation functions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Let's Start**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Silence Warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Import Libraries\n",
    "import pandas as pd     # used to work with datasets, analyze and modify them\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "# Make numpy printouts easier to read\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Std_Id</th>\n",
       "      <th>Attendance</th>\n",
       "      <th>Class_Test</th>\n",
       "      <th>Mid</th>\n",
       "      <th>Final</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR01</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR02</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>Re_Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LR03</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>Re_Admit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LR04</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>42</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LR05</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>37</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR06</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>38</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LR07</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LR08</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>33</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LR09</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LR10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>22</td>\n",
       "      <td>39</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Std_Id  Attendance  Class_Test  Mid  Final      Type\n",
       "0   LR01           8           8   20     40   Regular\n",
       "1   LR02           9           7   19     32  Re_Admit\n",
       "2   LR03           9           9   26     27  Re_Admit\n",
       "3   LR04           5           8   27     42   Regular\n",
       "4   LR05           7           5   24     37   Regular\n",
       "5   LR06           8           5   19     38   Regular\n",
       "6   LR07           8           5   20     40   Regular\n",
       "7   LR08           5           9   19     33   Regular\n",
       "8   LR09           7          10   27     30   Regular\n",
       "9   LR10           7           8   22     39   Regular"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data.csv')\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clean Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Std_Id  Attendance  Class_Test  Mid  Final  Regular  Re_Admit\n",
      "0    LR01           8           8   23     40        1         0\n",
      "1    LR02           9           7   19     32        0         1\n",
      "2    LR03           9           9   26     27        0         1\n",
      "3    LR04           5           8   27     42        1         0\n",
      "4    LR05           7           5   24     37        1         0\n",
      "..    ...         ...         ...  ...    ...      ...       ...\n",
      "95   LR96           8           5   19     40        1         0\n",
      "96   LR97           8           5   20     40        1         0\n",
      "97   LR98           5           9   19     33        1         0\n",
      "98   LR99           7          10   17     30        1         0\n",
      "99  LR100           7           8   22     39        1         0\n",
      "\n",
      "[100 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop the data with missing values. In our dataset there is no missing value, so we need not drop anything.\n",
    "#dataset = dataset.dropna()\n",
    "#dataset\n",
    "\n",
    "# Convert Categorical 'Type' data into one-hot data: In our dataset, all the data are numerical except Type data. So, to ignore confusion of our model we will one-hot encoding the type.\n",
    "dataset = pd.read_csv('data.csv')\n",
    "type = dataset.pop('Type')\n",
    "dataset['Regular'] = (type == 'Regular')*1\n",
    "dataset['Re_Admit'] = (type == 'Re_Admit')*1\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Data into Train-Test**\n",
    "###### **We can do it by calling *sample* that includes what percentage we want to use for training. Remaining percentage automatically goes for testing, We just have to drop the training specified dataset.**\n",
    "###### **Before spliting data we have to remove the *Std_Id* column, because is a string type object and it can confuse the spliting process.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Attendance  Class_Test  Mid  Final  Regular  Re_Admit\n",
      "0            8           8   23     40        1         0\n",
      "1            9           7   19     32        0         1\n",
      "2            9           9   26     27        0         1\n",
      "3            5           8   27     42        1         0\n",
      "4            7           5   24     37        1         0\n",
      "..         ...         ...  ...    ...      ...       ...\n",
      "95           8           5   19     40        1         0\n",
      "96           8           5   20     40        1         0\n",
      "97           5           9   19     33        1         0\n",
      "98           7          10   17     30        1         0\n",
      "99           7           8   22     39        1         0\n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Removing the \"Sd_Id\" column\n",
    "id = dataset.pop('Std_Id')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 6) (80, 6) (20, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attendance</th>\n",
       "      <td>80.0</td>\n",
       "      <td>7.2000</td>\n",
       "      <td>1.335020</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class_Test</th>\n",
       "      <td>80.0</td>\n",
       "      <td>7.4625</td>\n",
       "      <td>1.749819</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mid</th>\n",
       "      <td>80.0</td>\n",
       "      <td>21.8375</td>\n",
       "      <td>3.591283</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.25</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Final</th>\n",
       "      <td>80.0</td>\n",
       "      <td>35.8250</td>\n",
       "      <td>4.716722</td>\n",
       "      <td>27.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>40.00</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regular</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.265053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Re_Admit</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.265053</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            count     mean       std   min   25%   50%    75%   max\n",
       "Attendance   80.0   7.2000  1.335020   5.0   7.0   7.0   8.00  10.0\n",
       "Class_Test   80.0   7.4625  1.749819   5.0   5.0   8.0   9.00  10.0\n",
       "Mid          80.0  21.8375  3.591283  13.0  19.0  21.0  25.25  29.0\n",
       "Final        80.0  35.8250  4.716722  27.0  32.0  37.0  40.00  44.0\n",
       "Regular      80.0   0.9250  0.265053   0.0   1.0   1.0   1.00   1.0\n",
       "Re_Admit     80.0   0.0750  0.265053   0.0   0.0   0.0   0.00   1.0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "print(dataset.shape, train_dataset.shape, test_dataset.shape)\n",
    "train_dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **In our dataset, we have 10 entries and 7 different columns. From which 8 entries will be used for training and remaining 2 entries will be used for testing. And the dercribe function gives us some parameters that might be used to analyze the dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Features**\n",
    "###### **Here, we will split the features from the labels. From our dataset, we will predict *Final* marks so we copy the training and testing dataset as training and testing features and because Final is the label of both training and testing features we pop the *Final* label.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop('Final')\n",
    "test_labels = test_features.pop('Final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot Features**\n",
    "###### **We will define a simple plot function and can use the function to plot any feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(feature, x=None, y=None):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.scatter(train_features[feature], train_labels, label='Data')\n",
    "    if(x is not None and y is not None):\n",
    "        plt.plot(x, y, color='k', label='Prediction')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Final')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot('Mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize**\n",
    "###### **If we see the description of the data, seen above in Split Data in Train-Test, we can see that the mean values have different ranges. If we take then as it is, it may confuge our model. The best way to overcome it is to normalize the data. For this, we can use a normalization layer from tensorflow preprocessing module.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               mean       std\n",
      "Attendance   7.2000  1.335020\n",
      "Class_Test   7.4625  1.749819\n",
      "Mid         21.8375  3.591283\n",
      "Final       35.8250  4.716722\n",
      "Regular      0.9250  0.265053\n",
      "Re_Admit     0.0750  0.265053\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x0000015E0FADD4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[ 7.2    7.463 21.838  0.925  0.075]]\n"
     ]
    }
   ],
   "source": [
    "# First, see the data\n",
    "print(train_dataset.describe().transpose()[['mean', 'std']])\n",
    "\n",
    "# Normalization Layer\n",
    "normalizer = preprocessing.Normalization()  # This is a keras layer for sequential api.\n",
    "# Adapt to Data: To call the normalizer we have to adapt it to our data.\n",
    "# Because our dataset is a pandas dataset, we need to make it to a numpy array.\n",
    "normalizer.adapt(np.array(train_features))\n",
    "# Now, if we see the normalization value we see that it is exactly the mean value. Because we don't apply the normalization layer so far.\n",
    "print(normalizer.mean.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### **Let's check out the first training features to be normalized. When the normalize layer is called, it returns the input data with each feature independently normalized. It uses the formula- ((input-mean)/stddev).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Column: [[ 5  9 19  1  0]]\n",
      "Normalized: [[-1.658  0.884 -0.795  0.285 -0.285]]\n"
     ]
    }
   ],
   "source": [
    "first = np.array(train_features[:1])\n",
    "# We will use the normalizer and casting the tensor into numpy array\n",
    "normalized_first = normalizer(first).numpy()\n",
    "print(\"First Column:\", first)\n",
    "print(\"Normalized:\", normalized_first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regression**\n",
    "###### **Now, we will use Linear Regression to predict final ccording to attendance/class_test/mid. For this, we have to normalize the input(attendance/class_test/mid). To predict the output(final) it will use a linear transformation function(y=mx+c) used in dense layer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80,) (80, 5)\n"
     ]
    }
   ],
   "source": [
    "# Work with Single Feature: [Not working due to shape issue]\n",
    "# Use \"Attendance\" as input\n",
    "feature = \"Attendance\"\n",
    "single_feature = np.array(train_features[feature])\n",
    "print(single_feature.shape, train_features.shape)\n",
    "# Now, we have to normalize and adapt the frature\n",
    "# Normalization Layer\n",
    "single_feature_normalizer = preprocessing.Normalization()\n",
    "# Adapt to the data\n",
    "#single_feature_normalizer.adapt(single_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sequential Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Model\n",
    "feature_model = keras.models.Sequential([\n",
    "    normalizer,\n",
    "    layers.Dense(units=1)   # Linear Model\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization (Normalizatio  (None, 5)                11        \n",
      " n)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17\n",
      "Trainable params: 6\n",
      "Non-trainable params: 11\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(feature_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "loss = keras.losses.MeanSquaredError()     # |y_p - y|. We can also use MeanSquareError: (y_p - p)^2\n",
    "optim = keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "feature_model.compile(optimizer=optim, loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 174ms/step - loss: 1304.2395 - val_loss: 1276.6001\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1287.2887 - val_loss: 1270.0029\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1271.0450 - val_loss: 1262.0629\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 1255.4906 - val_loss: 1251.9729\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1240.9199 - val_loss: 1243.1379\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1226.4978 - val_loss: 1234.4622\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 1211.5090 - val_loss: 1224.5941\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1197.8802 - val_loss: 1215.1193\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1184.1189 - val_loss: 1205.5540\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1168.8828 - val_loss: 1194.7045\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1155.2106 - val_loss: 1184.1633\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1141.7905 - val_loss: 1173.5542\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1128.5116 - val_loss: 1163.3062\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1114.9866 - val_loss: 1152.9050\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1101.8932 - val_loss: 1142.8463\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1089.0114 - val_loss: 1131.9290\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1076.0417 - val_loss: 1121.6224\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1063.6372 - val_loss: 1111.6321\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1050.6855 - val_loss: 1101.1165\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1038.3583 - val_loss: 1090.1018\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1025.6180 - val_loss: 1079.1534\n",
      "Epoch 22/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1013.5942 - val_loss: 1068.5352\n",
      "Epoch 23/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 1001.6035 - val_loss: 1057.3425\n",
      "Epoch 24/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 989.6111 - val_loss: 1046.5421\n",
      "Epoch 25/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 977.5437 - val_loss: 1035.5697\n",
      "Epoch 26/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 965.9366 - val_loss: 1024.6527\n",
      "Epoch 27/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 954.4064 - val_loss: 1013.5924\n",
      "Epoch 28/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 942.6802 - val_loss: 1002.5247\n",
      "Epoch 29/300\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 931.4761 - val_loss: 992.4719\n",
      "Epoch 30/300\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 919.9700 - val_loss: 981.7130\n",
      "Epoch 31/300\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 908.9230 - val_loss: 970.9702\n",
      "Epoch 32/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 897.7627 - val_loss: 959.5541\n",
      "Epoch 33/300\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 886.7350 - val_loss: 948.9386\n",
      "Epoch 34/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 876.2502 - val_loss: 937.5565\n",
      "Epoch 35/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 865.2528 - val_loss: 926.5833\n",
      "Epoch 36/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 854.4967 - val_loss: 916.1322\n",
      "Epoch 37/300\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 844.2688 - val_loss: 905.9926\n",
      "Epoch 38/300\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 833.6578 - val_loss: 895.1541\n",
      "Epoch 39/300\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 823.2509 - val_loss: 884.3761\n",
      "Epoch 40/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 812.9938 - val_loss: 873.9552\n",
      "Epoch 41/300\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 802.8395 - val_loss: 863.5916\n",
      "Epoch 42/300\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 792.9115 - val_loss: 853.1682\n",
      "Epoch 43/300\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 782.9346 - val_loss: 843.2770\n",
      "Epoch 44/300\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 773.0474 - val_loss: 832.8980\n",
      "Epoch 45/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 763.3842 - val_loss: 822.4044\n",
      "Epoch 46/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 753.6839 - val_loss: 812.1791\n",
      "Epoch 47/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 744.3642 - val_loss: 802.7490\n",
      "Epoch 48/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 734.6345 - val_loss: 793.2764\n",
      "Epoch 49/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 725.2679 - val_loss: 783.7849\n",
      "Epoch 50/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 716.1564 - val_loss: 773.5258\n",
      "Epoch 51/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 707.1091 - val_loss: 764.2282\n",
      "Epoch 52/300\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 698.3228 - val_loss: 754.5107\n",
      "Epoch 53/300\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 688.8018 - val_loss: 744.8352\n",
      "Epoch 54/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 679.9297 - val_loss: 735.3635\n",
      "Epoch 55/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 671.3539 - val_loss: 725.6882\n",
      "Epoch 56/300\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 662.4261 - val_loss: 716.3950\n",
      "Epoch 57/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 653.9176 - val_loss: 707.5211\n",
      "Epoch 58/300\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 645.3206 - val_loss: 698.0490\n",
      "Epoch 59/300\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 636.8710 - val_loss: 689.0099\n",
      "Epoch 60/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 628.6578 - val_loss: 680.1013\n",
      "Epoch 61/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 620.3889 - val_loss: 670.8276\n",
      "Epoch 62/300\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 612.3333 - val_loss: 661.4509\n",
      "Epoch 63/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 603.8879 - val_loss: 653.0499\n",
      "Epoch 64/300\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 596.0152 - val_loss: 644.0306\n",
      "Epoch 65/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 588.1041 - val_loss: 635.3860\n",
      "Epoch 66/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 580.1254 - val_loss: 627.0363\n",
      "Epoch 67/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 572.3495 - val_loss: 618.8662\n",
      "Epoch 68/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 564.8372 - val_loss: 610.3738\n",
      "Epoch 69/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 557.1890 - val_loss: 602.5765\n",
      "Epoch 70/300\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 549.8379 - val_loss: 594.1832\n",
      "Epoch 71/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 542.2239 - val_loss: 586.1561\n",
      "Epoch 72/300\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 535.2649 - val_loss: 577.7709\n",
      "Epoch 73/300\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 527.6257 - val_loss: 570.0760\n",
      "Epoch 74/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 520.5073 - val_loss: 562.2663\n",
      "Epoch 75/300\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 513.4023 - val_loss: 554.5705\n",
      "Epoch 76/300\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 506.2418 - val_loss: 547.1771\n",
      "Epoch 77/300\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 499.4415 - val_loss: 539.7886\n",
      "Epoch 78/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 492.6908 - val_loss: 532.8056\n",
      "Epoch 79/300\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 485.7787 - val_loss: 525.6760\n",
      "Epoch 80/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 479.1895 - val_loss: 518.0450\n",
      "Epoch 81/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 472.7464 - val_loss: 510.2629\n",
      "Epoch 82/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 465.9443 - val_loss: 503.4592\n",
      "Epoch 83/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 459.4872 - val_loss: 496.3792\n",
      "Epoch 84/300\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 453.0807 - val_loss: 489.2755\n",
      "Epoch 85/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 446.8094 - val_loss: 482.4814\n",
      "Epoch 86/300\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 440.4537 - val_loss: 475.8706\n",
      "Epoch 87/300\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 434.2932 - val_loss: 469.2323\n",
      "Epoch 88/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 428.2929 - val_loss: 462.5310\n",
      "Epoch 89/300\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 422.1602 - val_loss: 455.7838\n",
      "Epoch 90/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 416.1582 - val_loss: 449.3332\n",
      "Epoch 91/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 410.1944 - val_loss: 443.1742\n",
      "Epoch 92/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 404.4990 - val_loss: 436.6829\n",
      "Epoch 93/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 398.6939 - val_loss: 430.2637\n",
      "Epoch 94/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 393.1133 - val_loss: 424.1801\n",
      "Epoch 95/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 387.2714 - val_loss: 418.1446\n",
      "Epoch 96/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 381.7412 - val_loss: 412.0831\n",
      "Epoch 97/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 376.2384 - val_loss: 406.1118\n",
      "Epoch 98/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 371.1031 - val_loss: 400.1377\n",
      "Epoch 99/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 365.6392 - val_loss: 393.9672\n",
      "Epoch 100/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 360.1518 - val_loss: 388.4197\n",
      "Epoch 101/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 354.9104 - val_loss: 382.8124\n",
      "Epoch 102/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 349.7736 - val_loss: 377.2036\n",
      "Epoch 103/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 344.6859 - val_loss: 371.6859\n",
      "Epoch 104/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 339.7303 - val_loss: 365.9841\n",
      "Epoch 105/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 334.6798 - val_loss: 360.7201\n",
      "Epoch 106/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 329.7598 - val_loss: 355.6034\n",
      "Epoch 107/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 325.0337 - val_loss: 350.2849\n",
      "Epoch 108/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 320.1949 - val_loss: 345.0173\n",
      "Epoch 109/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 315.3677 - val_loss: 340.0588\n",
      "Epoch 110/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 310.7651 - val_loss: 335.2770\n",
      "Epoch 111/300\n",
      "2/2 [==============================] - ETA: 0s - loss: 317.848 - 0s 43ms/step - loss: 306.2789 - val_loss: 330.0780\n",
      "Epoch 112/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 301.5992 - val_loss: 324.9992\n",
      "Epoch 113/300\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 297.0760 - val_loss: 320.1694\n",
      "Epoch 114/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 292.6974 - val_loss: 315.3935\n",
      "Epoch 115/300\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 288.4306 - val_loss: 310.2380\n",
      "Epoch 116/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 283.9007 - val_loss: 305.6230\n",
      "Epoch 117/300\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 279.7213 - val_loss: 301.2090\n",
      "Epoch 118/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 275.4744 - val_loss: 296.7054\n",
      "Epoch 119/300\n",
      "2/2 [==============================] - 0s 123ms/step - loss: 271.5798 - val_loss: 291.7628\n",
      "Epoch 120/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 267.3707 - val_loss: 287.5212\n",
      "Epoch 121/300\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 263.2128 - val_loss: 283.2346\n",
      "Epoch 122/300\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 259.1700 - val_loss: 278.8406\n",
      "Epoch 123/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 255.2599 - val_loss: 274.6772\n",
      "Epoch 124/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 251.4070 - val_loss: 270.5091\n",
      "Epoch 125/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 247.5892 - val_loss: 266.2417\n",
      "Epoch 126/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 243.8665 - val_loss: 262.0680\n",
      "Epoch 127/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 240.0404 - val_loss: 258.1837\n",
      "Epoch 128/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 236.3489 - val_loss: 254.3244\n",
      "Epoch 129/300\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 232.7842 - val_loss: 250.1745\n",
      "Epoch 130/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 229.1316 - val_loss: 246.2928\n",
      "Epoch 131/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 225.7448 - val_loss: 242.5028\n",
      "Epoch 132/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 222.2378 - val_loss: 238.6255\n",
      "Epoch 133/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 218.8191 - val_loss: 234.9795\n",
      "Epoch 134/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 215.2927 - val_loss: 231.2770\n",
      "Epoch 135/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 211.9822 - val_loss: 227.8013\n",
      "Epoch 136/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 208.8497 - val_loss: 224.0067\n",
      "Epoch 137/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 205.5006 - val_loss: 220.4071\n",
      "Epoch 138/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 202.2731 - val_loss: 216.8335\n",
      "Epoch 139/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 199.0750 - val_loss: 213.3857\n",
      "Epoch 140/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 195.9939 - val_loss: 210.0813\n",
      "Epoch 141/300\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 193.0490 - val_loss: 206.7466\n",
      "Epoch 142/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 189.9201 - val_loss: 203.6252\n",
      "Epoch 143/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 187.0128 - val_loss: 200.4318\n",
      "Epoch 144/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 184.1440 - val_loss: 197.2130\n",
      "Epoch 145/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 181.2456 - val_loss: 193.8646\n",
      "Epoch 146/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 178.3160 - val_loss: 190.7812\n",
      "Epoch 147/300\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 175.5129 - val_loss: 187.7507\n",
      "Epoch 148/300\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 172.6625 - val_loss: 184.7631\n",
      "Epoch 149/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 169.9462 - val_loss: 181.8478\n",
      "Epoch 150/300\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 167.2704 - val_loss: 178.9876\n",
      "Epoch 151/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 164.6458 - val_loss: 176.1156\n",
      "Epoch 152/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 162.0452 - val_loss: 173.3316\n",
      "Epoch 153/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 159.4050 - val_loss: 170.6454\n",
      "Epoch 154/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 156.8317 - val_loss: 167.9855\n",
      "Epoch 155/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 154.4889 - val_loss: 165.4461\n",
      "Epoch 156/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 151.9683 - val_loss: 162.8036\n",
      "Epoch 157/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 149.5667 - val_loss: 160.1195\n",
      "Epoch 158/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 147.2297 - val_loss: 157.4818\n",
      "Epoch 159/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 144.8402 - val_loss: 154.9702\n",
      "Epoch 160/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 142.5531 - val_loss: 152.4993\n",
      "Epoch 161/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 140.2757 - val_loss: 149.9849\n",
      "Epoch 162/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 138.0127 - val_loss: 147.5543\n",
      "Epoch 163/300\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 135.8503 - val_loss: 145.1840\n",
      "Epoch 164/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 133.6943 - val_loss: 142.9431\n",
      "Epoch 165/300\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 131.5198 - val_loss: 140.6189\n",
      "Epoch 166/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 129.4351 - val_loss: 138.4480\n",
      "Epoch 167/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 127.3725 - val_loss: 136.2624\n",
      "Epoch 168/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 125.2802 - val_loss: 134.0486\n",
      "Epoch 169/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 123.2942 - val_loss: 131.8493\n",
      "Epoch 170/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 121.3536 - val_loss: 129.7675\n",
      "Epoch 171/300\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 119.4184 - val_loss: 127.6989\n",
      "Epoch 172/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 117.4992 - val_loss: 125.6367\n",
      "Epoch 173/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 115.5569 - val_loss: 123.5754\n",
      "Epoch 174/300\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 113.7611 - val_loss: 121.6116\n",
      "Epoch 175/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 111.9924 - val_loss: 119.5291\n",
      "Epoch 176/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 110.1646 - val_loss: 117.5120\n",
      "Epoch 177/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 108.3768 - val_loss: 115.6901\n",
      "Epoch 178/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 106.6569 - val_loss: 113.7985\n",
      "Epoch 179/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 104.9832 - val_loss: 111.8462\n",
      "Epoch 180/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 103.2680 - val_loss: 110.0194\n",
      "Epoch 181/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 101.6219 - val_loss: 108.3069\n",
      "Epoch 182/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 100.0232 - val_loss: 106.5457\n",
      "Epoch 183/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 98.4421 - val_loss: 104.7944\n",
      "Epoch 184/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 96.8432 - val_loss: 103.1633\n",
      "Epoch 185/300\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 95.3275 - val_loss: 101.5604\n",
      "Epoch 186/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 93.7757 - val_loss: 99.9873\n",
      "Epoch 187/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 92.3545 - val_loss: 98.4289\n",
      "Epoch 188/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 90.9275 - val_loss: 96.8285\n",
      "Epoch 189/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 89.4048 - val_loss: 95.2582\n",
      "Epoch 190/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 87.9691 - val_loss: 93.7416\n",
      "Epoch 191/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 86.6041 - val_loss: 92.2256\n",
      "Epoch 192/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 85.2451 - val_loss: 90.7411\n",
      "Epoch 193/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 83.8549 - val_loss: 89.3414\n",
      "Epoch 194/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 82.5994 - val_loss: 87.9078\n",
      "Epoch 195/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 81.2245 - val_loss: 86.5737\n",
      "Epoch 196/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 79.9732 - val_loss: 85.2151\n",
      "Epoch 197/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 78.7189 - val_loss: 83.8828\n",
      "Epoch 198/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 77.5280 - val_loss: 82.4899\n",
      "Epoch 199/300\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 76.2989 - val_loss: 81.2983\n",
      "Epoch 200/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 75.0997 - val_loss: 80.0401\n",
      "Epoch 201/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 73.9275 - val_loss: 78.8174\n",
      "Epoch 202/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 72.7850 - val_loss: 77.5822\n",
      "Epoch 203/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 71.6936 - val_loss: 76.3245\n",
      "Epoch 204/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 70.5687 - val_loss: 75.0543\n",
      "Epoch 205/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 69.4136 - val_loss: 73.9217\n",
      "Epoch 206/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 68.3841 - val_loss: 72.7945\n",
      "Epoch 207/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 67.3639 - val_loss: 71.6235\n",
      "Epoch 208/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 66.3010 - val_loss: 70.5312\n",
      "Epoch 209/300\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 65.3130 - val_loss: 69.5028\n",
      "Epoch 210/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 64.3450 - val_loss: 68.4154\n",
      "Epoch 211/300\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 63.3601 - val_loss: 67.3738\n",
      "Epoch 212/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 62.4107 - val_loss: 66.4262\n",
      "Epoch 213/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 61.4498 - val_loss: 65.4508\n",
      "Epoch 214/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 60.5145 - val_loss: 64.4680\n",
      "Epoch 215/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 59.6236 - val_loss: 63.5079\n",
      "Epoch 216/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 58.7194 - val_loss: 62.5883\n",
      "Epoch 217/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 57.8713 - val_loss: 61.6016\n",
      "Epoch 218/300\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 57.0274 - val_loss: 60.6704\n",
      "Epoch 219/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 56.1568 - val_loss: 59.8189\n",
      "Epoch 220/300\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 55.3352 - val_loss: 59.0308\n",
      "Epoch 221/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 54.5584 - val_loss: 58.1638\n",
      "Epoch 222/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 53.7553 - val_loss: 57.3132\n",
      "Epoch 223/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 53.0076 - val_loss: 56.4495\n",
      "Epoch 224/300\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 52.1966 - val_loss: 55.6442\n",
      "Epoch 225/300\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 51.4656 - val_loss: 54.8504\n",
      "Epoch 226/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 50.6928 - val_loss: 54.1072\n",
      "Epoch 227/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 50.0258 - val_loss: 53.3325\n",
      "Epoch 228/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 49.2790 - val_loss: 52.6138\n",
      "Epoch 229/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 48.6287 - val_loss: 51.8406\n",
      "Epoch 230/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 47.9652 - val_loss: 51.1187\n",
      "Epoch 231/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 47.2518 - val_loss: 50.4731\n",
      "Epoch 232/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 46.6906 - val_loss: 49.7966\n",
      "Epoch 233/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 45.9885 - val_loss: 49.1116\n",
      "Epoch 234/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 45.3321 - val_loss: 48.4631\n",
      "Epoch 235/300\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 44.7196 - val_loss: 47.8178\n",
      "Epoch 236/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 44.1251 - val_loss: 47.1975\n",
      "Epoch 237/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 43.5627 - val_loss: 46.5247\n",
      "Epoch 238/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 42.9685 - val_loss: 45.9180\n",
      "Epoch 239/300\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 42.3951 - val_loss: 45.3544\n",
      "Epoch 240/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 41.8292 - val_loss: 44.7840\n",
      "Epoch 241/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 41.3230 - val_loss: 44.1862\n",
      "Epoch 242/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 40.7785 - val_loss: 43.6106\n",
      "Epoch 243/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 40.2350 - val_loss: 43.0918\n",
      "Epoch 244/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 39.7517 - val_loss: 42.5254\n",
      "Epoch 245/300\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 39.2166 - val_loss: 41.9939\n",
      "Epoch 246/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 38.7482 - val_loss: 41.5060\n",
      "Epoch 247/300\n",
      "2/2 [==============================] - 0s 133ms/step - loss: 38.2523 - val_loss: 40.9964\n",
      "Epoch 248/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 37.7982 - val_loss: 40.4974\n",
      "Epoch 249/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 37.3204 - val_loss: 40.0513\n",
      "Epoch 250/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 36.8805 - val_loss: 39.5625\n",
      "Epoch 251/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 36.4367 - val_loss: 39.0949\n",
      "Epoch 252/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 36.0383 - val_loss: 38.5972\n",
      "Epoch 253/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 35.5845 - val_loss: 38.1496\n",
      "Epoch 254/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 35.1681 - val_loss: 37.7411\n",
      "Epoch 255/300\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 34.7508 - val_loss: 37.3249\n",
      "Epoch 256/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 34.3708 - val_loss: 36.8653\n",
      "Epoch 257/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 33.9602 - val_loss: 36.4756\n",
      "Epoch 258/300\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 33.6270 - val_loss: 36.0839\n",
      "Epoch 259/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 33.2334 - val_loss: 35.6819\n",
      "Epoch 260/300\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 32.8647 - val_loss: 35.3174\n",
      "Epoch 261/300\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 32.4935 - val_loss: 34.9470\n",
      "Epoch 262/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 32.1248 - val_loss: 34.5663\n",
      "Epoch 263/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 31.7962 - val_loss: 34.2285\n",
      "Epoch 264/300\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 31.4584 - val_loss: 33.8646\n",
      "Epoch 265/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 31.1173 - val_loss: 33.5447\n",
      "Epoch 266/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 30.7958 - val_loss: 33.2111\n",
      "Epoch 267/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 30.4808 - val_loss: 32.8916\n",
      "Epoch 268/300\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 30.1839 - val_loss: 32.5706\n",
      "Epoch 269/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 29.8845 - val_loss: 32.2869\n",
      "Epoch 270/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 29.6153 - val_loss: 32.0229\n",
      "Epoch 271/300\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 29.3027 - val_loss: 31.7532\n",
      "Epoch 272/300\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 29.0304 - val_loss: 31.4598\n",
      "Epoch 273/300\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 28.7322 - val_loss: 31.1798\n",
      "Epoch 274/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 28.4886 - val_loss: 30.8875\n",
      "Epoch 275/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 28.2322 - val_loss: 30.6114\n",
      "Epoch 276/300\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 27.9706 - val_loss: 30.3555\n",
      "Epoch 277/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 27.7202 - val_loss: 30.0979\n",
      "Epoch 278/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 27.4695 - val_loss: 29.8451\n",
      "Epoch 279/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 27.2376 - val_loss: 29.5712\n",
      "Epoch 280/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 26.9878 - val_loss: 29.3148\n",
      "Epoch 281/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 26.7654 - val_loss: 29.0739\n",
      "Epoch 282/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 26.5467 - val_loss: 28.8585\n",
      "Epoch 283/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 26.3441 - val_loss: 28.6038\n",
      "Epoch 284/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 26.0948 - val_loss: 28.3765\n",
      "Epoch 285/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 25.8741 - val_loss: 28.1744\n",
      "Epoch 286/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 25.6895 - val_loss: 27.9751\n",
      "Epoch 287/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 25.5075 - val_loss: 27.7918\n",
      "Epoch 288/300\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 25.3028 - val_loss: 27.5891\n",
      "Epoch 289/300\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 25.1059 - val_loss: 27.4156\n",
      "Epoch 290/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 24.9224 - val_loss: 27.2137\n",
      "Epoch 291/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 24.7340 - val_loss: 27.0493\n",
      "Epoch 292/300\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 24.5518 - val_loss: 26.8771\n",
      "Epoch 293/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 24.4018 - val_loss: 26.7038\n",
      "Epoch 294/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 24.2169 - val_loss: 26.5287\n",
      "Epoch 295/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 24.0544 - val_loss: 26.3656\n",
      "Epoch 296/300\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 23.8903 - val_loss: 26.2034\n",
      "Epoch 297/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 23.7356 - val_loss: 26.0307\n",
      "Epoch 298/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 23.5962 - val_loss: 25.8647\n",
      "Epoch 299/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 23.4319 - val_loss: 25.6948\n",
      "Epoch 300/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 23.2872 - val_loss: 25.5547\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to Data\n",
    "history = feature_model.fit(\n",
    "    train_features, train_labels,\n",
    "    epochs=500,\n",
    "    verbose=1,\n",
    "    # Use 20% of data for validation\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the History**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss(history):\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    #plt.ylim([0,25])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Error[Final]')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step - loss: 36.9598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36.9598274230957"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_model.evaluate(\n",
    "    test_features, test_labels,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1) (10, 1)\n"
     ]
    }
   ],
   "source": [
    "feature = \"Mid\"\n",
    "range_min = np.min(test_features[feature])\n",
    "#print(range_min)\n",
    "range_max = np.max(test_features[feature])\n",
    "#print(range_max)\n",
    "x = tf.linspace([range_min], [range_max], 100)\n",
    "#x = [[23],[29],[19]]\n",
    "y = abs(feature_model.predict(x))\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(feature, x,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24d7359adec4ffe2916680474ceb48a86338759ffb8252cd67d6683f84078a4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
