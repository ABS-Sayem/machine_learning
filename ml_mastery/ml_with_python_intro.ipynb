{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Machine Learning with Python: An Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Lessons**\n",
    "1. Lesson 1: **Python Ecosystem for Machine Learning**\n",
    "2. Lesson 2: **Python and SciPy**\n",
    "3. Lesson 3: **Load Datasets from CSV**\n",
    "4. Lesson 4: **Analyze Data**\n",
    "    * Understand Data with Descriptive Statistics\n",
    "    * Understand Data with Visualization\n",
    "5. Lesson 5: **Prepare Data**\n",
    "    * Pre-Process Data\n",
    "    * Feature Selection\n",
    "6. Lesson 6: **Evaluate Algorithms**\n",
    "    * Resampling Methods\n",
    "    * Algorithm Evaluation Metrics\n",
    "    * Spot-Check Classification Algorithms\n",
    "    * Spot-Check Regression Algorithms\n",
    "    * Model Selection\n",
    "    * Pipelines\n",
    "7. Lesson 7: **Improve Results**\n",
    "    * Ensemble Methods\n",
    "    * Algorithm Parameter Tuning\n",
    "8. Lesson 8: **Present Results**\n",
    "    * Model Finalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Lesson 1: Python Ecosystem for Machine Learning**\n",
    "**1.1 Python:** Python is a dynamic language, widely used for machine learning and data science because of the excellent library\n",
    "support. Both useful for research and development and production of systems.\n",
    "\n",
    "**1.2 SciPy:** SciPy is an ecosystem of Python libraries for mathematics, science and engineering. The ecosystem is comprised of:\n",
    "* `NumPy:` to efficiently work with data in arrays.\n",
    "* `Matplotlib:` to create 2D charts and plots from data.\n",
    "* `Pandas:` to load, organize and analyze the data.\n",
    "\n",
    "**1.3 Scikit-Learn** It is build upon and requires the SciPy ecosystem. The focus of the scikit-learn library is machine learning algorithms for classification, regression, clustering and so on. It also provides tools for related tasks such as - evaluating models, tuning parameters and pre-processing data.\n",
    "\n",
    "**1.4 Installing the Ecosystem** [For Windows]\n",
    "* Python: Download python exe file for your windows (update version is better), install it on your machine, add the path in enviromnet variable.\n",
    "* SciPy: `pip install scipy`\n",
    "* Numpy: `pip install numpy`\n",
    "* Matplotlib: `pip install matplotlib`\n",
    "* Pandas: `pip install pandas`\n",
    "\n",
    "Once installed, we can confirm that the installation was successful. To check the installation - open any python code editor and run the following codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python      : 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)]\n",
      "Scipy       : 1.14.0\n",
      "Numpy       : 1.26.4\n",
      "Matplotlib  : 3.9.0\n",
      "Pandas      : 2.2.2\n",
      "Scikit-Learn: 1.5.1\n"
     ]
    }
   ],
   "source": [
    "# Check whether they are installed and version\n",
    "import sys\n",
    "print(f\"Python      : {sys.version}\")\n",
    "\n",
    "import scipy\n",
    "print(f\"Scipy       : {scipy.__version__}\")\n",
    "\n",
    "import numpy\n",
    "print(f\"Numpy       : {numpy.__version__}\")\n",
    "\n",
    "import matplotlib\n",
    "print(f\"Matplotlib  : {matplotlib.__version__}\")\n",
    "\n",
    "import pandas\n",
    "print(f\"Pandas      : {pandas.__version__}\")\n",
    "\n",
    "import sklearn\n",
    "print(f\"Scikit-Learn: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Lesson 2: Python and SciPy**\n",
    "This section is basically for Python and SciPy Libraries (Numpy, Matplotlib, Pandas) crash course. We assume that we know the basics of -\n",
    "* Coding in Python\n",
    "* Numpy basics - numpy structure and operations\n",
    "* Matplotlib basics - plotting using pyplot\n",
    "* Pandas basics - load, manipulate of dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Lesson 3: Load Datasets from CSV**\n",
    "The most common format for machine learning data is `csv (comma separated values)` file. Before loading csv data we have to consider some parameters of csv file.\n",
    "1. **File Header:** If the data have a file header it can help assigning names automatically to each column of data. But if not, we need to name the attributes manually.\n",
    "2. **Comments:** Comments in a csv file are indicated by a hash (#) at the start of a line. If comments exist in data, we may need to indicate whether or not to expect comments and the character that indicates the comment line.\n",
    "3. **Delimiter:** In csv file the common seperator is the comma (,). In some cases the data file may use a different delimiter like- tab or white-space in which we must specify the separator explicitely.\n",
    "4. **Quotes:** Sometimes the field values may contain spaces and they will be quated using double quotation (\"\"), the default quote character. Other characters may be used, and we must specify them in the file.\n",
    "\n",
    "**`Pima Indians Dataset`**\n",
    "\n",
    "To demonstrate data loading here we will use the 'Pima Indians' dataset. The dataset is good for demonstration because all the attributes are numeric and the output variable is binary (0 or 1), hence it is a classification problem. The dataset is available in the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`Load CSV file with Python Standard Library`**\n",
    "\n",
    "It uses an object that can iterate over each row of the dataset and then convert them into numpy array which makes a dataset of numpy array type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load CSV file (using Python Standard Library)\n",
    "import csv\n",
    "import numpy as np\n",
    "filepath = \"F:/courses/mlds_nactar/dataset/pima_indians_diabetes.csv\"\n",
    "with open(filepath, 'r') as raw_data:\n",
    "    reader = csv.reader(raw_data, delimiter=',', quoting=csv.QUOTE_NONE)\n",
    "    header = next(reader)  # Skip the header row\n",
    "    x = list(reader)\n",
    "\n",
    "data = np.array(x).astype(float)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`Load CSV file with Numpy`**\n",
    "\n",
    "Numpy uses 'numpy.loadtxt()' function that assumes no header row and all the data has the same format. It can also load dataset directly from the url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load CSV using Numpy\n",
    "import numpy as np\n",
    "filepath = \"F:/courses/mlds_nactar/dataset/pima_indians_diabetes.csv\"\n",
    "raw_data = open(filepath, 'rb')\n",
    "#data = np.loadtxt(raw_data, delimiter=',')\n",
    "data = np.genfromtxt(filepath, delimiter=',', skip_header=1)    # If there is headers\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV from URL using NumPy\n",
    "import numpy as np\n",
    "from urllib import urlopen\n",
    "url = 'https://goo.gl/vhm1eU'   # Url of pima_indians_diabetes dataset\n",
    "raw_data = urlopen(url)\n",
    "dataset = np.loadtxt(raw_data, delimiter=\",\")\n",
    "print(dataset.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **`Load CSV File with Pandas`**\n",
    "Pandas uses the 'pandas.read_csv()' function to load the dataset which is very flexible and the most recommended approach for loading machine learning data. The function returns a Dataframe which is helpful in summarizing and plotting data. This can also load data directly fron url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load local csv Data using Pandas\n",
    "import pandas as pd\n",
    "filepath = \"F:/courses/mlds_nactar/dataset/pima_indians_diabetes.csv\"\n",
    "data = pd.read_csv(filepath)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv Data using Pandas from URL\n",
    "import pandas as pd\n",
    "url = 'https://goo.gl/vhm1eU/'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']    # Explicitely specify the column names\n",
    "data = pd.read_csv(url, names=names)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Lesson 4: Analyze Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **4.1 Undestand Data with Descriptive Statistics**\n",
    "To get the best result we have to understand the data. To better understand the machine learning data, we will follow 7 recipes and through our journey of understanding data, we will use the 'Pima Indians Diabetes' dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`4.1.1. Take a Peek at Raw Data`**\n",
    "\n",
    "Looking at the raw data can reveal insights of the data and grow ideas on how to better pre-process and handle the data for our machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  DiabetesPedigreeFunction  Age  Outcome\n",
      "0            6      148             72             35        0  33.6                     0.627   50        1\n",
      "1            1       85             66             29        0  26.6                     0.351   31        0\n",
      "2            8      183             64              0        0  23.3                     0.672   32        1\n",
      "3            1       89             66             23       94  28.1                     0.167   21        0\n",
      "4            0      137             40             35      168  43.1                     2.288   33        1\n",
      "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  DiabetesPedigreeFunction  Age  Outcome\n",
      "763           10      101             76             48      180  32.9                     0.171   63        0\n",
      "764            2      122             70             27        0  36.8                     0.340   27        0\n",
      "765            5      121             72             23      112  26.2                     0.245   30        0\n",
      "766            1      126             60              0        0  30.1                     0.349   47        1\n",
      "767            1       93             70             31        0  30.4                     0.315   23        0\n"
     ]
    }
   ],
   "source": [
    "# Take a Look at Data\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 200)\n",
    "\n",
    "filepath = \"F:/courses/mlds_nactar/dataset/pima_indians_diabetes.csv\"\n",
    "data = pd.read_csv(filepath)\n",
    "print(data.head())      # Displays the first 5 items by default, we can also specify the item number - 'data.head(10)'\n",
    "print(data.tail())      # Displays the last 5 items by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`4.1.2. Dimensions of the Data`**\n",
    "\n",
    "Dimension means how many rows and columns are there in the dataset. It is important to know the dimension of the data because by this we can realize two things:\n",
    "* Too many rows may take too long to train the algorithms and too few rows perhaps we do not have enough data to train the algorithms.\n",
    "* Too many features (columns) and few instances (rows) can suffer poor performance due to the curse of dimensionality.\n",
    "\n",
    "[NB] The 'Pima Indinas Diabetes' dataset has 768 rows and 9 columns. The `shape` property results in rows then columns (rows, columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "# Shape of the Data\n",
    "import pandas as pd\n",
    "filepath = \"F:/courses/mlds_nactar/dataset/pima_indians_diabetes.csv\"\n",
    "data = pd.read_csv(filepath)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`4.1.3. Data Type of Each Attribute`**\n",
    "\n",
    "Knowing data type of each attribute is necessary because to train the algorithms on data we need the data in integer or floating point values. So, Strings, Categorical or Ordinal values need to be converted into floating point or integer value. We can get an idea while taking a look at data but we also can explicitely check the data type of the attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies                   int64\n",
      "Glucose                       int64\n",
      "BloodPressure                 int64\n",
      "SkinThickness                 int64\n",
      "Insulin                       int64\n",
      "BMI                         float64\n",
      "DiabetesPedigreeFunction    float64\n",
      "Age                           int64\n",
      "Outcome                       int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Types of the Data\n",
    "import pandas as pd\n",
    "filepath = \"F:/courses/mlds_nactar/dataset/pima_indians_diabetes.csv\"\n",
    "data = pd.read_csv(filepath)\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`4.1.4. Descriptive Statistics`**\n",
    "\n",
    "Descriptive statistics gives a great insights like - 'Total Instances', 'Are there any missing values', 'Central Tendency', 'Range', 'Dispersion' of data of each attribute. The pandas `describe()` function lists 8 statistical properties of each attribute:\n",
    "* `Count`: Total number of instances\n",
    "* `Mean`: Average value of instances\n",
    "* `Standard Deviation`: \n",
    "* `Minimum Value`: Lowest value among instances\n",
    "* `25th Percentile`: \n",
    "* `50th Percentile (Median)`: Middle value among instances\n",
    "* `75th Percentile`: \n",
    "* `Maximum Value`: Highest value among instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin     BMI  DiabetesPedigreeFunction     Age  Outcome\n",
      "count       768.00   768.00         768.00         768.00   768.00  768.00                    768.00  768.00   768.00\n",
      "mean          3.85   120.89          69.11          20.54    79.80   31.99                      0.47   33.24     0.35\n",
      "std           3.37    31.97          19.36          15.95   115.24    7.88                      0.33   11.76     0.48\n",
      "min           0.00     0.00           0.00           0.00     0.00    0.00                      0.08   21.00     0.00\n",
      "25%           1.00    99.00          62.00           0.00     0.00   27.30                      0.24   24.00     0.00\n",
      "50%           3.00   117.00          72.00          23.00    30.50   32.00                      0.37   29.00     0.00\n",
      "75%           6.00   140.25          80.00          32.00   127.25   36.60                      0.63   41.00     1.00\n",
      "max          17.00   199.00         122.00          99.00   846.00   67.10                      2.42   81.00     1.00\n"
     ]
    }
   ],
   "source": [
    "# Types of the Data\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "filepath = \"F:/courses/mlds_nactar/dataset/pima_indians_diabetes.csv\"\n",
    "data = pd.read_csv(filepath)\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`4.1.5. Class Distribution (for Classification only)`**\n",
    "\n",
    "Class distribution means - how many instances are in each class. On classification problem we need to know how balanced the class distribution is. Highly imbalanced dataset is common and may need special handling in data pre-processing. 'Pima Indians Diabetes' dataset is a binary classification problem having 500 instances in class 0 and 268 instances in class 1. (0 = No Diabetes, 1 = Diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome\n",
      "0    500\n",
      "1    268\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Types of the Data\n",
    "import pandas as pd\n",
    "filepath = \"F:/courses/mlds_nactar/dataset/pima_indians_diabetes.csv\"\n",
    "data = pd.read_csv(filepath)\n",
    "class_counts = data.groupby('Outcome').size()\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`4.1.6. Correlation Between Attributes`**\n",
    "\n",
    "Correlation refers to the relationship between two attributes and how they may or may not change together. Pearson's Correlation Coefficient, the most comonly used method, describes correlation between two attributes by -1 or 1 means a full negetive or positive correlation respectively and 0 shows no correlation at all. `Highly correlated attributes can cause poor performance in linear or logistic regression.`\n",
    "\n",
    "The pandas 'corr()' function lists all attributes across the top and down and give correlation coefficient between all pairs of attributes. The diagonal line through the matrix shows perfect correlation of each attribute with itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  DiabetesPedigreeFunction   Age  Outcome\n",
      "Pregnancies                      1.00     0.13           0.14          -0.08    -0.07  0.02                     -0.03  0.54     0.22\n",
      "Glucose                          0.13     1.00           0.15           0.06     0.33  0.22                      0.14  0.26     0.47\n",
      "BloodPressure                    0.14     0.15           1.00           0.21     0.09  0.28                      0.04  0.24     0.07\n",
      "SkinThickness                   -0.08     0.06           0.21           1.00     0.44  0.39                      0.18 -0.11     0.07\n",
      "Insulin                         -0.07     0.33           0.09           0.44     1.00  0.20                      0.19 -0.04     0.13\n",
      "BMI                              0.02     0.22           0.28           0.39     0.20  1.00                      0.14  0.04     0.29\n",
      "DiabetesPedigreeFunction        -0.03     0.14           0.04           0.18     0.19  0.14                      1.00  0.03     0.17\n",
      "Age                              0.54     0.26           0.24          -0.11    -0.04  0.04                      0.03  1.00     0.24\n",
      "Outcome                          0.22     0.47           0.07           0.07     0.13  0.29                      0.17  0.24     1.00\n"
     ]
    }
   ],
   "source": [
    "# Types of the Data\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 200)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "filepath = \"F:/courses/mlds_nactar/dataset/pima_indians_diabetes.csv\"\n",
    "data = pd.read_csv(filepath)\n",
    "correlations = data.corr(method='pearson')\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`4.1.7. Skew of Univariate Distribution`**\n",
    "\n",
    "Many Machine Learning algorithms assume that the data has a `Gaussion` distribution, because it is preferred for better result. Skew refers to a distribution, which is assumed Gaussian (Normal or Bell Curve), that is shifted or squashed in one direction or another. Knowing that an attribute has a skew allow us to perform data preparation to correct the skew to improve accouracy of the models.\n",
    "\n",
    "Pandas `skew()` function shows a positive (right) or negetive (left) skew. Values closer to zero shows less skew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregnancies                 0.901674\n",
      "Glucose                     0.173754\n",
      "BloodPressure              -1.843608\n",
      "SkinThickness               0.109372\n",
      "Insulin                     2.272251\n",
      "BMI                        -0.428982\n",
      "DiabetesPedigreeFunction    1.919911\n",
      "Age                         1.129597\n",
      "Outcome                     0.635017\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Types of the Data\n",
    "import pandas as pd\n",
    "\n",
    "filepath = \"F:/courses/mlds_nactar/dataset/pima_indians_diabetes.csv\"\n",
    "data = pd.read_csv(filepath)\n",
    "skew = data.skew()\n",
    "print(skew)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
